<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="pdoc 15.0.1"/>
    <title>lstm_clm.clm API documentation</title>

    <style>/*! * Bootstrap Reboot v5.0.0 (https://getbootstrap.com/) * Copyright 2011-2021 The Bootstrap Authors * Copyright 2011-2021 Twitter, Inc. * Licensed under MIT (https://github.com/twbs/bootstrap/blob/main/LICENSE) * Forked from Normalize.css, licensed MIT (https://github.com/necolas/normalize.css/blob/master/LICENSE.md) */*,::after,::before{box-sizing:border-box}@media (prefers-reduced-motion:no-preference){:root{scroll-behavior:smooth}}body{margin:0;font-family:system-ui,-apple-system,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans","Liberation Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-size:1rem;font-weight:400;line-height:1.5;color:#212529;background-color:#fff;-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:transparent}hr{margin:1rem 0;color:inherit;background-color:currentColor;border:0;opacity:.25}hr:not([size]){height:1px}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:.5rem;font-weight:500;line-height:1.2}h1{font-size:calc(1.375rem + 1.5vw)}@media (min-width:1200px){h1{font-size:2.5rem}}h2{font-size:calc(1.325rem + .9vw)}@media (min-width:1200px){h2{font-size:2rem}}h3{font-size:calc(1.3rem + .6vw)}@media (min-width:1200px){h3{font-size:1.75rem}}h4{font-size:calc(1.275rem + .3vw)}@media (min-width:1200px){h4{font-size:1.5rem}}h5{font-size:1.25rem}h6{font-size:1rem}p{margin-top:0;margin-bottom:1rem}abbr[data-bs-original-title],abbr[title]{-webkit-text-decoration:underline dotted;text-decoration:underline dotted;cursor:help;-webkit-text-decoration-skip-ink:none;text-decoration-skip-ink:none}address{margin-bottom:1rem;font-style:normal;line-height:inherit}ol,ul{padding-left:2rem}dl,ol,ul{margin-top:0;margin-bottom:1rem}ol ol,ol ul,ul ol,ul ul{margin-bottom:0}dt{font-weight:700}dd{margin-bottom:.5rem;margin-left:0}blockquote{margin:0 0 1rem}b,strong{font-weight:bolder}small{font-size:.875em}mark{padding:.2em;background-color:#fcf8e3}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}a{color:#0d6efd;text-decoration:underline}a:hover{color:#0a58ca}a:not([href]):not([class]),a:not([href]):not([class]):hover{color:inherit;text-decoration:none}code,kbd,pre,samp{font-family:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;font-size:1em;direction:ltr;unicode-bidi:bidi-override}pre{display:block;margin-top:0;margin-bottom:1rem;overflow:auto;font-size:.875em}pre code{font-size:inherit;color:inherit;word-break:normal}code{font-size:.875em;color:#d63384;word-wrap:break-word}a>code{color:inherit}kbd{padding:.2rem .4rem;font-size:.875em;color:#fff;background-color:#212529;border-radius:.2rem}kbd kbd{padding:0;font-size:1em;font-weight:700}figure{margin:0 0 1rem}img,svg{vertical-align:middle}table{caption-side:bottom;border-collapse:collapse}caption{padding-top:.5rem;padding-bottom:.5rem;color:#6c757d;text-align:left}th{text-align:inherit;text-align:-webkit-match-parent}tbody,td,tfoot,th,thead,tr{border-color:inherit;border-style:solid;border-width:0}label{display:inline-block}button{border-radius:0}button:focus:not(:focus-visible){outline:0}button,input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:inherit;line-height:inherit}button,select{text-transform:none}[role=button]{cursor:pointer}select{word-wrap:normal}select:disabled{opacity:1}[list]::-webkit-calendar-picker-indicator{display:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]:not(:disabled),[type=reset]:not(:disabled),[type=submit]:not(:disabled),button:not(:disabled){cursor:pointer}::-moz-focus-inner{padding:0;border-style:none}textarea{resize:vertical}fieldset{min-width:0;padding:0;margin:0;border:0}legend{float:left;width:100%;padding:0;margin-bottom:.5rem;font-size:calc(1.275rem + .3vw);line-height:inherit}@media (min-width:1200px){legend{font-size:1.5rem}}legend+*{clear:left}::-webkit-datetime-edit-day-field,::-webkit-datetime-edit-fields-wrapper,::-webkit-datetime-edit-hour-field,::-webkit-datetime-edit-minute,::-webkit-datetime-edit-month-field,::-webkit-datetime-edit-text,::-webkit-datetime-edit-year-field{padding:0}::-webkit-inner-spin-button{height:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-color-swatch-wrapper{padding:0}::file-selector-button{font:inherit}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}output{display:inline-block}iframe{border:0}summary{display:list-item;cursor:pointer}progress{vertical-align:baseline}[hidden]{display:none!important}</style>
    <style>/*! syntax-highlighting.css */pre{line-height:125%;}span.linenos{color:inherit; background-color:transparent; padding-left:5px; padding-right:20px;}.pdoc-code .hll{background-color:#ffffcc}.pdoc-code{background:#f8f8f8;}.pdoc-code .c{color:#3D7B7B; font-style:italic}.pdoc-code .err{border:1px solid #FF0000}.pdoc-code .k{color:#008000; font-weight:bold}.pdoc-code .o{color:#666666}.pdoc-code .ch{color:#3D7B7B; font-style:italic}.pdoc-code .cm{color:#3D7B7B; font-style:italic}.pdoc-code .cp{color:#9C6500}.pdoc-code .cpf{color:#3D7B7B; font-style:italic}.pdoc-code .c1{color:#3D7B7B; font-style:italic}.pdoc-code .cs{color:#3D7B7B; font-style:italic}.pdoc-code .gd{color:#A00000}.pdoc-code .ge{font-style:italic}.pdoc-code .gr{color:#E40000}.pdoc-code .gh{color:#000080; font-weight:bold}.pdoc-code .gi{color:#008400}.pdoc-code .go{color:#717171}.pdoc-code .gp{color:#000080; font-weight:bold}.pdoc-code .gs{font-weight:bold}.pdoc-code .gu{color:#800080; font-weight:bold}.pdoc-code .gt{color:#0044DD}.pdoc-code .kc{color:#008000; font-weight:bold}.pdoc-code .kd{color:#008000; font-weight:bold}.pdoc-code .kn{color:#008000; font-weight:bold}.pdoc-code .kp{color:#008000}.pdoc-code .kr{color:#008000; font-weight:bold}.pdoc-code .kt{color:#B00040}.pdoc-code .m{color:#666666}.pdoc-code .s{color:#BA2121}.pdoc-code .na{color:#687822}.pdoc-code .nb{color:#008000}.pdoc-code .nc{color:#0000FF; font-weight:bold}.pdoc-code .no{color:#880000}.pdoc-code .nd{color:#AA22FF}.pdoc-code .ni{color:#717171; font-weight:bold}.pdoc-code .ne{color:#CB3F38; font-weight:bold}.pdoc-code .nf{color:#0000FF}.pdoc-code .nl{color:#767600}.pdoc-code .nn{color:#0000FF; font-weight:bold}.pdoc-code .nt{color:#008000; font-weight:bold}.pdoc-code .nv{color:#19177C}.pdoc-code .ow{color:#AA22FF; font-weight:bold}.pdoc-code .w{color:#bbbbbb}.pdoc-code .mb{color:#666666}.pdoc-code .mf{color:#666666}.pdoc-code .mh{color:#666666}.pdoc-code .mi{color:#666666}.pdoc-code .mo{color:#666666}.pdoc-code .sa{color:#BA2121}.pdoc-code .sb{color:#BA2121}.pdoc-code .sc{color:#BA2121}.pdoc-code .dl{color:#BA2121}.pdoc-code .sd{color:#BA2121; font-style:italic}.pdoc-code .s2{color:#BA2121}.pdoc-code .se{color:#AA5D1F; font-weight:bold}.pdoc-code .sh{color:#BA2121}.pdoc-code .si{color:#A45A77; font-weight:bold}.pdoc-code .sx{color:#008000}.pdoc-code .sr{color:#A45A77}.pdoc-code .s1{color:#BA2121}.pdoc-code .ss{color:#19177C}.pdoc-code .bp{color:#008000}.pdoc-code .fm{color:#0000FF}.pdoc-code .vc{color:#19177C}.pdoc-code .vg{color:#19177C}.pdoc-code .vi{color:#19177C}.pdoc-code .vm{color:#19177C}.pdoc-code .il{color:#666666}</style>
    <style>/*! theme.css */:root{--pdoc-background:#fff;}.pdoc{--text:#212529;--muted:#6c757d;--link:#3660a5;--link-hover:#1659c5;--code:#f8f8f8;--active:#fff598;--accent:#eee;--accent2:#c1c1c1;--nav-hover:rgba(255, 255, 255, 0.5);--name:#0066BB;--def:#008800;--annotation:#007020;}</style>
    <style>/*! layout.css */html, body{width:100%;height:100%;}html, main{scroll-behavior:smooth;}body{background-color:var(--pdoc-background);}@media (max-width:769px){#navtoggle{cursor:pointer;position:absolute;width:50px;height:40px;top:1rem;right:1rem;border-color:var(--text);color:var(--text);display:flex;opacity:0.8;z-index:999;}#navtoggle:hover{opacity:1;}#togglestate + div{display:none;}#togglestate:checked + div{display:inherit;}main, header{padding:2rem 3vw;}header + main{margin-top:-3rem;}.git-button{display:none !important;}nav input[type="search"]{max-width:77%;}nav input[type="search"]:first-child{margin-top:-6px;}nav input[type="search"]:valid ~ *{display:none !important;}}@media (min-width:770px){:root{--sidebar-width:clamp(12.5rem, 28vw, 22rem);}nav{position:fixed;overflow:auto;height:100vh;width:var(--sidebar-width);}main, header{padding:3rem 2rem 3rem calc(var(--sidebar-width) + 3rem);width:calc(54rem + var(--sidebar-width));max-width:100%;}header + main{margin-top:-4rem;}#navtoggle{display:none;}}#togglestate{position:absolute;height:0;opacity:0;}nav.pdoc{--pad:clamp(0.5rem, 2vw, 1.75rem);--indent:1.5rem;background-color:var(--accent);border-right:1px solid var(--accent2);box-shadow:0 0 20px rgba(50, 50, 50, .2) inset;padding:0 0 0 var(--pad);overflow-wrap:anywhere;scrollbar-width:thin; scrollbar-color:var(--accent2) transparent; z-index:1}nav.pdoc::-webkit-scrollbar{width:.4rem; }nav.pdoc::-webkit-scrollbar-thumb{background-color:var(--accent2); }nav.pdoc > div{padding:var(--pad) 0;}nav.pdoc .module-list-button{display:inline-flex;align-items:center;color:var(--text);border-color:var(--muted);margin-bottom:1rem;}nav.pdoc .module-list-button:hover{border-color:var(--text);}nav.pdoc input[type=search]{display:block;outline-offset:0;width:calc(100% - var(--pad));}nav.pdoc .logo{max-width:calc(100% - var(--pad));max-height:35vh;display:block;margin:0 auto 1rem;transform:translate(calc(-.5 * var(--pad)), 0);}nav.pdoc ul{list-style:none;padding-left:0;}nav.pdoc > div > ul{margin-left:calc(0px - var(--pad));}nav.pdoc li a{padding:.2rem 0 .2rem calc(var(--pad) + var(--indent));}nav.pdoc > div > ul > li > a{padding-left:var(--pad);}nav.pdoc li{transition:all 100ms;}nav.pdoc li:hover{background-color:var(--nav-hover);}nav.pdoc a, nav.pdoc a:hover{color:var(--text);}nav.pdoc a{display:block;}nav.pdoc > h2:first-of-type{margin-top:1.5rem;}nav.pdoc .class:before{content:"class ";color:var(--muted);}nav.pdoc .function:after{content:"()";color:var(--muted);}nav.pdoc footer:before{content:"";display:block;width:calc(100% - var(--pad));border-top:solid var(--accent2) 1px;margin-top:1.5rem;padding-top:.5rem;}nav.pdoc footer{font-size:small;}</style>
    <style>/*! content.css */.pdoc{color:var(--text);box-sizing:border-box;line-height:1.5;background:none;}.pdoc .pdoc-button{cursor:pointer;display:inline-block;border:solid black 1px;border-radius:2px;font-size:.75rem;padding:calc(0.5em - 1px) 1em;transition:100ms all;}.pdoc .alert{padding:1rem 1rem 1rem calc(1.5rem + 24px);border:1px solid transparent;border-radius:.25rem;background-repeat:no-repeat;background-position:.75rem center;margin-bottom:1rem;}.pdoc .alert > em{display:none;}.pdoc .alert > *:last-child{margin-bottom:0;}.pdoc .alert.note {color:#084298;background-color:#cfe2ff;border-color:#b6d4fe;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23084298%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8%2016A8%208%200%201%200%208%200a8%208%200%200%200%200%2016zm.93-9.412-1%204.705c-.07.34.029.533.304.533.194%200%20.487-.07.686-.246l-.088.416c-.287.346-.92.598-1.465.598-.703%200-1.002-.422-.808-1.319l.738-3.468c.064-.293.006-.399-.287-.47l-.451-.081.082-.381%202.29-.287zM8%205.5a1%201%200%201%201%200-2%201%201%200%200%201%200%202z%22/%3E%3C/svg%3E");}.pdoc .alert.warning{color:#664d03;background-color:#fff3cd;border-color:#ffecb5;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23664d03%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8.982%201.566a1.13%201.13%200%200%200-1.96%200L.165%2013.233c-.457.778.091%201.767.98%201.767h13.713c.889%200%201.438-.99.98-1.767L8.982%201.566zM8%205c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%205.995A.905.905%200%200%201%208%205zm.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2z%22/%3E%3C/svg%3E");}.pdoc .alert.danger{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M5.52.359A.5.5%200%200%201%206%200h4a.5.5%200%200%201%20.474.658L8.694%206H12.5a.5.5%200%200%201%20.395.807l-7%209a.5.5%200%200%201-.873-.454L6.823%209.5H3.5a.5.5%200%200%201-.48-.641l2.5-8.5z%22/%3E%3C/svg%3E");}.pdoc .visually-hidden{position:absolute !important;width:1px !important;height:1px !important;padding:0 !important;margin:-1px !important;overflow:hidden !important;clip:rect(0, 0, 0, 0) !important;white-space:nowrap !important;border:0 !important;}.pdoc h1, .pdoc h2, .pdoc h3{font-weight:300;margin:.3em 0;padding:.2em 0;}.pdoc > section:not(.module-info) h1{font-size:1.5rem;font-weight:500;}.pdoc > section:not(.module-info) h2{font-size:1.4rem;font-weight:500;}.pdoc > section:not(.module-info) h3{font-size:1.3rem;font-weight:500;}.pdoc > section:not(.module-info) h4{font-size:1.2rem;}.pdoc > section:not(.module-info) h5{font-size:1.1rem;}.pdoc a{text-decoration:none;color:var(--link);}.pdoc a:hover{color:var(--link-hover);}.pdoc blockquote{margin-left:2rem;}.pdoc pre{border-top:1px solid var(--accent2);border-bottom:1px solid var(--accent2);margin-top:0;margin-bottom:1em;padding:.5rem 0 .5rem .5rem;overflow-x:auto;background-color:var(--code);}.pdoc code{color:var(--text);padding:.2em .4em;margin:0;font-size:85%;background-color:var(--accent);border-radius:6px;}.pdoc a > code{color:inherit;}.pdoc pre > code{display:inline-block;font-size:inherit;background:none;border:none;padding:0;}.pdoc > section:not(.module-info){margin-bottom:1.5rem;}.pdoc .modulename{margin-top:0;font-weight:bold;}.pdoc .modulename a{color:var(--link);transition:100ms all;}.pdoc .git-button{float:right;border:solid var(--link) 1px;}.pdoc .git-button:hover{background-color:var(--link);color:var(--pdoc-background);}.view-source-toggle-state,.view-source-toggle-state ~ .pdoc-code{display:none;}.view-source-toggle-state:checked ~ .pdoc-code{display:block;}.view-source-button{display:inline-block;float:right;font-size:.75rem;line-height:1.5rem;color:var(--muted);padding:0 .4rem 0 1.3rem;cursor:pointer;text-indent:-2px;}.view-source-button > span{visibility:hidden;}.module-info .view-source-button{float:none;display:flex;justify-content:flex-end;margin:-1.2rem .4rem -.2rem 0;}.view-source-button::before{position:absolute;content:"View Source";display:list-item;list-style-type:disclosure-closed;}.view-source-toggle-state:checked ~ .attr .view-source-button::before,.view-source-toggle-state:checked ~ .view-source-button::before{list-style-type:disclosure-open;}.pdoc .docstring{margin-bottom:1.5rem;}.pdoc section:not(.module-info) .docstring{margin-left:clamp(0rem, 5vw - 2rem, 1rem);}.pdoc .docstring .pdoc-code{margin-left:1em;margin-right:1em;}.pdoc h1:target,.pdoc h2:target,.pdoc h3:target,.pdoc h4:target,.pdoc h5:target,.pdoc h6:target,.pdoc .pdoc-code > pre > span:target{background-color:var(--active);box-shadow:-1rem 0 0 0 var(--active);}.pdoc .pdoc-code > pre > span:target{display:block;}.pdoc div:target > .attr,.pdoc section:target > .attr,.pdoc dd:target > a{background-color:var(--active);}.pdoc *{scroll-margin:2rem;}.pdoc .pdoc-code .linenos{user-select:none;}.pdoc .attr:hover{filter:contrast(0.95);}.pdoc section, .pdoc .classattr{position:relative;}.pdoc .headerlink{--width:clamp(1rem, 3vw, 2rem);position:absolute;top:0;left:calc(0rem - var(--width));transition:all 100ms ease-in-out;opacity:0;}.pdoc .headerlink::before{content:"#";display:block;text-align:center;width:var(--width);height:2.3rem;line-height:2.3rem;font-size:1.5rem;}.pdoc .attr:hover ~ .headerlink,.pdoc *:target > .headerlink,.pdoc .headerlink:hover{opacity:1;}.pdoc .attr{display:block;margin:.5rem 0 .5rem;padding:.4rem .4rem .4rem 1rem;background-color:var(--accent);overflow-x:auto;}.pdoc .classattr{margin-left:2rem;}.pdoc .decorator-deprecated{color:#842029;}.pdoc .decorator-deprecated ~ span{filter:grayscale(1) opacity(0.8);}.pdoc .name{color:var(--name);font-weight:bold;}.pdoc .def{color:var(--def);font-weight:bold;}.pdoc .signature{background-color:transparent;}.pdoc .param, .pdoc .return-annotation{white-space:pre;}.pdoc .signature.multiline .param{display:block;}.pdoc .signature.condensed .param{display:inline-block;}.pdoc .annotation{color:var(--annotation);}.pdoc .view-value-toggle-state,.pdoc .view-value-toggle-state ~ .default_value{display:none;}.pdoc .view-value-toggle-state:checked ~ .default_value{display:inherit;}.pdoc .view-value-button{font-size:.5rem;vertical-align:middle;border-style:dashed;margin-top:-0.1rem;}.pdoc .view-value-button:hover{background:white;}.pdoc .view-value-button::before{content:"show";text-align:center;width:2.2em;display:inline-block;}.pdoc .view-value-toggle-state:checked ~ .view-value-button::before{content:"hide";}.pdoc .inherited{margin-left:2rem;}.pdoc .inherited dt{font-weight:700;}.pdoc .inherited dt, .pdoc .inherited dd{display:inline;margin-left:0;margin-bottom:.5rem;}.pdoc .inherited dd:not(:last-child):after{content:", ";}.pdoc .inherited .class:before{content:"class ";}.pdoc .inherited .function a:after{content:"()";}.pdoc .search-result .docstring{overflow:auto;max-height:25vh;}.pdoc .search-result.focused > .attr{background-color:var(--active);}.pdoc .attribution{margin-top:2rem;display:block;opacity:0.5;transition:all 200ms;filter:grayscale(100%);}.pdoc .attribution:hover{opacity:1;filter:grayscale(0%);}.pdoc .attribution img{margin-left:5px;height:35px;vertical-align:middle;width:70px;transition:all 200ms;}.pdoc table{display:block;width:max-content;max-width:100%;overflow:auto;margin-bottom:1rem;}.pdoc table th{font-weight:600;}.pdoc table th, .pdoc table td{padding:6px 13px;border:1px solid var(--accent2);}</style>
    <style>/*! custom.css */</style></head>
<body>
    <nav class="pdoc">
        <label id="navtoggle" for="togglestate" class="pdoc-button"><svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 30 30'><path stroke-linecap='round' stroke="currentColor" stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/></svg></label>
        <input id="togglestate" type="checkbox" aria-hidden="true" tabindex="-1">
        <div>            <a class="pdoc-button module-list-button" href="../lstm_clm.html">
<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-box-arrow-in-left" viewBox="0 0 16 16">
  <path fill-rule="evenodd" d="M10 3.5a.5.5 0 0 0-.5-.5h-8a.5.5 0 0 0-.5.5v9a.5.5 0 0 0 .5.5h8a.5.5 0 0 0 .5-.5v-2a.5.5 0 0 1 1 0v2A1.5 1.5 0 0 1 9.5 14h-8A1.5 1.5 0 0 1 0 12.5v-9A1.5 1.5 0 0 1 1.5 2h8A1.5 1.5 0 0 1 11 3.5v2a.5.5 0 0 1-1 0v-2z"/>
  <path fill-rule="evenodd" d="M4.146 8.354a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H14.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3z"/>
</svg>                &nbsp;lstm_clm</a>


            <input type="search" placeholder="Search..." role="searchbox" aria-label="search"
                   pattern=".+" required>


            <h2>Submodules</h2>
            <ul>
                    <li><a href="clm/perplexity.html">perplexity</a></li>
                    <li><a href="clm/randomized.html">randomized</a></li>
                    <li><a href="clm/utils.html">utils</a></li>
            </ul>

            <h2>API Documentation</h2>
                <ul class="memberlist">
            <li>
                    <a class="class" href="#BaseCLM">BaseCLM</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#BaseCLM.__init__">BaseCLM</a>
                        </li>
                        <li>
                                <a class="function" href="#BaseCLM.from_vocab">from_vocab</a>
                        </li>
                        <li>
                                <a class="function" href="#BaseCLM.call_cell">call_cell</a>
                        </li>
                        <li>
                                <a class="function" href="#BaseCLM.load_optim">load_optim</a>
                        </li>
                        <li>
                                <a class="function" href="#BaseCLM.save_optim">save_optim</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#MultinomialCLM">MultinomialCLM</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#MultinomialCLM.generate">generate</a>
                        </li>
                        <li>
                                <a class="function" href="#MultinomialCLM.sample_next_tokens">sample_next_tokens</a>
                        </li>
                        <li>
                                <a class="function" href="#MultinomialCLM.generate_with_perplexity">generate_with_perplexity</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#Trainer">Trainer</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#Trainer.fit">fit</a>
                        </li>
                        <li>
                                <a class="function" href="#Trainer.callbacks">callbacks</a>
                        </li>
                        <li>
                                <a class="function" href="#Trainer.init">init</a>
                        </li>
                        <li>
                                <a class="function" href="#Trainer.build">build</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#VocabMultinomialCLM">VocabMultinomialCLM</a>
                            <ul class="memberlist">
                        <li>
                                <a class="variable" href="#VocabMultinomialCLM.ASSERT_VOCAB">ASSERT_VOCAB</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="function" href="#allow_memory_growth">allow_memory_growth</a>
            </li>
            <li>
                    <a class="function" href="#batch_tensor_slices">batch_tensor_slices</a>
            </li>
            <li>
                    <a class="function" href="#build_adam_optimizer">build_adam_optimizer</a>
            </li>
            <li>
                    <a class="function" href="#build_model_cp">build_model_cp</a>
            </li>
            <li>
                    <a class="function" href="#get_data_from_vocab">get_data_from_vocab</a>
            </li>
    </ul>



        <a class="attribution" title="pdoc: Python API documentation generator" href="https://pdoc.dev" target="_blank">
            built with <span class="visually-hidden">pdoc</span><img
                alt="pdoc logo"
                src="data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20role%3D%22img%22%20aria-label%3D%22pdoc%20logo%22%20width%3D%22300%22%20height%3D%22150%22%20viewBox%3D%22-1%200%2060%2030%22%3E%3Ctitle%3Epdoc%3C/title%3E%3Cpath%20d%3D%22M29.621%2021.293c-.011-.273-.214-.475-.511-.481a.5.5%200%200%200-.489.503l-.044%201.393c-.097.551-.695%201.215-1.566%201.704-.577.428-1.306.486-2.193.182-1.426-.617-2.467-1.654-3.304-2.487l-.173-.172a3.43%203.43%200%200%200-.365-.306.49.49%200%200%200-.286-.196c-1.718-1.06-4.931-1.47-7.353.191l-.219.15c-1.707%201.187-3.413%202.131-4.328%201.03-.02-.027-.49-.685-.141-1.763.233-.721.546-2.408.772-4.076.042-.09.067-.187.046-.288.166-1.347.277-2.625.241-3.351%201.378-1.008%202.271-2.586%202.271-4.362%200-.976-.272-1.935-.788-2.774-.057-.094-.122-.18-.184-.268.033-.167.052-.339.052-.516%200-1.477-1.202-2.679-2.679-2.679-.791%200-1.496.352-1.987.9a6.3%206.3%200%200%200-1.001.029c-.492-.564-1.207-.929-2.012-.929-1.477%200-2.679%201.202-2.679%202.679A2.65%202.65%200%200%200%20.97%206.554c-.383.747-.595%201.572-.595%202.41%200%202.311%201.507%204.29%203.635%205.107-.037.699-.147%202.27-.423%203.294l-.137.461c-.622%202.042-2.515%208.257%201.727%2010.643%201.614.908%203.06%201.248%204.317%201.248%202.665%200%204.492-1.524%205.322-2.401%201.476-1.559%202.886-1.854%206.491.82%201.877%201.393%203.514%201.753%204.861%201.068%202.223-1.713%202.811-3.867%203.399-6.374.077-.846.056-1.469.054-1.537zm-4.835%204.313c-.054.305-.156.586-.242.629-.034-.007-.131-.022-.307-.157-.145-.111-.314-.478-.456-.908.221.121.432.25.675.355.115.039.219.051.33.081zm-2.251-1.238c-.05.33-.158.648-.252.694-.022.001-.125-.018-.307-.157-.217-.166-.488-.906-.639-1.573.358.344.754.693%201.198%201.036zm-3.887-2.337c-.006-.116-.018-.231-.041-.342.635.145%201.189.368%201.599.625.097.231.166.481.174.642-.03.049-.055.101-.067.158-.046.013-.128.026-.298.004-.278-.037-.901-.57-1.367-1.087zm-1.127-.497c.116.306.176.625.12.71-.019.014-.117.045-.345.016-.206-.027-.604-.332-.986-.695.41-.051.816-.056%201.211-.031zm-4.535%201.535c.209.22.379.47.358.598-.006.041-.088.138-.351.234-.144.055-.539-.063-.979-.259a11.66%2011.66%200%200%200%20.972-.573zm.983-.664c.359-.237.738-.418%201.126-.554.25.237.479.548.457.694-.006.042-.087.138-.351.235-.174.064-.694-.105-1.232-.375zm-3.381%201.794c-.022.145-.061.29-.149.401-.133.166-.358.248-.69.251h-.002c-.133%200-.306-.26-.45-.621.417.091.854.07%201.291-.031zm-2.066-8.077a4.78%204.78%200%200%201-.775-.584c.172-.115.505-.254.88-.378l-.105.962zm-.331%202.302a10.32%2010.32%200%200%201-.828-.502c.202-.143.576-.328.984-.49l-.156.992zm-.45%202.157l-.701-.403c.214-.115.536-.249.891-.376a11.57%2011.57%200%200%201-.19.779zm-.181%201.716c.064.398.194.702.298.893-.194-.051-.435-.162-.736-.398.061-.119.224-.3.438-.495zM8.87%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zm-.735-.389a1.15%201.15%200%200%200-.314.783%201.16%201.16%200%200%200%201.162%201.162c.457%200%20.842-.27%201.032-.653.026.117.042.238.042.362a1.68%201.68%200%200%201-1.679%201.679%201.68%201.68%200%200%201-1.679-1.679c0-.843.626-1.535%201.436-1.654zM5.059%205.406A1.68%201.68%200%200%201%203.38%207.085a1.68%201.68%200%200%201-1.679-1.679c0-.037.009-.072.011-.109.21.3.541.508.935.508a1.16%201.16%200%200%200%201.162-1.162%201.14%201.14%200%200%200-.474-.912c.015%200%20.03-.005.045-.005.926.001%201.679.754%201.679%201.68zM3.198%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zM1.375%208.964c0-.52.103-1.035.288-1.52.466.394%201.06.64%201.717.64%201.144%200%202.116-.725%202.499-1.738.383%201.012%201.355%201.738%202.499%201.738.867%200%201.631-.421%202.121-1.062.307.605.478%201.267.478%201.942%200%202.486-2.153%204.51-4.801%204.51s-4.801-2.023-4.801-4.51zm24.342%2019.349c-.985.498-2.267.168-3.813-.979-3.073-2.281-5.453-3.199-7.813-.705-1.315%201.391-4.163%203.365-8.423.97-3.174-1.786-2.239-6.266-1.261-9.479l.146-.492c.276-1.02.395-2.457.444-3.268a6.11%206.11%200%200%200%201.18.115%206.01%206.01%200%200%200%202.536-.562l-.006.175c-.802.215-1.848.612-2.021%201.25-.079.295.021.601.274.837.219.203.415.364.598.501-.667.304-1.243.698-1.311%201.179-.02.144-.022.507.393.787.213.144.395.26.564.365-1.285.521-1.361.96-1.381%201.126-.018.142-.011.496.427.746l.854.489c-.473.389-.971.914-.999%201.429-.018.278.095.532.316.713.675.556%201.231.721%201.653.721.059%200%20.104-.014.158-.02.207.707.641%201.64%201.513%201.64h.013c.8-.008%201.236-.345%201.462-.626.173-.216.268-.457.325-.692.424.195.93.374%201.372.374.151%200%20.294-.021.423-.068.732-.27.944-.704.993-1.021.009-.061.003-.119.002-.179.266.086.538.147.789.147.15%200%20.294-.021.423-.069.542-.2.797-.489.914-.754.237.147.478.258.704.288.106.014.205.021.296.021.356%200%20.595-.101.767-.229.438.435%201.094.992%201.656%201.067.106.014.205.021.296.021a1.56%201.56%200%200%200%20.323-.035c.17.575.453%201.289.866%201.605.358.273.665.362.914.362a.99.99%200%200%200%20.421-.093%201.03%201.03%200%200%200%20.245-.164c.168.428.39.846.68%201.068.358.273.665.362.913.362a.99.99%200%200%200%20.421-.093c.317-.148.512-.448.639-.762.251.157.495.257.726.257.127%200%20.25-.024.37-.071.427-.17.706-.617.841-1.314.022-.015.047-.022.068-.038.067-.051.133-.104.196-.159-.443%201.486-1.107%202.761-2.086%203.257zM8.66%209.925a.5.5%200%201%200-1%200c0%20.653-.818%201.205-1.787%201.205s-1.787-.552-1.787-1.205a.5.5%200%201%200-1%200c0%201.216%201.25%202.205%202.787%202.205s2.787-.989%202.787-2.205zm4.4%2015.965l-.208.097c-2.661%201.258-4.708%201.436-6.086.527-1.542-1.017-1.88-3.19-1.844-4.198a.4.4%200%200%200-.385-.414c-.242-.029-.406.164-.414.385-.046%201.249.367%203.686%202.202%204.896.708.467%201.547.7%202.51.7%201.248%200%202.706-.392%204.362-1.174l.185-.086a.4.4%200%200%200%20.205-.527c-.089-.204-.326-.291-.527-.206zM9.547%202.292c.093.077.205.114.317.114a.5.5%200%200%200%20.318-.886L8.817.397a.5.5%200%200%200-.703.068.5.5%200%200%200%20.069.703l1.364%201.124zm-7.661-.065c.086%200%20.173-.022.253-.068l1.523-.893a.5.5%200%200%200-.506-.863l-1.523.892a.5.5%200%200%200-.179.685c.094.158.261.247.432.247z%22%20transform%3D%22matrix%28-1%200%200%201%2058%200%29%22%20fill%3D%22%233bb300%22/%3E%3Cpath%20d%3D%22M.3%2021.86V10.18q0-.46.02-.68.04-.22.18-.5.28-.54%201.34-.54%201.06%200%201.42.28.38.26.44.78.76-1.04%202.38-1.04%201.64%200%203.1%201.54%201.46%201.54%201.46%203.58%200%202.04-1.46%203.58-1.44%201.54-3.08%201.54-1.64%200-2.38-.92v4.04q0%20.46-.04.68-.02.22-.18.5-.14.3-.5.42-.36.12-.98.12-.62%200-1-.12-.36-.12-.52-.4-.14-.28-.18-.5-.02-.22-.02-.68zm3.96-9.42q-.46.54-.46%201.18%200%20.64.46%201.18.48.52%201.2.52.74%200%201.24-.52.52-.52.52-1.18%200-.66-.48-1.18-.48-.54-1.26-.54-.76%200-1.22.54zm14.741-8.36q.16-.3.54-.42.38-.12%201-.12.64%200%201.02.12.38.12.52.42.16.3.18.54.04.22.04.68v11.94q0%20.46-.04.7-.02.22-.18.5-.3.54-1.7.54-1.38%200-1.54-.98-.84.96-2.34.96-1.8%200-3.28-1.56-1.48-1.58-1.48-3.66%200-2.1%201.48-3.68%201.5-1.58%203.28-1.58%201.48%200%202.3%201v-4.2q0-.46.02-.68.04-.24.18-.52zm-3.24%2010.86q.52.54%201.26.54.74%200%201.22-.54.5-.54.5-1.18%200-.66-.48-1.22-.46-.56-1.26-.56-.8%200-1.28.56-.48.54-.48%201.2%200%20.66.52%201.2zm7.833-1.2q0-2.4%201.68-3.96%201.68-1.56%203.84-1.56%202.16%200%203.82%201.56%201.66%201.54%201.66%203.94%200%201.66-.86%202.96-.86%201.28-2.1%201.9-1.22.6-2.54.6-1.32%200-2.56-.64-1.24-.66-2.1-1.92-.84-1.28-.84-2.88zm4.18%201.44q.64.48%201.3.48.66%200%201.32-.5.66-.5.66-1.48%200-.98-.62-1.46-.62-.48-1.34-.48-.72%200-1.34.5-.62.5-.62%201.48%200%20.96.64%201.46zm11.412-1.44q0%20.84.56%201.32.56.46%201.18.46.64%200%201.18-.36.56-.38.9-.38.6%200%201.46%201.06.46.58.46%201.04%200%20.76-1.1%201.42-1.14.8-2.8.8-1.86%200-3.58-1.34-.82-.64-1.34-1.7-.52-1.08-.52-2.36%200-1.3.52-2.34.52-1.06%201.34-1.7%201.66-1.32%203.54-1.32.76%200%201.48.22.72.2%201.06.4l.32.2q.36.24.56.38.52.4.52.92%200%20.5-.42%201.14-.72%201.1-1.38%201.1-.38%200-1.08-.44-.36-.34-1.04-.34-.66%200-1.24.48-.58.48-.58%201.34z%22%20fill%3D%22green%22/%3E%3C/svg%3E"/>
        </a>
</div>
    </nav>
    <main class="pdoc">
            <section class="module-info">
                    <h1 class="modulename">
<a href="./../lstm_clm.html">lstm_clm</a><wbr>.clm    </h1>

                        <div class="docstring"><p>Different classes to generate text from a lstm_clm.</p>
</div>

                        <input id="mod-clm-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">

                        <label class="view-source-button" for="mod-clm-view-source"><span>View Source</span></label>

                        <div class="pdoc-code codehilite"><pre><span></span><span id="L-1"><a href="#L-1"><span class="linenos"> 1</span></a><span class="sd">&quot;&quot;&quot;Different classes to generate text from a lstm_clm.&quot;&quot;&quot;</span>
</span><span id="L-2"><a href="#L-2"><span class="linenos"> 2</span></a>
</span><span id="L-3"><a href="#L-3"><span class="linenos"> 3</span></a><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">annotations</span>
</span><span id="L-4"><a href="#L-4"><span class="linenos"> 4</span></a>
</span><span id="L-5"><a href="#L-5"><span class="linenos"> 5</span></a><span class="kn">from</span> <span class="nn">lstm_clm.clm</span> <span class="kn">import</span> <span class="n">perplexity</span><span class="p">,</span> <span class="n">randomized</span><span class="p">,</span> <span class="n">utils</span>
</span><span id="L-6"><a href="#L-6"><span class="linenos"> 6</span></a><span class="kn">from</span> <span class="nn">lstm_clm.clm.base</span> <span class="kn">import</span> <span class="n">BaseCLM</span><span class="p">,</span> <span class="n">get_data_from_vocab</span>
</span><span id="L-7"><a href="#L-7"><span class="linenos"> 7</span></a><span class="kn">from</span> <span class="nn">lstm_clm.clm.multinomial</span> <span class="kn">import</span> <span class="n">MultinomialCLM</span><span class="p">,</span> <span class="n">VocabMultinomialCLM</span>
</span><span id="L-8"><a href="#L-8"><span class="linenos"> 8</span></a><span class="kn">from</span> <span class="nn">lstm_clm.clm.trainer</span> <span class="kn">import</span> <span class="n">Trainer</span>
</span><span id="L-9"><a href="#L-9"><span class="linenos"> 9</span></a><span class="kn">from</span> <span class="nn">lstm_clm.clm.utils</span> <span class="kn">import</span> <span class="p">(</span>
</span><span id="L-10"><a href="#L-10"><span class="linenos">10</span></a>    <span class="n">allow_memory_growth</span><span class="p">,</span>
</span><span id="L-11"><a href="#L-11"><span class="linenos">11</span></a>    <span class="n">batch_tensor_slices</span><span class="p">,</span>
</span><span id="L-12"><a href="#L-12"><span class="linenos">12</span></a>    <span class="n">build_adam_optimizer</span><span class="p">,</span>
</span><span id="L-13"><a href="#L-13"><span class="linenos">13</span></a>    <span class="n">build_model_cp</span><span class="p">,</span>
</span><span id="L-14"><a href="#L-14"><span class="linenos">14</span></a><span class="p">)</span>
</span><span id="L-15"><a href="#L-15"><span class="linenos">15</span></a>
</span><span id="L-16"><a href="#L-16"><span class="linenos">16</span></a><span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="L-17"><a href="#L-17"><span class="linenos">17</span></a>    <span class="s2">&quot;BaseCLM&quot;</span><span class="p">,</span>
</span><span id="L-18"><a href="#L-18"><span class="linenos">18</span></a>    <span class="s2">&quot;MultinomialCLM&quot;</span><span class="p">,</span>
</span><span id="L-19"><a href="#L-19"><span class="linenos">19</span></a>    <span class="s2">&quot;Trainer&quot;</span><span class="p">,</span>
</span><span id="L-20"><a href="#L-20"><span class="linenos">20</span></a>    <span class="s2">&quot;VocabMultinomialCLM&quot;</span><span class="p">,</span>
</span><span id="L-21"><a href="#L-21"><span class="linenos">21</span></a>    <span class="s2">&quot;allow_memory_growth&quot;</span><span class="p">,</span>
</span><span id="L-22"><a href="#L-22"><span class="linenos">22</span></a>    <span class="s2">&quot;batch_tensor_slices&quot;</span><span class="p">,</span>
</span><span id="L-23"><a href="#L-23"><span class="linenos">23</span></a>    <span class="s2">&quot;build_adam_optimizer&quot;</span><span class="p">,</span>
</span><span id="L-24"><a href="#L-24"><span class="linenos">24</span></a>    <span class="s2">&quot;build_model_cp&quot;</span><span class="p">,</span>
</span><span id="L-25"><a href="#L-25"><span class="linenos">25</span></a>    <span class="s2">&quot;get_data_from_vocab&quot;</span><span class="p">,</span>
</span><span id="L-26"><a href="#L-26"><span class="linenos">26</span></a>    <span class="s2">&quot;perplexity&quot;</span><span class="p">,</span>
</span><span id="L-27"><a href="#L-27"><span class="linenos">27</span></a>    <span class="s2">&quot;randomized&quot;</span><span class="p">,</span>
</span><span id="L-28"><a href="#L-28"><span class="linenos">28</span></a>    <span class="s2">&quot;utils&quot;</span><span class="p">,</span>
</span><span id="L-29"><a href="#L-29"><span class="linenos">29</span></a><span class="p">]</span>
</span></pre></div>


            </section>
                <section id="BaseCLM">
                            <input id="BaseCLM-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">

    <span class="def">class</span>
    <span class="name">BaseCLM</span>:

                <label class="view-source-button" for="BaseCLM-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BaseCLM"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BaseCLM-27"><a href="#BaseCLM-27"><span class="linenos"> 27</span></a><span class="k">class</span> <span class="nc">BaseCLM</span><span class="p">:</span>
</span><span id="BaseCLM-28"><a href="#BaseCLM-28"><span class="linenos"> 28</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Absolute base class for all CLM models.</span>
</span><span id="BaseCLM-29"><a href="#BaseCLM-29"><span class="linenos"> 29</span></a>
</span><span id="BaseCLM-30"><a href="#BaseCLM-30"><span class="linenos"> 30</span></a><span class="sd">    Implements a default call per time step and a default sample function.</span>
</span><span id="BaseCLM-31"><a href="#BaseCLM-31"><span class="linenos"> 31</span></a><span class="sd">    Compliance with the :class:`GenModel` protocol.</span>
</span><span id="BaseCLM-32"><a href="#BaseCLM-32"><span class="linenos"> 32</span></a>
</span><span id="BaseCLM-33"><a href="#BaseCLM-33"><span class="linenos"> 33</span></a><span class="sd">    Class variables:</span>
</span><span id="BaseCLM-34"><a href="#BaseCLM-34"><span class="linenos"> 34</span></a><span class="sd">        - ASSERT_VOCAB (bool): Whether to assert that a vocabulary is provided.</span>
</span><span id="BaseCLM-35"><a href="#BaseCLM-35"><span class="linenos"> 35</span></a>
</span><span id="BaseCLM-36"><a href="#BaseCLM-36"><span class="linenos"> 36</span></a><span class="sd">    Attributes:</span>
</span><span id="BaseCLM-37"><a href="#BaseCLM-37"><span class="linenos"> 37</span></a><span class="sd">        model (tf.keras.Model): Model to wrap with LSTM layers.</span>
</span><span id="BaseCLM-38"><a href="#BaseCLM-38"><span class="linenos"> 38</span></a><span class="sd">        vocab (Vocabulary | None): Vocabulary.</span>
</span><span id="BaseCLM-39"><a href="#BaseCLM-39"><span class="linenos"> 39</span></a><span class="sd">        vocab_size (int): Size of vocabulary.</span>
</span><span id="BaseCLM-40"><a href="#BaseCLM-40"><span class="linenos"> 40</span></a><span class="sd">        seq_len (int): Sequence length.</span>
</span><span id="BaseCLM-41"><a href="#BaseCLM-41"><span class="linenos"> 41</span></a><span class="sd">        dims (list[int]): Number of neurons per LSTM layers.</span>
</span><span id="BaseCLM-42"><a href="#BaseCLM-42"><span class="linenos"> 42</span></a><span class="sd">        has_embedding (bool): Whether the model has an Embedding layer.</span>
</span><span id="BaseCLM-43"><a href="#BaseCLM-43"><span class="linenos"> 43</span></a><span class="sd">        start_token (tf.Tensor): Start token for generation.</span>
</span><span id="BaseCLM-44"><a href="#BaseCLM-44"><span class="linenos"> 44</span></a><span class="sd">            If embedding: [1] {int32}</span>
</span><span id="BaseCLM-45"><a href="#BaseCLM-45"><span class="linenos"> 45</span></a><span class="sd">            Else: [1, Vocab] {float32}</span>
</span><span id="BaseCLM-46"><a href="#BaseCLM-46"><span class="linenos"> 46</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="BaseCLM-47"><a href="#BaseCLM-47"><span class="linenos"> 47</span></a>
</span><span id="BaseCLM-48"><a href="#BaseCLM-48"><span class="linenos"> 48</span></a>    <span class="n">ASSERT_VOCAB</span><span class="p">:</span> <span class="n">ClassVar</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="BaseCLM-49"><a href="#BaseCLM-49"><span class="linenos"> 49</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;@private&quot;&quot;&quot;</span>
</span><span id="BaseCLM-50"><a href="#BaseCLM-50"><span class="linenos"> 50</span></a>
</span><span id="BaseCLM-51"><a href="#BaseCLM-51"><span class="linenos"> 51</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="BaseCLM-52"><a href="#BaseCLM-52"><span class="linenos"> 52</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="BaseCLM-53"><a href="#BaseCLM-53"><span class="linenos"> 53</span></a>        <span class="n">model</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">,</span>
</span><span id="BaseCLM-54"><a href="#BaseCLM-54"><span class="linenos"> 54</span></a>        <span class="n">max_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="BaseCLM-55"><a href="#BaseCLM-55"><span class="linenos"> 55</span></a>        <span class="n">start_index</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="BaseCLM-56"><a href="#BaseCLM-56"><span class="linenos"> 56</span></a>        <span class="n">seq_len_append</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="BaseCLM-57"><a href="#BaseCLM-57"><span class="linenos"> 57</span></a>        <span class="n">vocab</span><span class="p">:</span> <span class="n">VocabProto</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="BaseCLM-58"><a href="#BaseCLM-58"><span class="linenos"> 58</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="BaseCLM-59"><a href="#BaseCLM-59"><span class="linenos"> 59</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize BaseCLM.</span>
</span><span id="BaseCLM-60"><a href="#BaseCLM-60"><span class="linenos"> 60</span></a>
</span><span id="BaseCLM-61"><a href="#BaseCLM-61"><span class="linenos"> 61</span></a><span class="sd">        The start index is the index of the BOS token in the vocabulary.</span>
</span><span id="BaseCLM-62"><a href="#BaseCLM-62"><span class="linenos"> 62</span></a><span class="sd">        The sequence length append is 1 if the EOS token is present, else 0.</span>
</span><span id="BaseCLM-63"><a href="#BaseCLM-63"><span class="linenos"> 63</span></a><span class="sd">        The values are extracted from the vocabulary, if provided.</span>
</span><span id="BaseCLM-64"><a href="#BaseCLM-64"><span class="linenos"> 64</span></a>
</span><span id="BaseCLM-65"><a href="#BaseCLM-65"><span class="linenos"> 65</span></a><span class="sd">        Args:</span>
</span><span id="BaseCLM-66"><a href="#BaseCLM-66"><span class="linenos"> 66</span></a><span class="sd">            model: Model to wrap with LSTM layers.</span>
</span><span id="BaseCLM-67"><a href="#BaseCLM-67"><span class="linenos"> 67</span></a><span class="sd">            max_len: Maximum length of generated samples.</span>
</span><span id="BaseCLM-68"><a href="#BaseCLM-68"><span class="linenos"> 68</span></a><span class="sd">            start_index: Index of the start token. Defaults to 1.</span>
</span><span id="BaseCLM-69"><a href="#BaseCLM-69"><span class="linenos"> 69</span></a><span class="sd">            seq_len_append: Additional sequence length for EOS token. Defaults to 1.</span>
</span><span id="BaseCLM-70"><a href="#BaseCLM-70"><span class="linenos"> 70</span></a><span class="sd">            vocab: Vocabulary. Defaults to None.</span>
</span><span id="BaseCLM-71"><a href="#BaseCLM-71"><span class="linenos"> 71</span></a>
</span><span id="BaseCLM-72"><a href="#BaseCLM-72"><span class="linenos"> 72</span></a><span class="sd">        Raises:</span>
</span><span id="BaseCLM-73"><a href="#BaseCLM-73"><span class="linenos"> 73</span></a><span class="sd">            ValueError: If vocabulary does not match provided lengths.</span>
</span><span id="BaseCLM-74"><a href="#BaseCLM-74"><span class="linenos"> 74</span></a><span class="sd">            ValueError: If `ASSERT_VOCAB` is True and no vocabulary is provided.</span>
</span><span id="BaseCLM-75"><a href="#BaseCLM-75"><span class="linenos"> 75</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaseCLM-76"><a href="#BaseCLM-76"><span class="linenos"> 76</span></a>        <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</span><span id="BaseCLM-77"><a href="#BaseCLM-77"><span class="linenos"> 77</span></a>
</span><span id="BaseCLM-78"><a href="#BaseCLM-78"><span class="linenos"> 78</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ASSERT_VOCAB</span> <span class="ow">and</span> <span class="n">vocab</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="BaseCLM-79"><a href="#BaseCLM-79"><span class="linenos"> 79</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Vocabulary is required for this model&quot;</span><span class="p">)</span>
</span><span id="BaseCLM-80"><a href="#BaseCLM-80"><span class="linenos"> 80</span></a>
</span><span id="BaseCLM-81"><a href="#BaseCLM-81"><span class="linenos"> 81</span></a>        <span class="k">if</span> <span class="n">max_len</span> <span class="o">&gt;</span> <span class="n">MAX_LEN_BOUNDARY</span><span class="p">:</span>  <span class="c1"># pragma: no cover # TODO: Remove this</span>
</span><span id="BaseCLM-82"><a href="#BaseCLM-82"><span class="linenos"> 82</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;max_len should be less than 150&quot;</span><span class="p">)</span>
</span><span id="BaseCLM-83"><a href="#BaseCLM-83"><span class="linenos"> 83</span></a>
</span><span id="BaseCLM-84"><a href="#BaseCLM-84"><span class="linenos"> 84</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
</span><span id="BaseCLM-85"><a href="#BaseCLM-85"><span class="linenos"> 85</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;@private&quot;&quot;&quot;</span>
</span><span id="BaseCLM-86"><a href="#BaseCLM-86"><span class="linenos"> 86</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span> <span class="o">=</span> <span class="n">vocab</span>
</span><span id="BaseCLM-87"><a href="#BaseCLM-87"><span class="linenos"> 87</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;@private&quot;&quot;&quot;</span>
</span><span id="BaseCLM-88"><a href="#BaseCLM-88"><span class="linenos"> 88</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span> <span class="o">=</span> <span class="n">max_len</span> <span class="o">+</span> <span class="n">seq_len_append</span>
</span><span id="BaseCLM-89"><a href="#BaseCLM-89"><span class="linenos"> 89</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;@private&quot;&quot;&quot;</span>
</span><span id="BaseCLM-90"><a href="#BaseCLM-90"><span class="linenos"> 90</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">output_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="BaseCLM-91"><a href="#BaseCLM-91"><span class="linenos"> 91</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;@private&quot;&quot;&quot;</span>
</span><span id="BaseCLM-92"><a href="#BaseCLM-92"><span class="linenos"> 92</span></a>
</span><span id="BaseCLM-93"><a href="#BaseCLM-93"><span class="linenos"> 93</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_vocab</span><span class="p">(</span><span class="n">max_len</span><span class="p">,</span> <span class="n">start_index</span><span class="p">,</span> <span class="n">seq_len_append</span><span class="p">)</span>
</span><span id="BaseCLM-94"><a href="#BaseCLM-94"><span class="linenos"> 94</span></a>
</span><span id="BaseCLM-95"><a href="#BaseCLM-95"><span class="linenos"> 95</span></a>        <span class="c1"># Get number of neurons in LSTM layers, used for initializing hidden states</span>
</span><span id="BaseCLM-96"><a href="#BaseCLM-96"><span class="linenos"> 96</span></a>        <span class="n">lstm_layers</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="BaseCLM-97"><a href="#BaseCLM-97"><span class="linenos"> 97</span></a>            <span class="n">layer</span>
</span><span id="BaseCLM-98"><a href="#BaseCLM-98"><span class="linenos"> 98</span></a>            <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span>
</span><span id="BaseCLM-99"><a href="#BaseCLM-99"><span class="linenos"> 99</span></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">)</span>
</span><span id="BaseCLM-100"><a href="#BaseCLM-100"><span class="linenos">100</span></a>        <span class="p">]</span>
</span><span id="BaseCLM-101"><a href="#BaseCLM-101"><span class="linenos">101</span></a>
</span><span id="BaseCLM-102"><a href="#BaseCLM-102"><span class="linenos">102</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dims</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">layer</span><span class="o">.</span><span class="n">units</span> <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">lstm_layers</span><span class="p">]</span>
</span><span id="BaseCLM-103"><a href="#BaseCLM-103"><span class="linenos">103</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;@private&quot;&quot;&quot;</span>
</span><span id="BaseCLM-104"><a href="#BaseCLM-104"><span class="linenos">104</span></a>
</span><span id="BaseCLM-105"><a href="#BaseCLM-105"><span class="linenos">105</span></a>        <span class="c1"># Check if model has Embedding layer</span>
</span><span id="BaseCLM-106"><a href="#BaseCLM-106"><span class="linenos">106</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">has_embedding</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span>
</span><span id="BaseCLM-107"><a href="#BaseCLM-107"><span class="linenos">107</span></a>            <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">)</span> <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span>
</span><span id="BaseCLM-108"><a href="#BaseCLM-108"><span class="linenos">108</span></a>        <span class="p">)</span>
</span><span id="BaseCLM-109"><a href="#BaseCLM-109"><span class="linenos">109</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;@private&quot;&quot;&quot;</span>
</span><span id="BaseCLM-110"><a href="#BaseCLM-110"><span class="linenos">110</span></a>
</span><span id="BaseCLM-111"><a href="#BaseCLM-111"><span class="linenos">111</span></a>        <span class="n">start_token_emb</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="n">start_index</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>  <span class="c1"># [1] {int32}</span>
</span><span id="BaseCLM-112"><a href="#BaseCLM-112"><span class="linenos">112</span></a>        <span class="n">start_token_one_hot</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span>
</span><span id="BaseCLM-113"><a href="#BaseCLM-113"><span class="linenos">113</span></a>            <span class="n">start_token_emb</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">output_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="BaseCLM-114"><a href="#BaseCLM-114"><span class="linenos">114</span></a>        <span class="p">)</span>  <span class="c1"># [1, Vocab] {float32}</span>
</span><span id="BaseCLM-115"><a href="#BaseCLM-115"><span class="linenos">115</span></a>
</span><span id="BaseCLM-116"><a href="#BaseCLM-116"><span class="linenos">116</span></a>        <span class="c1"># One-hot encode start tokens if model has no Embedding layer</span>
</span><span id="BaseCLM-117"><a href="#BaseCLM-117"><span class="linenos">117</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">start_token</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="BaseCLM-118"><a href="#BaseCLM-118"><span class="linenos">118</span></a>            <span class="n">start_token_emb</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_embedding</span> <span class="k">else</span> <span class="n">start_token_one_hot</span>
</span><span id="BaseCLM-119"><a href="#BaseCLM-119"><span class="linenos">119</span></a>        <span class="p">)</span>
</span><span id="BaseCLM-120"><a href="#BaseCLM-120"><span class="linenos">120</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;@private&quot;&quot;&quot;</span>
</span><span id="BaseCLM-121"><a href="#BaseCLM-121"><span class="linenos">121</span></a>
</span><span id="BaseCLM-122"><a href="#BaseCLM-122"><span class="linenos">122</span></a>    <span class="k">def</span> <span class="nf">_validate_vocab</span><span class="p">(</span>
</span><span id="BaseCLM-123"><a href="#BaseCLM-123"><span class="linenos">123</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">max_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">start_index</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">seq_len_append</span><span class="p">:</span> <span class="nb">int</span>
</span><span id="BaseCLM-124"><a href="#BaseCLM-124"><span class="linenos">124</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="BaseCLM-125"><a href="#BaseCLM-125"><span class="linenos">125</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Validate the vocabulary against the provided lengths.</span>
</span><span id="BaseCLM-126"><a href="#BaseCLM-126"><span class="linenos">126</span></a>
</span><span id="BaseCLM-127"><a href="#BaseCLM-127"><span class="linenos">127</span></a><span class="sd">        Raises:</span>
</span><span id="BaseCLM-128"><a href="#BaseCLM-128"><span class="linenos">128</span></a><span class="sd">            ValueError: If vocabulary does not match provided lengths.</span>
</span><span id="BaseCLM-129"><a href="#BaseCLM-129"><span class="linenos">129</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaseCLM-130"><a href="#BaseCLM-130"><span class="linenos">130</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="BaseCLM-131"><a href="#BaseCLM-131"><span class="linenos">131</span></a>            <span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;max_len&quot;</span><span class="p">,</span> <span class="s2">&quot;start_index&quot;</span><span class="p">,</span> <span class="s2">&quot;seq_len_append&quot;</span><span class="p">]</span>
</span><span id="BaseCLM-132"><a href="#BaseCLM-132"><span class="linenos">132</span></a>            <span class="n">vocab_size</span><span class="p">,</span> <span class="o">*</span><span class="n">vocab_data</span> <span class="o">=</span> <span class="n">get_data_from_vocab</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span>
</span><span id="BaseCLM-133"><a href="#BaseCLM-133"><span class="linenos">133</span></a>
</span><span id="BaseCLM-134"><a href="#BaseCLM-134"><span class="linenos">134</span></a>            <span class="k">if</span> <span class="n">vocab_size</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">output_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
</span><span id="BaseCLM-135"><a href="#BaseCLM-135"><span class="linenos">135</span></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="BaseCLM-136"><a href="#BaseCLM-136"><span class="linenos">136</span></a>                    <span class="s2">&quot;Vocabulary size does not match the last layers&#39; output dims: &quot;</span>
</span><span id="BaseCLM-137"><a href="#BaseCLM-137"><span class="linenos">137</span></a>                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">vocab_size</span><span class="si">}</span><span class="s2"> != </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">output_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="BaseCLM-138"><a href="#BaseCLM-138"><span class="linenos">138</span></a>                <span class="p">)</span>
</span><span id="BaseCLM-139"><a href="#BaseCLM-139"><span class="linenos">139</span></a>
</span><span id="BaseCLM-140"><a href="#BaseCLM-140"><span class="linenos">140</span></a>            <span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
</span><span id="BaseCLM-141"><a href="#BaseCLM-141"><span class="linenos">141</span></a>                <span class="n">vocab_data</span><span class="p">,</span> <span class="p">(</span><span class="n">max_len</span><span class="p">,</span> <span class="n">start_index</span><span class="p">,</span> <span class="n">seq_len_append</span><span class="p">),</span> <span class="n">names</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span>
</span><span id="BaseCLM-142"><a href="#BaseCLM-142"><span class="linenos">142</span></a>            <span class="p">):</span>
</span><span id="BaseCLM-143"><a href="#BaseCLM-143"><span class="linenos">143</span></a>                <span class="k">if</span> <span class="n">a</span> <span class="o">!=</span> <span class="n">b</span><span class="p">:</span>
</span><span id="BaseCLM-144"><a href="#BaseCLM-144"><span class="linenos">144</span></a>                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="BaseCLM-145"><a href="#BaseCLM-145"><span class="linenos">145</span></a>                        <span class="sa">f</span><span class="s2">&quot;Model/Vocab discrepancy: </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> does not match (</span><span class="si">{</span><span class="n">a</span><span class="si">}</span><span class="s2"> != </span><span class="si">{</span><span class="n">b</span><span class="si">}</span><span class="s2">)&quot;</span>
</span><span id="BaseCLM-146"><a href="#BaseCLM-146"><span class="linenos">146</span></a>                    <span class="p">)</span>
</span><span id="BaseCLM-147"><a href="#BaseCLM-147"><span class="linenos">147</span></a>
</span><span id="BaseCLM-148"><a href="#BaseCLM-148"><span class="linenos">148</span></a>    <span class="nd">@classmethod</span>
</span><span id="BaseCLM-149"><a href="#BaseCLM-149"><span class="linenos">149</span></a>    <span class="k">def</span> <span class="nf">from_vocab</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">,</span> <span class="n">vocab</span><span class="p">:</span> <span class="n">VocabProto</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Self</span><span class="p">:</span>
</span><span id="BaseCLM-150"><a href="#BaseCLM-150"><span class="linenos">150</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize :class:`BaseCLM` from a vocabulary.</span>
</span><span id="BaseCLM-151"><a href="#BaseCLM-151"><span class="linenos">151</span></a>
</span><span id="BaseCLM-152"><a href="#BaseCLM-152"><span class="linenos">152</span></a><span class="sd">        Args:</span>
</span><span id="BaseCLM-153"><a href="#BaseCLM-153"><span class="linenos">153</span></a><span class="sd">            model: Model to wrap with LSTM layers.</span>
</span><span id="BaseCLM-154"><a href="#BaseCLM-154"><span class="linenos">154</span></a><span class="sd">            vocab: Vocabulary.</span>
</span><span id="BaseCLM-155"><a href="#BaseCLM-155"><span class="linenos">155</span></a>
</span><span id="BaseCLM-156"><a href="#BaseCLM-156"><span class="linenos">156</span></a><span class="sd">        Returns:</span>
</span><span id="BaseCLM-157"><a href="#BaseCLM-157"><span class="linenos">157</span></a><span class="sd">            :class:`BaseCLM` instance.</span>
</span><span id="BaseCLM-158"><a href="#BaseCLM-158"><span class="linenos">158</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaseCLM-159"><a href="#BaseCLM-159"><span class="linenos">159</span></a>        <span class="n">_</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">start_index</span><span class="p">,</span> <span class="n">seq_len_append</span> <span class="o">=</span> <span class="n">get_data_from_vocab</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span>
</span><span id="BaseCLM-160"><a href="#BaseCLM-160"><span class="linenos">160</span></a>        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">start_index</span><span class="p">,</span> <span class="n">seq_len_append</span><span class="p">,</span> <span class="n">vocab</span><span class="p">)</span>
</span><span id="BaseCLM-161"><a href="#BaseCLM-161"><span class="linenos">161</span></a>
</span><span id="BaseCLM-162"><a href="#BaseCLM-162"><span class="linenos">162</span></a>    <span class="k">def</span> <span class="nf">call_cell</span><span class="p">(</span>
</span><span id="BaseCLM-163"><a href="#BaseCLM-163"><span class="linenos">163</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="BaseCLM-164"><a href="#BaseCLM-164"><span class="linenos">164</span></a>        <span class="n">x_t</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="BaseCLM-165"><a href="#BaseCLM-165"><span class="linenos">165</span></a>        <span class="n">hidden_states</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span>
</span><span id="BaseCLM-166"><a href="#BaseCLM-166"><span class="linenos">166</span></a>        <span class="o">/</span><span class="p">,</span>
</span><span id="BaseCLM-167"><a href="#BaseCLM-167"><span class="linenos">167</span></a>        <span class="n">training</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="BaseCLM-168"><a href="#BaseCLM-168"><span class="linenos">168</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span> <span class="kc">None</span><span class="p">]:</span>
</span><span id="BaseCLM-169"><a href="#BaseCLM-169"><span class="linenos">169</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Call the model for one time step.</span>
</span><span id="BaseCLM-170"><a href="#BaseCLM-170"><span class="linenos">170</span></a>
</span><span id="BaseCLM-171"><a href="#BaseCLM-171"><span class="linenos">171</span></a><span class="sd">        Args:</span>
</span><span id="BaseCLM-172"><a href="#BaseCLM-172"><span class="linenos">172</span></a><span class="sd">            x_t: Input at time step t.</span>
</span><span id="BaseCLM-173"><a href="#BaseCLM-173"><span class="linenos">173</span></a><span class="sd">                If embedding: [Batch] {int32}</span>
</span><span id="BaseCLM-174"><a href="#BaseCLM-174"><span class="linenos">174</span></a><span class="sd">                Else: [Batch, Vocab] {float32}</span>
</span><span id="BaseCLM-175"><a href="#BaseCLM-175"><span class="linenos">175</span></a><span class="sd">            hidden_states: LSTM layers&#39; hidden states.</span>
</span><span id="BaseCLM-176"><a href="#BaseCLM-176"><span class="linenos">176</span></a><span class="sd">                [2 x [Batch, Hidden] {float32}, ...]</span>
</span><span id="BaseCLM-177"><a href="#BaseCLM-177"><span class="linenos">177</span></a><span class="sd">            training: Whether in training mode. Defaults to False.</span>
</span><span id="BaseCLM-178"><a href="#BaseCLM-178"><span class="linenos">178</span></a>
</span><span id="BaseCLM-179"><a href="#BaseCLM-179"><span class="linenos">179</span></a><span class="sd">        Returns:</span>
</span><span id="BaseCLM-180"><a href="#BaseCLM-180"><span class="linenos">180</span></a><span class="sd">            tuple[tf.Tensor, list[list[tf.Tensor]], None]:</span>
</span><span id="BaseCLM-181"><a href="#BaseCLM-181"><span class="linenos">181</span></a><span class="sd">                output: Time step t output. [Batch, Vocab] {float32}</span>
</span><span id="BaseCLM-182"><a href="#BaseCLM-182"><span class="linenos">182</span></a><span class="sd">                states: LSTM layers&#39; output states. [2 x [Batch, Hidden] {float32}, ...]</span>
</span><span id="BaseCLM-183"><a href="#BaseCLM-183"><span class="linenos">183</span></a><span class="sd">                info: Always None.</span>
</span><span id="BaseCLM-184"><a href="#BaseCLM-184"><span class="linenos">184</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaseCLM-185"><a href="#BaseCLM-185"><span class="linenos">185</span></a>        <span class="k">return</span> <span class="n">lstm_model_call</span><span class="p">(</span>
</span><span id="BaseCLM-186"><a href="#BaseCLM-186"><span class="linenos">186</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dims</span><span class="p">,</span> <span class="n">x_t</span><span class="p">,</span> <span class="n">hidden_states</span><span class="p">,</span> <span class="n">training</span>
</span><span id="BaseCLM-187"><a href="#BaseCLM-187"><span class="linenos">187</span></a>        <span class="p">)</span>
</span><span id="BaseCLM-188"><a href="#BaseCLM-188"><span class="linenos">188</span></a>
</span><span id="BaseCLM-189"><a href="#BaseCLM-189"><span class="linenos">189</span></a>    <span class="k">def</span> <span class="nf">load_optim</span><span class="p">(</span>
</span><span id="BaseCLM-190"><a href="#BaseCLM-190"><span class="linenos">190</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="n">StrPath</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">Loss</span> <span class="o">|</span> <span class="nb">str</span><span class="p">,</span> <span class="n">shape</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
</span><span id="BaseCLM-191"><a href="#BaseCLM-191"><span class="linenos">191</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="BaseCLM-192"><a href="#BaseCLM-192"><span class="linenos">192</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Load optimizer from a file and compile the model.</span>
</span><span id="BaseCLM-193"><a href="#BaseCLM-193"><span class="linenos">193</span></a>
</span><span id="BaseCLM-194"><a href="#BaseCLM-194"><span class="linenos">194</span></a><span class="sd">        Important:</span>
</span><span id="BaseCLM-195"><a href="#BaseCLM-195"><span class="linenos">195</span></a><span class="sd">            If batch normalization should be freezed,</span>
</span><span id="BaseCLM-196"><a href="#BaseCLM-196"><span class="linenos">196</span></a><span class="sd">            use it before saving or loading the optimizer.</span>
</span><span id="BaseCLM-197"><a href="#BaseCLM-197"><span class="linenos">197</span></a>
</span><span id="BaseCLM-198"><a href="#BaseCLM-198"><span class="linenos">198</span></a><span class="sd">        Args:</span>
</span><span id="BaseCLM-199"><a href="#BaseCLM-199"><span class="linenos">199</span></a><span class="sd">            path: Path to the file.</span>
</span><span id="BaseCLM-200"><a href="#BaseCLM-200"><span class="linenos">200</span></a><span class="sd">            loss: Loss function.</span>
</span><span id="BaseCLM-201"><a href="#BaseCLM-201"><span class="linenos">201</span></a><span class="sd">            shape: Shape of the in- and output of the model.</span>
</span><span id="BaseCLM-202"><a href="#BaseCLM-202"><span class="linenos">202</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaseCLM-203"><a href="#BaseCLM-203"><span class="linenos">203</span></a>        <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</span><span id="BaseCLM-204"><a href="#BaseCLM-204"><span class="linenos">204</span></a>
</span><span id="BaseCLM-205"><a href="#BaseCLM-205"><span class="linenos">205</span></a>        <span class="n">bytes_content</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">path</span><span class="p">)</span><span class="o">.</span><span class="n">read_bytes</span><span class="p">()</span>
</span><span id="BaseCLM-206"><a href="#BaseCLM-206"><span class="linenos">206</span></a>        <span class="n">data</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="nb">list</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">bytes_content</span><span class="p">)</span>
</span><span id="BaseCLM-207"><a href="#BaseCLM-207"><span class="linenos">207</span></a>        <span class="n">config</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">data</span>
</span><span id="BaseCLM-208"><a href="#BaseCLM-208"><span class="linenos">208</span></a>
</span><span id="BaseCLM-209"><a href="#BaseCLM-209"><span class="linenos">209</span></a>        <span class="n">opt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="BaseCLM-210"><a href="#BaseCLM-210"><span class="linenos">210</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">)</span>
</span><span id="BaseCLM-211"><a href="#BaseCLM-211"><span class="linenos">211</span></a>
</span><span id="BaseCLM-212"><a href="#BaseCLM-212"><span class="linenos">212</span></a>        <span class="c1"># fit to initialize variables</span>
</span><span id="BaseCLM-213"><a href="#BaseCLM-213"><span class="linenos">213</span></a>        <span class="n">prev_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>
</span><span id="BaseCLM-214"><a href="#BaseCLM-214"><span class="linenos">214</span></a>        <span class="n">test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">shape</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="BaseCLM-215"><a href="#BaseCLM-215"><span class="linenos">215</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="BaseCLM-216"><a href="#BaseCLM-216"><span class="linenos">216</span></a>        <span class="c1"># reset weights</span>
</span><span id="BaseCLM-217"><a href="#BaseCLM-217"><span class="linenos">217</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">prev_weights</span><span class="p">)</span>
</span><span id="BaseCLM-218"><a href="#BaseCLM-218"><span class="linenos">218</span></a>
</span><span id="BaseCLM-219"><a href="#BaseCLM-219"><span class="linenos">219</span></a>        <span class="c1"># set optimizer weights</span>
</span><span id="BaseCLM-220"><a href="#BaseCLM-220"><span class="linenos">220</span></a>        <span class="n">opt</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
</span><span id="BaseCLM-221"><a href="#BaseCLM-221"><span class="linenos">221</span></a>
</span><span id="BaseCLM-222"><a href="#BaseCLM-222"><span class="linenos">222</span></a>        <span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">variables</span><span class="p">(),</span> <span class="n">weights</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
</span><span id="BaseCLM-223"><a href="#BaseCLM-223"><span class="linenos">223</span></a>            <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">b</span><span class="p">):</span>
</span><span id="BaseCLM-224"><a href="#BaseCLM-224"><span class="linenos">224</span></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Optimizer weights do not match&quot;</span><span class="p">)</span>
</span><span id="BaseCLM-225"><a href="#BaseCLM-225"><span class="linenos">225</span></a>
</span><span id="BaseCLM-226"><a href="#BaseCLM-226"><span class="linenos">226</span></a>    <span class="k">def</span> <span class="nf">save_optim</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="n">StrPath</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="BaseCLM-227"><a href="#BaseCLM-227"><span class="linenos">227</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Save optimizer to a file.</span>
</span><span id="BaseCLM-228"><a href="#BaseCLM-228"><span class="linenos">228</span></a>
</span><span id="BaseCLM-229"><a href="#BaseCLM-229"><span class="linenos">229</span></a><span class="sd">        Important:</span>
</span><span id="BaseCLM-230"><a href="#BaseCLM-230"><span class="linenos">230</span></a><span class="sd">            use `freeze_batch_norm` before saving or loading the optimizer.</span>
</span><span id="BaseCLM-231"><a href="#BaseCLM-231"><span class="linenos">231</span></a>
</span><span id="BaseCLM-232"><a href="#BaseCLM-232"><span class="linenos">232</span></a><span class="sd">        Args:</span>
</span><span id="BaseCLM-233"><a href="#BaseCLM-233"><span class="linenos">233</span></a><span class="sd">            path: Path to the file.</span>
</span><span id="BaseCLM-234"><a href="#BaseCLM-234"><span class="linenos">234</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaseCLM-235"><a href="#BaseCLM-235"><span class="linenos">235</span></a>        <span class="n">opt</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span>
</span><span id="BaseCLM-236"><a href="#BaseCLM-236"><span class="linenos">236</span></a>        <span class="n">config</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
</span><span id="BaseCLM-237"><a href="#BaseCLM-237"><span class="linenos">237</span></a>        <span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">opt</span><span class="o">.</span><span class="n">variables</span><span class="p">()]</span>
</span><span id="BaseCLM-238"><a href="#BaseCLM-238"><span class="linenos">238</span></a>        <span class="n">bytes_content</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">dumps</span><span class="p">((</span><span class="n">config</span><span class="p">,</span> <span class="n">weights</span><span class="p">))</span>
</span><span id="BaseCLM-239"><a href="#BaseCLM-239"><span class="linenos">239</span></a>        <span class="n">Path</span><span class="p">(</span><span class="n">path</span><span class="p">)</span><span class="o">.</span><span class="n">write_bytes</span><span class="p">(</span><span class="n">bytes_content</span><span class="p">)</span>
</span><span id="BaseCLM-240"><a href="#BaseCLM-240"><span class="linenos">240</span></a>
</span><span id="BaseCLM-241"><a href="#BaseCLM-241"><span class="linenos">241</span></a>    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">/</span><span class="p">,</span> <span class="n">training</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="BaseCLM-242"><a href="#BaseCLM-242"><span class="linenos">242</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Wrap the underlying TensorFlow model call.</span>
</span><span id="BaseCLM-243"><a href="#BaseCLM-243"><span class="linenos">243</span></a>
</span><span id="BaseCLM-244"><a href="#BaseCLM-244"><span class="linenos">244</span></a><span class="sd">        Args:</span>
</span><span id="BaseCLM-245"><a href="#BaseCLM-245"><span class="linenos">245</span></a><span class="sd">            inputs: Input sequence.</span>
</span><span id="BaseCLM-246"><a href="#BaseCLM-246"><span class="linenos">246</span></a><span class="sd">                If embedding: [Batch, Length] {int32}</span>
</span><span id="BaseCLM-247"><a href="#BaseCLM-247"><span class="linenos">247</span></a><span class="sd">                Else: [Batch, Length, Vocab] {float32}</span>
</span><span id="BaseCLM-248"><a href="#BaseCLM-248"><span class="linenos">248</span></a><span class="sd">            training: Whether in training mode. Defaults to False.</span>
</span><span id="BaseCLM-249"><a href="#BaseCLM-249"><span class="linenos">249</span></a>
</span><span id="BaseCLM-250"><a href="#BaseCLM-250"><span class="linenos">250</span></a><span class="sd">        Returns:</span>
</span><span id="BaseCLM-251"><a href="#BaseCLM-251"><span class="linenos">251</span></a><span class="sd">            Output sequence. [Batch, Length, Vocab] {float32}</span>
</span><span id="BaseCLM-252"><a href="#BaseCLM-252"><span class="linenos">252</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaseCLM-253"><a href="#BaseCLM-253"><span class="linenos">253</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
</span><span id="BaseCLM-254"><a href="#BaseCLM-254"><span class="linenos">254</span></a>
</span><span id="BaseCLM-255"><a href="#BaseCLM-255"><span class="linenos">255</span></a>    <span class="k">def</span> <span class="fm">__getattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
</span><span id="BaseCLM-256"><a href="#BaseCLM-256"><span class="linenos">256</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Get attribute from the underlying model.</span>
</span><span id="BaseCLM-257"><a href="#BaseCLM-257"><span class="linenos">257</span></a>
</span><span id="BaseCLM-258"><a href="#BaseCLM-258"><span class="linenos">258</span></a><span class="sd">        Example:</span>
</span><span id="BaseCLM-259"><a href="#BaseCLM-259"><span class="linenos">259</span></a><span class="sd">            &gt;&gt;&gt; clm = BaseCLM(...)</span>
</span><span id="BaseCLM-260"><a href="#BaseCLM-260"><span class="linenos">260</span></a><span class="sd">            &gt;&gt;&gt; lstm_clm.summary()</span>
</span><span id="BaseCLM-261"><a href="#BaseCLM-261"><span class="linenos">261</span></a><span class="sd">            # is equivalent to lstm_clm.model.summary()</span>
</span><span id="BaseCLM-262"><a href="#BaseCLM-262"><span class="linenos">262</span></a><span class="sd">            ...</span>
</span><span id="BaseCLM-263"><a href="#BaseCLM-263"><span class="linenos">263</span></a>
</span><span id="BaseCLM-264"><a href="#BaseCLM-264"><span class="linenos">264</span></a><span class="sd">        Args:</span>
</span><span id="BaseCLM-265"><a href="#BaseCLM-265"><span class="linenos">265</span></a><span class="sd">            key: Attribute name.</span>
</span><span id="BaseCLM-266"><a href="#BaseCLM-266"><span class="linenos">266</span></a>
</span><span id="BaseCLM-267"><a href="#BaseCLM-267"><span class="linenos">267</span></a><span class="sd">        Returns:</span>
</span><span id="BaseCLM-268"><a href="#BaseCLM-268"><span class="linenos">268</span></a><span class="sd">            Attribute value.</span>
</span><span id="BaseCLM-269"><a href="#BaseCLM-269"><span class="linenos">269</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaseCLM-270"><a href="#BaseCLM-270"><span class="linenos">270</span></a>        <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>
</span><span id="BaseCLM-271"><a href="#BaseCLM-271"><span class="linenos">271</span></a>
</span><span id="BaseCLM-272"><a href="#BaseCLM-272"><span class="linenos">272</span></a>    <span class="k">if</span> <span class="n">TYPE_CHECKING</span><span class="p">:</span>  <span class="c1"># pragma: no cover</span>
</span><span id="BaseCLM-273"><a href="#BaseCLM-273"><span class="linenos">273</span></a>        <span class="c1"># type hints some wrapped methods</span>
</span><span id="BaseCLM-274"><a href="#BaseCLM-274"><span class="linenos">274</span></a>        <span class="c1"># could be much longer - only the most used methods are included</span>
</span><span id="BaseCLM-275"><a href="#BaseCLM-275"><span class="linenos">275</span></a>
</span><span id="BaseCLM-276"><a href="#BaseCLM-276"><span class="linenos">276</span></a>        <span class="k">def</span> <span class="nf">load_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="n">StrPath</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="BaseCLM-277"><a href="#BaseCLM-277"><span class="linenos">277</span></a><span class="w">            </span><span class="sd">&quot;&quot;&quot;Load the model weights from a file.</span>
</span><span id="BaseCLM-278"><a href="#BaseCLM-278"><span class="linenos">278</span></a>
</span><span id="BaseCLM-279"><a href="#BaseCLM-279"><span class="linenos">279</span></a><span class="sd">            Args:</span>
</span><span id="BaseCLM-280"><a href="#BaseCLM-280"><span class="linenos">280</span></a><span class="sd">                path: Path to the file.</span>
</span><span id="BaseCLM-281"><a href="#BaseCLM-281"><span class="linenos">281</span></a><span class="sd">            &quot;&quot;&quot;</span>
</span><span id="BaseCLM-282"><a href="#BaseCLM-282"><span class="linenos">282</span></a>
</span><span id="BaseCLM-283"><a href="#BaseCLM-283"><span class="linenos">283</span></a>        <span class="k">def</span> <span class="nf">save_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="n">StrPath</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="BaseCLM-284"><a href="#BaseCLM-284"><span class="linenos">284</span></a><span class="w">            </span><span class="sd">&quot;&quot;&quot;Save the model weights to a file.</span>
</span><span id="BaseCLM-285"><a href="#BaseCLM-285"><span class="linenos">285</span></a>
</span><span id="BaseCLM-286"><a href="#BaseCLM-286"><span class="linenos">286</span></a><span class="sd">            Args:</span>
</span><span id="BaseCLM-287"><a href="#BaseCLM-287"><span class="linenos">287</span></a><span class="sd">                path: Path to the file.</span>
</span><span id="BaseCLM-288"><a href="#BaseCLM-288"><span class="linenos">288</span></a><span class="sd">            &quot;&quot;&quot;</span>
</span></pre></div>


            <div class="docstring"><p>Absolute base class for all CLM models.</p>

<p>Implements a default call per time step and a default sample function.
Compliance with the <code>GenModel</code> protocol.</p>

<h6 id="class-variables">Class variables:</h6>

<blockquote>
  <ul>
  <li>ASSERT_VOCAB (bool): Whether to assert that a vocabulary is provided.</li>
  </ul>
</blockquote>

<h6 id="attributes">Attributes:</h6>

<ul>
<li><strong>model (tf.keras.Model):</strong>  Model to wrap with LSTM layers.</li>
<li><strong>vocab (Vocabulary | None):</strong>  Vocabulary.</li>
<li><strong>vocab_size (int):</strong>  Size of vocabulary.</li>
<li><strong>seq_len (int):</strong>  Sequence length.</li>
<li><strong>dims (list[int]):</strong>  Number of neurons per LSTM layers.</li>
<li><strong>has_embedding (bool):</strong>  Whether the model has an Embedding layer.</li>
<li><strong>start_token (tf.Tensor):</strong>  Start token for generation.
If embedding: [1] {int32}
Else: [1, Vocab] {float32}</li>
</ul>
</div>


                            <div id="BaseCLM.__init__" class="classattr">
                                        <input id="BaseCLM.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">

        <span class="name">BaseCLM</span><span class="signature pdoc-code multiline">(<span class="param">  <span class="n">model</span><span class="p">:</span> <span class="n">keras</span><span class="o">.</span><span class="n">src</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">Model</span>,</span><span class="param"> <span class="n">max_len</span><span class="p">:</span> <span class="nb">int</span>,</span><span class="param">  <span class="n">start_index</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>,</span><span class="param">   <span class="n">seq_len_append</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>,</span><span class="param">    <span class="n">vocab</span><span class="p">:</span> <span class="n"><a href="vocab.html#VocabProto">lstm_clm.vocab.VocabProto</a></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span></span>)</span>

                <label class="view-source-button" for="BaseCLM.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BaseCLM.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BaseCLM.__init__-51"><a href="#BaseCLM.__init__-51"><span class="linenos"> 51</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="BaseCLM.__init__-52"><a href="#BaseCLM.__init__-52"><span class="linenos"> 52</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="BaseCLM.__init__-53"><a href="#BaseCLM.__init__-53"><span class="linenos"> 53</span></a>        <span class="n">model</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">,</span>
</span><span id="BaseCLM.__init__-54"><a href="#BaseCLM.__init__-54"><span class="linenos"> 54</span></a>        <span class="n">max_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="BaseCLM.__init__-55"><a href="#BaseCLM.__init__-55"><span class="linenos"> 55</span></a>        <span class="n">start_index</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="BaseCLM.__init__-56"><a href="#BaseCLM.__init__-56"><span class="linenos"> 56</span></a>        <span class="n">seq_len_append</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="BaseCLM.__init__-57"><a href="#BaseCLM.__init__-57"><span class="linenos"> 57</span></a>        <span class="n">vocab</span><span class="p">:</span> <span class="n">VocabProto</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="BaseCLM.__init__-58"><a href="#BaseCLM.__init__-58"><span class="linenos"> 58</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="BaseCLM.__init__-59"><a href="#BaseCLM.__init__-59"><span class="linenos"> 59</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize BaseCLM.</span>
</span><span id="BaseCLM.__init__-60"><a href="#BaseCLM.__init__-60"><span class="linenos"> 60</span></a>
</span><span id="BaseCLM.__init__-61"><a href="#BaseCLM.__init__-61"><span class="linenos"> 61</span></a><span class="sd">        The start index is the index of the BOS token in the vocabulary.</span>
</span><span id="BaseCLM.__init__-62"><a href="#BaseCLM.__init__-62"><span class="linenos"> 62</span></a><span class="sd">        The sequence length append is 1 if the EOS token is present, else 0.</span>
</span><span id="BaseCLM.__init__-63"><a href="#BaseCLM.__init__-63"><span class="linenos"> 63</span></a><span class="sd">        The values are extracted from the vocabulary, if provided.</span>
</span><span id="BaseCLM.__init__-64"><a href="#BaseCLM.__init__-64"><span class="linenos"> 64</span></a>
</span><span id="BaseCLM.__init__-65"><a href="#BaseCLM.__init__-65"><span class="linenos"> 65</span></a><span class="sd">        Args:</span>
</span><span id="BaseCLM.__init__-66"><a href="#BaseCLM.__init__-66"><span class="linenos"> 66</span></a><span class="sd">            model: Model to wrap with LSTM layers.</span>
</span><span id="BaseCLM.__init__-67"><a href="#BaseCLM.__init__-67"><span class="linenos"> 67</span></a><span class="sd">            max_len: Maximum length of generated samples.</span>
</span><span id="BaseCLM.__init__-68"><a href="#BaseCLM.__init__-68"><span class="linenos"> 68</span></a><span class="sd">            start_index: Index of the start token. Defaults to 1.</span>
</span><span id="BaseCLM.__init__-69"><a href="#BaseCLM.__init__-69"><span class="linenos"> 69</span></a><span class="sd">            seq_len_append: Additional sequence length for EOS token. Defaults to 1.</span>
</span><span id="BaseCLM.__init__-70"><a href="#BaseCLM.__init__-70"><span class="linenos"> 70</span></a><span class="sd">            vocab: Vocabulary. Defaults to None.</span>
</span><span id="BaseCLM.__init__-71"><a href="#BaseCLM.__init__-71"><span class="linenos"> 71</span></a>
</span><span id="BaseCLM.__init__-72"><a href="#BaseCLM.__init__-72"><span class="linenos"> 72</span></a><span class="sd">        Raises:</span>
</span><span id="BaseCLM.__init__-73"><a href="#BaseCLM.__init__-73"><span class="linenos"> 73</span></a><span class="sd">            ValueError: If vocabulary does not match provided lengths.</span>
</span><span id="BaseCLM.__init__-74"><a href="#BaseCLM.__init__-74"><span class="linenos"> 74</span></a><span class="sd">            ValueError: If `ASSERT_VOCAB` is True and no vocabulary is provided.</span>
</span><span id="BaseCLM.__init__-75"><a href="#BaseCLM.__init__-75"><span class="linenos"> 75</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaseCLM.__init__-76"><a href="#BaseCLM.__init__-76"><span class="linenos"> 76</span></a>        <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</span><span id="BaseCLM.__init__-77"><a href="#BaseCLM.__init__-77"><span class="linenos"> 77</span></a>
</span><span id="BaseCLM.__init__-78"><a href="#BaseCLM.__init__-78"><span class="linenos"> 78</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ASSERT_VOCAB</span> <span class="ow">and</span> <span class="n">vocab</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="BaseCLM.__init__-79"><a href="#BaseCLM.__init__-79"><span class="linenos"> 79</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Vocabulary is required for this model&quot;</span><span class="p">)</span>
</span><span id="BaseCLM.__init__-80"><a href="#BaseCLM.__init__-80"><span class="linenos"> 80</span></a>
</span><span id="BaseCLM.__init__-81"><a href="#BaseCLM.__init__-81"><span class="linenos"> 81</span></a>        <span class="k">if</span> <span class="n">max_len</span> <span class="o">&gt;</span> <span class="n">MAX_LEN_BOUNDARY</span><span class="p">:</span>  <span class="c1"># pragma: no cover # TODO: Remove this</span>
</span><span id="BaseCLM.__init__-82"><a href="#BaseCLM.__init__-82"><span class="linenos"> 82</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;max_len should be less than 150&quot;</span><span class="p">)</span>
</span><span id="BaseCLM.__init__-83"><a href="#BaseCLM.__init__-83"><span class="linenos"> 83</span></a>
</span><span id="BaseCLM.__init__-84"><a href="#BaseCLM.__init__-84"><span class="linenos"> 84</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
</span><span id="BaseCLM.__init__-85"><a href="#BaseCLM.__init__-85"><span class="linenos"> 85</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;@private&quot;&quot;&quot;</span>
</span><span id="BaseCLM.__init__-86"><a href="#BaseCLM.__init__-86"><span class="linenos"> 86</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span> <span class="o">=</span> <span class="n">vocab</span>
</span><span id="BaseCLM.__init__-87"><a href="#BaseCLM.__init__-87"><span class="linenos"> 87</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;@private&quot;&quot;&quot;</span>
</span><span id="BaseCLM.__init__-88"><a href="#BaseCLM.__init__-88"><span class="linenos"> 88</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span> <span class="o">=</span> <span class="n">max_len</span> <span class="o">+</span> <span class="n">seq_len_append</span>
</span><span id="BaseCLM.__init__-89"><a href="#BaseCLM.__init__-89"><span class="linenos"> 89</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;@private&quot;&quot;&quot;</span>
</span><span id="BaseCLM.__init__-90"><a href="#BaseCLM.__init__-90"><span class="linenos"> 90</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">output_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="BaseCLM.__init__-91"><a href="#BaseCLM.__init__-91"><span class="linenos"> 91</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;@private&quot;&quot;&quot;</span>
</span><span id="BaseCLM.__init__-92"><a href="#BaseCLM.__init__-92"><span class="linenos"> 92</span></a>
</span><span id="BaseCLM.__init__-93"><a href="#BaseCLM.__init__-93"><span class="linenos"> 93</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_vocab</span><span class="p">(</span><span class="n">max_len</span><span class="p">,</span> <span class="n">start_index</span><span class="p">,</span> <span class="n">seq_len_append</span><span class="p">)</span>
</span><span id="BaseCLM.__init__-94"><a href="#BaseCLM.__init__-94"><span class="linenos"> 94</span></a>
</span><span id="BaseCLM.__init__-95"><a href="#BaseCLM.__init__-95"><span class="linenos"> 95</span></a>        <span class="c1"># Get number of neurons in LSTM layers, used for initializing hidden states</span>
</span><span id="BaseCLM.__init__-96"><a href="#BaseCLM.__init__-96"><span class="linenos"> 96</span></a>        <span class="n">lstm_layers</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="BaseCLM.__init__-97"><a href="#BaseCLM.__init__-97"><span class="linenos"> 97</span></a>            <span class="n">layer</span>
</span><span id="BaseCLM.__init__-98"><a href="#BaseCLM.__init__-98"><span class="linenos"> 98</span></a>            <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span>
</span><span id="BaseCLM.__init__-99"><a href="#BaseCLM.__init__-99"><span class="linenos"> 99</span></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">)</span>
</span><span id="BaseCLM.__init__-100"><a href="#BaseCLM.__init__-100"><span class="linenos">100</span></a>        <span class="p">]</span>
</span><span id="BaseCLM.__init__-101"><a href="#BaseCLM.__init__-101"><span class="linenos">101</span></a>
</span><span id="BaseCLM.__init__-102"><a href="#BaseCLM.__init__-102"><span class="linenos">102</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">dims</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">layer</span><span class="o">.</span><span class="n">units</span> <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">lstm_layers</span><span class="p">]</span>
</span><span id="BaseCLM.__init__-103"><a href="#BaseCLM.__init__-103"><span class="linenos">103</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;@private&quot;&quot;&quot;</span>
</span><span id="BaseCLM.__init__-104"><a href="#BaseCLM.__init__-104"><span class="linenos">104</span></a>
</span><span id="BaseCLM.__init__-105"><a href="#BaseCLM.__init__-105"><span class="linenos">105</span></a>        <span class="c1"># Check if model has Embedding layer</span>
</span><span id="BaseCLM.__init__-106"><a href="#BaseCLM.__init__-106"><span class="linenos">106</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">has_embedding</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span>
</span><span id="BaseCLM.__init__-107"><a href="#BaseCLM.__init__-107"><span class="linenos">107</span></a>            <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">)</span> <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span>
</span><span id="BaseCLM.__init__-108"><a href="#BaseCLM.__init__-108"><span class="linenos">108</span></a>        <span class="p">)</span>
</span><span id="BaseCLM.__init__-109"><a href="#BaseCLM.__init__-109"><span class="linenos">109</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;@private&quot;&quot;&quot;</span>
</span><span id="BaseCLM.__init__-110"><a href="#BaseCLM.__init__-110"><span class="linenos">110</span></a>
</span><span id="BaseCLM.__init__-111"><a href="#BaseCLM.__init__-111"><span class="linenos">111</span></a>        <span class="n">start_token_emb</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="n">start_index</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>  <span class="c1"># [1] {int32}</span>
</span><span id="BaseCLM.__init__-112"><a href="#BaseCLM.__init__-112"><span class="linenos">112</span></a>        <span class="n">start_token_one_hot</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span>
</span><span id="BaseCLM.__init__-113"><a href="#BaseCLM.__init__-113"><span class="linenos">113</span></a>            <span class="n">start_token_emb</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">output_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="BaseCLM.__init__-114"><a href="#BaseCLM.__init__-114"><span class="linenos">114</span></a>        <span class="p">)</span>  <span class="c1"># [1, Vocab] {float32}</span>
</span><span id="BaseCLM.__init__-115"><a href="#BaseCLM.__init__-115"><span class="linenos">115</span></a>
</span><span id="BaseCLM.__init__-116"><a href="#BaseCLM.__init__-116"><span class="linenos">116</span></a>        <span class="c1"># One-hot encode start tokens if model has no Embedding layer</span>
</span><span id="BaseCLM.__init__-117"><a href="#BaseCLM.__init__-117"><span class="linenos">117</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">start_token</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="BaseCLM.__init__-118"><a href="#BaseCLM.__init__-118"><span class="linenos">118</span></a>            <span class="n">start_token_emb</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_embedding</span> <span class="k">else</span> <span class="n">start_token_one_hot</span>
</span><span id="BaseCLM.__init__-119"><a href="#BaseCLM.__init__-119"><span class="linenos">119</span></a>        <span class="p">)</span>
</span><span id="BaseCLM.__init__-120"><a href="#BaseCLM.__init__-120"><span class="linenos">120</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;@private&quot;&quot;&quot;</span>
</span></pre></div>


            <div class="docstring"><p>Initialize BaseCLM.</p>

<p>The start index is the index of the BOS token in the vocabulary.
The sequence length append is 1 if the EOS token is present, else 0.
The values are extracted from the vocabulary, if provided.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>model:</strong>  Model to wrap with LSTM layers.</li>
<li><strong>max_len:</strong>  Maximum length of generated samples.</li>
<li><strong>start_index:</strong>  Index of the start token. Defaults to 1.</li>
<li><strong>seq_len_append:</strong>  Additional sequence length for EOS token. Defaults to 1.</li>
<li><strong>vocab:</strong>  Vocabulary. Defaults to None.</li>
</ul>

<h6 id="raises">Raises:</h6>

<ul>
<li><strong>ValueError:</strong>  If vocabulary does not match provided lengths.</li>
<li><strong>ValueError:</strong>  If <code>ASSERT_VOCAB</code> is True and no vocabulary is provided.</li>
</ul>
</div>


                            </div>
                            <div id="BaseCLM.from_vocab" class="classattr">
                                        <input id="BaseCLM.from_vocab-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-classmethod">@classmethod</div>

        <span class="def">def</span>
        <span class="name">from_vocab</span><span class="signature pdoc-code multiline">(<span class="param">   <span class="bp">cls</span>,</span><span class="param"> <span class="n">model</span><span class="p">:</span> <span class="n">keras</span><span class="o">.</span><span class="n">src</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">Model</span>,</span><span class="param"> <span class="n">vocab</span><span class="p">:</span> <span class="n"><a href="vocab.html#VocabProto">lstm_clm.vocab.VocabProto</a></span></span><span class="return-annotation">) -> <span class="n">typing_extensions</span><span class="o">.</span><span class="n">Self</span>:</span></span>

                <label class="view-source-button" for="BaseCLM.from_vocab-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BaseCLM.from_vocab"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BaseCLM.from_vocab-148"><a href="#BaseCLM.from_vocab-148"><span class="linenos">148</span></a>    <span class="nd">@classmethod</span>
</span><span id="BaseCLM.from_vocab-149"><a href="#BaseCLM.from_vocab-149"><span class="linenos">149</span></a>    <span class="k">def</span> <span class="nf">from_vocab</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">,</span> <span class="n">vocab</span><span class="p">:</span> <span class="n">VocabProto</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Self</span><span class="p">:</span>
</span><span id="BaseCLM.from_vocab-150"><a href="#BaseCLM.from_vocab-150"><span class="linenos">150</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize :class:`BaseCLM` from a vocabulary.</span>
</span><span id="BaseCLM.from_vocab-151"><a href="#BaseCLM.from_vocab-151"><span class="linenos">151</span></a>
</span><span id="BaseCLM.from_vocab-152"><a href="#BaseCLM.from_vocab-152"><span class="linenos">152</span></a><span class="sd">        Args:</span>
</span><span id="BaseCLM.from_vocab-153"><a href="#BaseCLM.from_vocab-153"><span class="linenos">153</span></a><span class="sd">            model: Model to wrap with LSTM layers.</span>
</span><span id="BaseCLM.from_vocab-154"><a href="#BaseCLM.from_vocab-154"><span class="linenos">154</span></a><span class="sd">            vocab: Vocabulary.</span>
</span><span id="BaseCLM.from_vocab-155"><a href="#BaseCLM.from_vocab-155"><span class="linenos">155</span></a>
</span><span id="BaseCLM.from_vocab-156"><a href="#BaseCLM.from_vocab-156"><span class="linenos">156</span></a><span class="sd">        Returns:</span>
</span><span id="BaseCLM.from_vocab-157"><a href="#BaseCLM.from_vocab-157"><span class="linenos">157</span></a><span class="sd">            :class:`BaseCLM` instance.</span>
</span><span id="BaseCLM.from_vocab-158"><a href="#BaseCLM.from_vocab-158"><span class="linenos">158</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaseCLM.from_vocab-159"><a href="#BaseCLM.from_vocab-159"><span class="linenos">159</span></a>        <span class="n">_</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">start_index</span><span class="p">,</span> <span class="n">seq_len_append</span> <span class="o">=</span> <span class="n">get_data_from_vocab</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span>
</span><span id="BaseCLM.from_vocab-160"><a href="#BaseCLM.from_vocab-160"><span class="linenos">160</span></a>        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">start_index</span><span class="p">,</span> <span class="n">seq_len_append</span><span class="p">,</span> <span class="n">vocab</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Initialize <code><a href="#BaseCLM">BaseCLM</a></code> from a vocabulary.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>model:</strong>  Model to wrap with LSTM layers.</li>
<li><strong>vocab:</strong>  Vocabulary.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p><code><a href="#BaseCLM">BaseCLM</a></code> instance.</p>
</blockquote>
</div>


                            </div>
                            <div id="BaseCLM.call_cell" class="classattr">
                                        <input id="BaseCLM.call_cell-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">

        <span class="def">def</span>
        <span class="name">call_cell</span><span class="signature pdoc-code multiline">(<span class="param">    <span class="bp">self</span>,</span><span class="param">    <span class="n">x_t</span><span class="p">:</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span>,</span><span class="param">    <span class="n">hidden_states</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span>,</span><span class="param">   <span class="o">/</span>,</span><span class="param">    <span class="n">training</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span></span><span class="return-annotation">) -> <span class="nb">tuple</span><span class="p">[</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span> <span class="kc">None</span><span class="p">]</span>:</span></span>

                <label class="view-source-button" for="BaseCLM.call_cell-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BaseCLM.call_cell"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BaseCLM.call_cell-162"><a href="#BaseCLM.call_cell-162"><span class="linenos">162</span></a>    <span class="k">def</span> <span class="nf">call_cell</span><span class="p">(</span>
</span><span id="BaseCLM.call_cell-163"><a href="#BaseCLM.call_cell-163"><span class="linenos">163</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="BaseCLM.call_cell-164"><a href="#BaseCLM.call_cell-164"><span class="linenos">164</span></a>        <span class="n">x_t</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="BaseCLM.call_cell-165"><a href="#BaseCLM.call_cell-165"><span class="linenos">165</span></a>        <span class="n">hidden_states</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span>
</span><span id="BaseCLM.call_cell-166"><a href="#BaseCLM.call_cell-166"><span class="linenos">166</span></a>        <span class="o">/</span><span class="p">,</span>
</span><span id="BaseCLM.call_cell-167"><a href="#BaseCLM.call_cell-167"><span class="linenos">167</span></a>        <span class="n">training</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="BaseCLM.call_cell-168"><a href="#BaseCLM.call_cell-168"><span class="linenos">168</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span> <span class="kc">None</span><span class="p">]:</span>
</span><span id="BaseCLM.call_cell-169"><a href="#BaseCLM.call_cell-169"><span class="linenos">169</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Call the model for one time step.</span>
</span><span id="BaseCLM.call_cell-170"><a href="#BaseCLM.call_cell-170"><span class="linenos">170</span></a>
</span><span id="BaseCLM.call_cell-171"><a href="#BaseCLM.call_cell-171"><span class="linenos">171</span></a><span class="sd">        Args:</span>
</span><span id="BaseCLM.call_cell-172"><a href="#BaseCLM.call_cell-172"><span class="linenos">172</span></a><span class="sd">            x_t: Input at time step t.</span>
</span><span id="BaseCLM.call_cell-173"><a href="#BaseCLM.call_cell-173"><span class="linenos">173</span></a><span class="sd">                If embedding: [Batch] {int32}</span>
</span><span id="BaseCLM.call_cell-174"><a href="#BaseCLM.call_cell-174"><span class="linenos">174</span></a><span class="sd">                Else: [Batch, Vocab] {float32}</span>
</span><span id="BaseCLM.call_cell-175"><a href="#BaseCLM.call_cell-175"><span class="linenos">175</span></a><span class="sd">            hidden_states: LSTM layers&#39; hidden states.</span>
</span><span id="BaseCLM.call_cell-176"><a href="#BaseCLM.call_cell-176"><span class="linenos">176</span></a><span class="sd">                [2 x [Batch, Hidden] {float32}, ...]</span>
</span><span id="BaseCLM.call_cell-177"><a href="#BaseCLM.call_cell-177"><span class="linenos">177</span></a><span class="sd">            training: Whether in training mode. Defaults to False.</span>
</span><span id="BaseCLM.call_cell-178"><a href="#BaseCLM.call_cell-178"><span class="linenos">178</span></a>
</span><span id="BaseCLM.call_cell-179"><a href="#BaseCLM.call_cell-179"><span class="linenos">179</span></a><span class="sd">        Returns:</span>
</span><span id="BaseCLM.call_cell-180"><a href="#BaseCLM.call_cell-180"><span class="linenos">180</span></a><span class="sd">            tuple[tf.Tensor, list[list[tf.Tensor]], None]:</span>
</span><span id="BaseCLM.call_cell-181"><a href="#BaseCLM.call_cell-181"><span class="linenos">181</span></a><span class="sd">                output: Time step t output. [Batch, Vocab] {float32}</span>
</span><span id="BaseCLM.call_cell-182"><a href="#BaseCLM.call_cell-182"><span class="linenos">182</span></a><span class="sd">                states: LSTM layers&#39; output states. [2 x [Batch, Hidden] {float32}, ...]</span>
</span><span id="BaseCLM.call_cell-183"><a href="#BaseCLM.call_cell-183"><span class="linenos">183</span></a><span class="sd">                info: Always None.</span>
</span><span id="BaseCLM.call_cell-184"><a href="#BaseCLM.call_cell-184"><span class="linenos">184</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaseCLM.call_cell-185"><a href="#BaseCLM.call_cell-185"><span class="linenos">185</span></a>        <span class="k">return</span> <span class="n">lstm_model_call</span><span class="p">(</span>
</span><span id="BaseCLM.call_cell-186"><a href="#BaseCLM.call_cell-186"><span class="linenos">186</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dims</span><span class="p">,</span> <span class="n">x_t</span><span class="p">,</span> <span class="n">hidden_states</span><span class="p">,</span> <span class="n">training</span>
</span><span id="BaseCLM.call_cell-187"><a href="#BaseCLM.call_cell-187"><span class="linenos">187</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Call the model for one time step.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>x_t:</strong>  Input at time step t.
If embedding: [Batch] {int32}
Else: [Batch, Vocab] {float32}</li>
<li><strong>hidden_states:</strong>  LSTM layers' hidden states.
[2 x [Batch, Hidden] {float32}, ...]</li>
<li><strong>training:</strong>  Whether in training mode. Defaults to False.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>tuple[tf.Tensor, list[list[tf.Tensor]], None]:
      output: Time step t output. [Batch, Vocab] {float32}
      states: LSTM layers' output states. [2 x [Batch, Hidden] {float32}, ...]
      info: Always None.</p>
</blockquote>
</div>


                            </div>
                            <div id="BaseCLM.load_optim" class="classattr">
                                        <input id="BaseCLM.load_optim-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">

        <span class="def">def</span>
        <span class="name">load_optim</span><span class="signature pdoc-code multiline">(<span class="param">   <span class="bp">self</span>,</span><span class="param">    <span class="n">path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>,</span><span class="param">    <span class="n">loss</span><span class="p">:</span> <span class="n">keras</span><span class="o">.</span><span class="n">src</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">Loss</span> <span class="o">|</span> <span class="nb">str</span>,</span><span class="param"> <span class="n">shape</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span></span><span class="return-annotation">) -> <span class="kc">None</span>:</span></span>

                <label class="view-source-button" for="BaseCLM.load_optim-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BaseCLM.load_optim"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BaseCLM.load_optim-189"><a href="#BaseCLM.load_optim-189"><span class="linenos">189</span></a>    <span class="k">def</span> <span class="nf">load_optim</span><span class="p">(</span>
</span><span id="BaseCLM.load_optim-190"><a href="#BaseCLM.load_optim-190"><span class="linenos">190</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="n">StrPath</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">Loss</span> <span class="o">|</span> <span class="nb">str</span><span class="p">,</span> <span class="n">shape</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
</span><span id="BaseCLM.load_optim-191"><a href="#BaseCLM.load_optim-191"><span class="linenos">191</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="BaseCLM.load_optim-192"><a href="#BaseCLM.load_optim-192"><span class="linenos">192</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Load optimizer from a file and compile the model.</span>
</span><span id="BaseCLM.load_optim-193"><a href="#BaseCLM.load_optim-193"><span class="linenos">193</span></a>
</span><span id="BaseCLM.load_optim-194"><a href="#BaseCLM.load_optim-194"><span class="linenos">194</span></a><span class="sd">        Important:</span>
</span><span id="BaseCLM.load_optim-195"><a href="#BaseCLM.load_optim-195"><span class="linenos">195</span></a><span class="sd">            If batch normalization should be freezed,</span>
</span><span id="BaseCLM.load_optim-196"><a href="#BaseCLM.load_optim-196"><span class="linenos">196</span></a><span class="sd">            use it before saving or loading the optimizer.</span>
</span><span id="BaseCLM.load_optim-197"><a href="#BaseCLM.load_optim-197"><span class="linenos">197</span></a>
</span><span id="BaseCLM.load_optim-198"><a href="#BaseCLM.load_optim-198"><span class="linenos">198</span></a><span class="sd">        Args:</span>
</span><span id="BaseCLM.load_optim-199"><a href="#BaseCLM.load_optim-199"><span class="linenos">199</span></a><span class="sd">            path: Path to the file.</span>
</span><span id="BaseCLM.load_optim-200"><a href="#BaseCLM.load_optim-200"><span class="linenos">200</span></a><span class="sd">            loss: Loss function.</span>
</span><span id="BaseCLM.load_optim-201"><a href="#BaseCLM.load_optim-201"><span class="linenos">201</span></a><span class="sd">            shape: Shape of the in- and output of the model.</span>
</span><span id="BaseCLM.load_optim-202"><a href="#BaseCLM.load_optim-202"><span class="linenos">202</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaseCLM.load_optim-203"><a href="#BaseCLM.load_optim-203"><span class="linenos">203</span></a>        <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</span><span id="BaseCLM.load_optim-204"><a href="#BaseCLM.load_optim-204"><span class="linenos">204</span></a>
</span><span id="BaseCLM.load_optim-205"><a href="#BaseCLM.load_optim-205"><span class="linenos">205</span></a>        <span class="n">bytes_content</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">path</span><span class="p">)</span><span class="o">.</span><span class="n">read_bytes</span><span class="p">()</span>
</span><span id="BaseCLM.load_optim-206"><a href="#BaseCLM.load_optim-206"><span class="linenos">206</span></a>        <span class="n">data</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="nb">list</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">bytes_content</span><span class="p">)</span>
</span><span id="BaseCLM.load_optim-207"><a href="#BaseCLM.load_optim-207"><span class="linenos">207</span></a>        <span class="n">config</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">data</span>
</span><span id="BaseCLM.load_optim-208"><a href="#BaseCLM.load_optim-208"><span class="linenos">208</span></a>
</span><span id="BaseCLM.load_optim-209"><a href="#BaseCLM.load_optim-209"><span class="linenos">209</span></a>        <span class="n">opt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="BaseCLM.load_optim-210"><a href="#BaseCLM.load_optim-210"><span class="linenos">210</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">)</span>
</span><span id="BaseCLM.load_optim-211"><a href="#BaseCLM.load_optim-211"><span class="linenos">211</span></a>
</span><span id="BaseCLM.load_optim-212"><a href="#BaseCLM.load_optim-212"><span class="linenos">212</span></a>        <span class="c1"># fit to initialize variables</span>
</span><span id="BaseCLM.load_optim-213"><a href="#BaseCLM.load_optim-213"><span class="linenos">213</span></a>        <span class="n">prev_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>
</span><span id="BaseCLM.load_optim-214"><a href="#BaseCLM.load_optim-214"><span class="linenos">214</span></a>        <span class="n">test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">shape</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="BaseCLM.load_optim-215"><a href="#BaseCLM.load_optim-215"><span class="linenos">215</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="BaseCLM.load_optim-216"><a href="#BaseCLM.load_optim-216"><span class="linenos">216</span></a>        <span class="c1"># reset weights</span>
</span><span id="BaseCLM.load_optim-217"><a href="#BaseCLM.load_optim-217"><span class="linenos">217</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">prev_weights</span><span class="p">)</span>
</span><span id="BaseCLM.load_optim-218"><a href="#BaseCLM.load_optim-218"><span class="linenos">218</span></a>
</span><span id="BaseCLM.load_optim-219"><a href="#BaseCLM.load_optim-219"><span class="linenos">219</span></a>        <span class="c1"># set optimizer weights</span>
</span><span id="BaseCLM.load_optim-220"><a href="#BaseCLM.load_optim-220"><span class="linenos">220</span></a>        <span class="n">opt</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
</span><span id="BaseCLM.load_optim-221"><a href="#BaseCLM.load_optim-221"><span class="linenos">221</span></a>
</span><span id="BaseCLM.load_optim-222"><a href="#BaseCLM.load_optim-222"><span class="linenos">222</span></a>        <span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">variables</span><span class="p">(),</span> <span class="n">weights</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
</span><span id="BaseCLM.load_optim-223"><a href="#BaseCLM.load_optim-223"><span class="linenos">223</span></a>            <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">b</span><span class="p">):</span>
</span><span id="BaseCLM.load_optim-224"><a href="#BaseCLM.load_optim-224"><span class="linenos">224</span></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Optimizer weights do not match&quot;</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Load optimizer from a file and compile the model.</p>

<h6 id="important">Important:</h6>

<blockquote>
  <p>If batch normalization should be freezed,
  use it before saving or loading the optimizer.</p>
</blockquote>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>path:</strong>  Path to the file.</li>
<li><strong>loss:</strong>  Loss function.</li>
<li><strong>shape:</strong>  Shape of the in- and output of the model.</li>
</ul>
</div>


                            </div>
                            <div id="BaseCLM.save_optim" class="classattr">
                                        <input id="BaseCLM.save_optim-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">

        <span class="def">def</span>
        <span class="name">save_optim</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span></span><span class="return-annotation">) -> <span class="kc">None</span>:</span></span>

                <label class="view-source-button" for="BaseCLM.save_optim-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#BaseCLM.save_optim"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="BaseCLM.save_optim-226"><a href="#BaseCLM.save_optim-226"><span class="linenos">226</span></a>    <span class="k">def</span> <span class="nf">save_optim</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="n">StrPath</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="BaseCLM.save_optim-227"><a href="#BaseCLM.save_optim-227"><span class="linenos">227</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Save optimizer to a file.</span>
</span><span id="BaseCLM.save_optim-228"><a href="#BaseCLM.save_optim-228"><span class="linenos">228</span></a>
</span><span id="BaseCLM.save_optim-229"><a href="#BaseCLM.save_optim-229"><span class="linenos">229</span></a><span class="sd">        Important:</span>
</span><span id="BaseCLM.save_optim-230"><a href="#BaseCLM.save_optim-230"><span class="linenos">230</span></a><span class="sd">            use `freeze_batch_norm` before saving or loading the optimizer.</span>
</span><span id="BaseCLM.save_optim-231"><a href="#BaseCLM.save_optim-231"><span class="linenos">231</span></a>
</span><span id="BaseCLM.save_optim-232"><a href="#BaseCLM.save_optim-232"><span class="linenos">232</span></a><span class="sd">        Args:</span>
</span><span id="BaseCLM.save_optim-233"><a href="#BaseCLM.save_optim-233"><span class="linenos">233</span></a><span class="sd">            path: Path to the file.</span>
</span><span id="BaseCLM.save_optim-234"><a href="#BaseCLM.save_optim-234"><span class="linenos">234</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="BaseCLM.save_optim-235"><a href="#BaseCLM.save_optim-235"><span class="linenos">235</span></a>        <span class="n">opt</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span>
</span><span id="BaseCLM.save_optim-236"><a href="#BaseCLM.save_optim-236"><span class="linenos">236</span></a>        <span class="n">config</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
</span><span id="BaseCLM.save_optim-237"><a href="#BaseCLM.save_optim-237"><span class="linenos">237</span></a>        <span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">opt</span><span class="o">.</span><span class="n">variables</span><span class="p">()]</span>
</span><span id="BaseCLM.save_optim-238"><a href="#BaseCLM.save_optim-238"><span class="linenos">238</span></a>        <span class="n">bytes_content</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">dumps</span><span class="p">((</span><span class="n">config</span><span class="p">,</span> <span class="n">weights</span><span class="p">))</span>
</span><span id="BaseCLM.save_optim-239"><a href="#BaseCLM.save_optim-239"><span class="linenos">239</span></a>        <span class="n">Path</span><span class="p">(</span><span class="n">path</span><span class="p">)</span><span class="o">.</span><span class="n">write_bytes</span><span class="p">(</span><span class="n">bytes_content</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Save optimizer to a file.</p>

<h6 id="important">Important:</h6>

<blockquote>
  <p>use <code>freeze_batch_norm</code> before saving or loading the optimizer.</p>
</blockquote>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>path:</strong>  Path to the file.</li>
</ul>
</div>


                            </div>
                </section>
                <section id="MultinomialCLM">
                            <input id="MultinomialCLM-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">

    <span class="def">class</span>
    <span class="name">MultinomialCLM</span><wbr>(<span class="base"><a href="#BaseCLM">lstm_clm.clm.BaseCLM</a></span>):

                <label class="view-source-button" for="MultinomialCLM-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#MultinomialCLM"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="MultinomialCLM-28"><a href="#MultinomialCLM-28"><span class="linenos"> 28</span></a><span class="k">class</span> <span class="nc">MultinomialCLM</span><span class="p">(</span><span class="n">BaseCLM</span><span class="p">):</span>
</span><span id="MultinomialCLM-29"><a href="#MultinomialCLM-29"><span class="linenos"> 29</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Base class for models generating samples with multinomial sampling.</span>
</span><span id="MultinomialCLM-30"><a href="#MultinomialCLM-30"><span class="linenos"> 30</span></a>
</span><span id="MultinomialCLM-31"><a href="#MultinomialCLM-31"><span class="linenos"> 31</span></a><span class="sd">    Attributes:</span>
</span><span id="MultinomialCLM-32"><a href="#MultinomialCLM-32"><span class="linenos"> 32</span></a><span class="sd">        model (tf.keras.Model): Model to wrap with LSTM layers.</span>
</span><span id="MultinomialCLM-33"><a href="#MultinomialCLM-33"><span class="linenos"> 33</span></a><span class="sd">        vocab (Vocabulary | None): Vocabulary.</span>
</span><span id="MultinomialCLM-34"><a href="#MultinomialCLM-34"><span class="linenos"> 34</span></a><span class="sd">        seq_len (int): Sequence length.</span>
</span><span id="MultinomialCLM-35"><a href="#MultinomialCLM-35"><span class="linenos"> 35</span></a><span class="sd">        dims (list[int]): Number of neurons per LSTM layers.</span>
</span><span id="MultinomialCLM-36"><a href="#MultinomialCLM-36"><span class="linenos"> 36</span></a><span class="sd">        has_embedding (bool): Whether the model has an Embedding layer.</span>
</span><span id="MultinomialCLM-37"><a href="#MultinomialCLM-37"><span class="linenos"> 37</span></a><span class="sd">        start_token (tf.Tensor): Start token for generation.</span>
</span><span id="MultinomialCLM-38"><a href="#MultinomialCLM-38"><span class="linenos"> 38</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="MultinomialCLM-39"><a href="#MultinomialCLM-39"><span class="linenos"> 39</span></a>
</span><span id="MultinomialCLM-40"><a href="#MultinomialCLM-40"><span class="linenos"> 40</span></a>    <span class="nd">@tf_func_wrapper</span>
</span><span id="MultinomialCLM-41"><a href="#MultinomialCLM-41"><span class="linenos"> 41</span></a>    <span class="k">def</span> <span class="nf">generate</span><span class="p">(</span>
</span><span id="MultinomialCLM-42"><a href="#MultinomialCLM-42"><span class="linenos"> 42</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="MultinomialCLM-43"><a href="#MultinomialCLM-43"><span class="linenos"> 43</span></a>        <span class="n">n_batches</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="MultinomialCLM-44"><a href="#MultinomialCLM-44"><span class="linenos"> 44</span></a>        <span class="n">temp</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
</span><span id="MultinomialCLM-45"><a href="#MultinomialCLM-45"><span class="linenos"> 45</span></a>        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span>
</span><span id="MultinomialCLM-46"><a href="#MultinomialCLM-46"><span class="linenos"> 46</span></a>        <span class="n">call_func</span><span class="p">:</span> <span class="n">CallFunc</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="MultinomialCLM-47"><a href="#MultinomialCLM-47"><span class="linenos"> 47</span></a>        <span class="n">sample_func</span><span class="p">:</span> <span class="n">SampleFunc</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="MultinomialCLM-48"><a href="#MultinomialCLM-48"><span class="linenos"> 48</span></a>        <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="MultinomialCLM-49"><a href="#MultinomialCLM-49"><span class="linenos"> 49</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
</span><span id="MultinomialCLM-50"><a href="#MultinomialCLM-50"><span class="linenos"> 50</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate multiple batches of samples (wrapped in a tf.function).</span>
</span><span id="MultinomialCLM-51"><a href="#MultinomialCLM-51"><span class="linenos"> 51</span></a>
</span><span id="MultinomialCLM-52"><a href="#MultinomialCLM-52"><span class="linenos"> 52</span></a><span class="sd">        Args:</span>
</span><span id="MultinomialCLM-53"><a href="#MultinomialCLM-53"><span class="linenos"> 53</span></a><span class="sd">            n_batches: Number of batches to generate.</span>
</span><span id="MultinomialCLM-54"><a href="#MultinomialCLM-54"><span class="linenos"> 54</span></a><span class="sd">            temp: Temperature factor. Defaults to 1.0.</span>
</span><span id="MultinomialCLM-55"><a href="#MultinomialCLM-55"><span class="linenos"> 55</span></a><span class="sd">            batch_size: Batch size for generation. Defaults to 1024.</span>
</span><span id="MultinomialCLM-56"><a href="#MultinomialCLM-56"><span class="linenos"> 56</span></a><span class="sd">            call_func: Function to call model for one time step.</span>
</span><span id="MultinomialCLM-57"><a href="#MultinomialCLM-57"><span class="linenos"> 57</span></a><span class="sd">                Defaults to instance&#39;s `call_cell` method.</span>
</span><span id="MultinomialCLM-58"><a href="#MultinomialCLM-58"><span class="linenos"> 58</span></a><span class="sd">            sample_func: Function to sample next tokens.</span>
</span><span id="MultinomialCLM-59"><a href="#MultinomialCLM-59"><span class="linenos"> 59</span></a><span class="sd">                Defaults to instance&#39;s `sample_next_tokens` method.</span>
</span><span id="MultinomialCLM-60"><a href="#MultinomialCLM-60"><span class="linenos"> 60</span></a><span class="sd">            verbose: Verbosity level. Unused. Defaults to 0.</span>
</span><span id="MultinomialCLM-61"><a href="#MultinomialCLM-61"><span class="linenos"> 61</span></a>
</span><span id="MultinomialCLM-62"><a href="#MultinomialCLM-62"><span class="linenos"> 62</span></a><span class="sd">        Returns:</span>
</span><span id="MultinomialCLM-63"><a href="#MultinomialCLM-63"><span class="linenos"> 63</span></a><span class="sd">            Tuple with generated samples [Batches*Batch, Length] {int32}</span>
</span><span id="MultinomialCLM-64"><a href="#MultinomialCLM-64"><span class="linenos"> 64</span></a><span class="sd">            and predictions [Batches*Batch, Length, Vocab] {float32}</span>
</span><span id="MultinomialCLM-65"><a href="#MultinomialCLM-65"><span class="linenos"> 65</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MultinomialCLM-66"><a href="#MultinomialCLM-66"><span class="linenos"> 66</span></a>        <span class="k">del</span> <span class="n">verbose</span>  <span class="c1"># Unused because no progress bar</span>
</span><span id="MultinomialCLM-67"><a href="#MultinomialCLM-67"><span class="linenos"> 67</span></a>        <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</span><span id="MultinomialCLM-68"><a href="#MultinomialCLM-68"><span class="linenos"> 68</span></a>        <span class="c1"># from tfpb import tfpb # noqa: ERA001</span>
</span><span id="MultinomialCLM-69"><a href="#MultinomialCLM-69"><span class="linenos"> 69</span></a>
</span><span id="MultinomialCLM-70"><a href="#MultinomialCLM-70"><span class="linenos"> 70</span></a>        <span class="n">safe_call_func</span><span class="p">:</span> <span class="n">CallFunc</span> <span class="o">=</span> <span class="n">call_func</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">call_cell</span>
</span><span id="MultinomialCLM-71"><a href="#MultinomialCLM-71"><span class="linenos"> 71</span></a>        <span class="n">safe_sample_func</span><span class="p">:</span> <span class="n">SampleFunc</span> <span class="o">=</span> <span class="n">sample_func</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_next_tokens</span>
</span><span id="MultinomialCLM-72"><a href="#MultinomialCLM-72"><span class="linenos"> 72</span></a>
</span><span id="MultinomialCLM-73"><a href="#MultinomialCLM-73"><span class="linenos"> 73</span></a>        <span class="k">if</span> <span class="n">n_batches</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="MultinomialCLM-74"><a href="#MultinomialCLM-74"><span class="linenos"> 74</span></a>            <span class="n">samples</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_batch</span><span class="p">(</span>
</span><span id="MultinomialCLM-75"><a href="#MultinomialCLM-75"><span class="linenos"> 75</span></a>                <span class="n">temp</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">safe_call_func</span><span class="p">,</span> <span class="n">safe_sample_func</span>
</span><span id="MultinomialCLM-76"><a href="#MultinomialCLM-76"><span class="linenos"> 76</span></a>            <span class="p">)</span>
</span><span id="MultinomialCLM-77"><a href="#MultinomialCLM-77"><span class="linenos"> 77</span></a>
</span><span id="MultinomialCLM-78"><a href="#MultinomialCLM-78"><span class="linenos"> 78</span></a>        <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_embedding</span> <span class="k">else</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span>
</span><span id="MultinomialCLM-79"><a href="#MultinomialCLM-79"><span class="linenos"> 79</span></a>        <span class="n">samples</span> <span class="o">=</span> <span class="n">init_tensor_array</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">n_batches</span><span class="p">)</span>
</span><span id="MultinomialCLM-80"><a href="#MultinomialCLM-80"><span class="linenos"> 80</span></a>        <span class="n">preds</span> <span class="o">=</span> <span class="n">init_tensor_array</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">n_batches</span><span class="p">)</span>
</span><span id="MultinomialCLM-81"><a href="#MultinomialCLM-81"><span class="linenos"> 81</span></a>
</span><span id="MultinomialCLM-82"><a href="#MultinomialCLM-82"><span class="linenos"> 82</span></a>        <span class="c1"># Define recurrence function to generate batches</span>
</span><span id="MultinomialCLM-83"><a href="#MultinomialCLM-83"><span class="linenos"> 83</span></a>
</span><span id="MultinomialCLM-84"><a href="#MultinomialCLM-84"><span class="linenos"> 84</span></a>        <span class="c1"># pb = tfpb(desc=&quot;Generating samples&quot;, total=n_batches, disable=verbose &lt; 1) # noqa: ERA001,E501</span>
</span><span id="MultinomialCLM-85"><a href="#MultinomialCLM-85"><span class="linenos"> 85</span></a>        <span class="n">start</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">timestamp</span><span class="p">()</span>
</span><span id="MultinomialCLM-86"><a href="#MultinomialCLM-86"><span class="linenos"> 86</span></a>
</span><span id="MultinomialCLM-87"><a href="#MultinomialCLM-87"><span class="linenos"> 87</span></a>        <span class="k">def</span> <span class="nf">_g_recurrence</span><span class="p">(</span>
</span><span id="MultinomialCLM-88"><a href="#MultinomialCLM-88"><span class="linenos"> 88</span></a>            <span class="n">ix</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="MultinomialCLM-89"><a href="#MultinomialCLM-89"><span class="linenos"> 89</span></a>            <span class="n">last</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="MultinomialCLM-90"><a href="#MultinomialCLM-90"><span class="linenos"> 90</span></a>            <span class="n">samples</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorArray</span><span class="p">,</span>
</span><span id="MultinomialCLM-91"><a href="#MultinomialCLM-91"><span class="linenos"> 91</span></a>            <span class="n">preds</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorArray</span><span class="p">,</span>
</span><span id="MultinomialCLM-92"><a href="#MultinomialCLM-92"><span class="linenos"> 92</span></a>        <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorArray</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorArray</span><span class="p">]:</span>
</span><span id="MultinomialCLM-93"><a href="#MultinomialCLM-93"><span class="linenos"> 93</span></a>            <span class="c1"># Generate batch of samples</span>
</span><span id="MultinomialCLM-94"><a href="#MultinomialCLM-94"><span class="linenos"> 94</span></a>            <span class="c1"># if embedding: [Batch, Length] {int32}</span>
</span><span id="MultinomialCLM-95"><a href="#MultinomialCLM-95"><span class="linenos"> 95</span></a>            <span class="c1"># else: [Batch, Length, Vocab] {float32} # noqa: ERA001</span>
</span><span id="MultinomialCLM-96"><a href="#MultinomialCLM-96"><span class="linenos"> 96</span></a>
</span><span id="MultinomialCLM-97"><a href="#MultinomialCLM-97"><span class="linenos"> 97</span></a>            <span class="c1"># If return_preds is True, unpack samples and predictions and</span>
</span><span id="MultinomialCLM-98"><a href="#MultinomialCLM-98"><span class="linenos"> 98</span></a>            <span class="c1"># append predictions to TensorArray</span>
</span><span id="MultinomialCLM-99"><a href="#MultinomialCLM-99"><span class="linenos"> 99</span></a>            <span class="c1"># if return_preds: type of preds is tf.TensorArray and</span>
</span><span id="MultinomialCLM-100"><a href="#MultinomialCLM-100"><span class="linenos">100</span></a>            <span class="c1"># type _samples is tuple[tf.Tensor, tf.Tensor]</span>
</span><span id="MultinomialCLM-101"><a href="#MultinomialCLM-101"><span class="linenos">101</span></a>            <span class="n">samples_batch</span><span class="p">,</span> <span class="n">preds_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_batch</span><span class="p">(</span>
</span><span id="MultinomialCLM-102"><a href="#MultinomialCLM-102"><span class="linenos">102</span></a>                <span class="n">temp</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">safe_call_func</span><span class="p">,</span> <span class="n">safe_sample_func</span>
</span><span id="MultinomialCLM-103"><a href="#MultinomialCLM-103"><span class="linenos">103</span></a>            <span class="p">)</span>
</span><span id="MultinomialCLM-104"><a href="#MultinomialCLM-104"><span class="linenos">104</span></a>            <span class="n">preds</span> <span class="o">=</span> <span class="n">preds</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">ix</span><span class="p">,</span> <span class="n">preds_batch</span><span class="p">)</span>
</span><span id="MultinomialCLM-105"><a href="#MultinomialCLM-105"><span class="linenos">105</span></a>
</span><span id="MultinomialCLM-106"><a href="#MultinomialCLM-106"><span class="linenos">106</span></a>            <span class="c1"># Append samples to TensorArray</span>
</span><span id="MultinomialCLM-107"><a href="#MultinomialCLM-107"><span class="linenos">107</span></a>            <span class="n">samples</span> <span class="o">=</span> <span class="n">samples</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">ix</span><span class="p">,</span> <span class="n">samples_batch</span><span class="p">)</span>
</span><span id="MultinomialCLM-108"><a href="#MultinomialCLM-108"><span class="linenos">108</span></a>
</span><span id="MultinomialCLM-109"><a href="#MultinomialCLM-109"><span class="linenos">109</span></a>            <span class="n">new_ix</span> <span class="o">=</span> <span class="n">ix</span> <span class="o">+</span> <span class="mi">1</span>
</span><span id="MultinomialCLM-110"><a href="#MultinomialCLM-110"><span class="linenos">110</span></a>            <span class="c1"># new_ix, last = pb.update(ix, last, start) # noqa: ERA001</span>
</span><span id="MultinomialCLM-111"><a href="#MultinomialCLM-111"><span class="linenos">111</span></a>
</span><span id="MultinomialCLM-112"><a href="#MultinomialCLM-112"><span class="linenos">112</span></a>            <span class="k">return</span> <span class="n">new_ix</span><span class="p">,</span> <span class="n">last</span><span class="p">,</span> <span class="n">samples</span><span class="p">,</span> <span class="n">preds</span>
</span><span id="MultinomialCLM-113"><a href="#MultinomialCLM-113"><span class="linenos">113</span></a>
</span><span id="MultinomialCLM-114"><a href="#MultinomialCLM-114"><span class="linenos">114</span></a>        <span class="c1"># Generate batches using recurrence function</span>
</span><span id="MultinomialCLM-115"><a href="#MultinomialCLM-115"><span class="linenos">115</span></a>
</span><span id="MultinomialCLM-116"><a href="#MultinomialCLM-116"><span class="linenos">116</span></a>        <span class="n">loop_output</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorArray</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorArray</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="MultinomialCLM-117"><a href="#MultinomialCLM-117"><span class="linenos">117</span></a>            <span class="n">tf</span><span class="o">.</span><span class="n">while_loop</span><span class="p">(</span>
</span><span id="MultinomialCLM-118"><a href="#MultinomialCLM-118"><span class="linenos">118</span></a>                <span class="n">cond</span><span class="o">=</span><span class="k">lambda</span> <span class="n">i</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span><span class="p">:</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">n_batches</span><span class="p">,</span>
</span><span id="MultinomialCLM-119"><a href="#MultinomialCLM-119"><span class="linenos">119</span></a>                <span class="n">body</span><span class="o">=</span><span class="n">_g_recurrence</span><span class="p">,</span>
</span><span id="MultinomialCLM-120"><a href="#MultinomialCLM-120"><span class="linenos">120</span></a>                <span class="n">loop_vars</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">samples</span><span class="p">,</span> <span class="n">preds</span><span class="p">),</span>
</span><span id="MultinomialCLM-121"><a href="#MultinomialCLM-121"><span class="linenos">121</span></a>            <span class="p">)</span>
</span><span id="MultinomialCLM-122"><a href="#MultinomialCLM-122"><span class="linenos">122</span></a>        <span class="p">)</span>
</span><span id="MultinomialCLM-123"><a href="#MultinomialCLM-123"><span class="linenos">123</span></a>
</span><span id="MultinomialCLM-124"><a href="#MultinomialCLM-124"><span class="linenos">124</span></a>        <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">samples</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">loop_output</span>
</span><span id="MultinomialCLM-125"><a href="#MultinomialCLM-125"><span class="linenos">125</span></a>
</span><span id="MultinomialCLM-126"><a href="#MultinomialCLM-126"><span class="linenos">126</span></a>        <span class="c1"># Stack generated batches into final output</span>
</span><span id="MultinomialCLM-127"><a href="#MultinomialCLM-127"><span class="linenos">127</span></a>        <span class="c1"># [Batches*Batch, Length] {int32} if embedding else {float32}</span>
</span><span id="MultinomialCLM-128"><a href="#MultinomialCLM-128"><span class="linenos">128</span></a>        <span class="n">joined_samples</span> <span class="o">=</span> <span class="n">samples</span><span class="o">.</span><span class="n">concat</span><span class="p">()</span>
</span><span id="MultinomialCLM-129"><a href="#MultinomialCLM-129"><span class="linenos">129</span></a>
</span><span id="MultinomialCLM-130"><a href="#MultinomialCLM-130"><span class="linenos">130</span></a>        <span class="c1"># stack predictions into final output</span>
</span><span id="MultinomialCLM-131"><a href="#MultinomialCLM-131"><span class="linenos">131</span></a>        <span class="c1"># [Batches*Batch, Length, Vocab] {float32}</span>
</span><span id="MultinomialCLM-132"><a href="#MultinomialCLM-132"><span class="linenos">132</span></a>        <span class="c1"># and return samples and predictions</span>
</span><span id="MultinomialCLM-133"><a href="#MultinomialCLM-133"><span class="linenos">133</span></a>
</span><span id="MultinomialCLM-134"><a href="#MultinomialCLM-134"><span class="linenos">134</span></a>        <span class="n">joined_preds</span> <span class="o">=</span> <span class="n">preds</span><span class="o">.</span><span class="n">concat</span><span class="p">()</span>
</span><span id="MultinomialCLM-135"><a href="#MultinomialCLM-135"><span class="linenos">135</span></a>        <span class="k">return</span> <span class="n">joined_samples</span><span class="p">,</span> <span class="n">joined_preds</span>
</span><span id="MultinomialCLM-136"><a href="#MultinomialCLM-136"><span class="linenos">136</span></a>
</span><span id="MultinomialCLM-137"><a href="#MultinomialCLM-137"><span class="linenos">137</span></a>    <span class="nd">@tf_kw_func_wrapper</span><span class="p">(</span>
</span><span id="MultinomialCLM-138"><a href="#MultinomialCLM-138"><span class="linenos">138</span></a>        <span class="n">input_signature</span><span class="o">=</span><span class="p">[</span>
</span><span id="MultinomialCLM-139"><a href="#MultinomialCLM-139"><span class="linenos">139</span></a>            <span class="n">tf_tensor_spec</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf_dtype</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
</span><span id="MultinomialCLM-140"><a href="#MultinomialCLM-140"><span class="linenos">140</span></a>            <span class="n">tf_tensor_spec</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf_dtype</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
</span><span id="MultinomialCLM-141"><a href="#MultinomialCLM-141"><span class="linenos">141</span></a>            <span class="n">tf_tensor_spec</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf_dtype</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span>
</span><span id="MultinomialCLM-142"><a href="#MultinomialCLM-142"><span class="linenos">142</span></a>        <span class="p">]</span>
</span><span id="MultinomialCLM-143"><a href="#MultinomialCLM-143"><span class="linenos">143</span></a>    <span class="p">)</span>
</span><span id="MultinomialCLM-144"><a href="#MultinomialCLM-144"><span class="linenos">144</span></a>    <span class="k">def</span> <span class="nf">sample_next_tokens</span><span class="p">(</span>
</span><span id="MultinomialCLM-145"><a href="#MultinomialCLM-145"><span class="linenos">145</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">x_t</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">/</span><span class="p">,</span> <span class="n">temp</span><span class="p">:</span> <span class="nb">float</span>
</span><span id="MultinomialCLM-146"><a href="#MultinomialCLM-146"><span class="linenos">146</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="MultinomialCLM-147"><a href="#MultinomialCLM-147"><span class="linenos">147</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Multinomially sample next tokens from the output (wrapped in a tf.function).</span>
</span><span id="MultinomialCLM-148"><a href="#MultinomialCLM-148"><span class="linenos">148</span></a>
</span><span id="MultinomialCLM-149"><a href="#MultinomialCLM-149"><span class="linenos">149</span></a><span class="sd">        Args:</span>
</span><span id="MultinomialCLM-150"><a href="#MultinomialCLM-150"><span class="linenos">150</span></a><span class="sd">            i: Current time step. [1] {int32}.</span>
</span><span id="MultinomialCLM-151"><a href="#MultinomialCLM-151"><span class="linenos">151</span></a><span class="sd">            x_t: Model output [Batch, Vocab] {float32}.</span>
</span><span id="MultinomialCLM-152"><a href="#MultinomialCLM-152"><span class="linenos">152</span></a><span class="sd">            temp: Temperature factor. [1]</span>
</span><span id="MultinomialCLM-153"><a href="#MultinomialCLM-153"><span class="linenos">153</span></a>
</span><span id="MultinomialCLM-154"><a href="#MultinomialCLM-154"><span class="linenos">154</span></a><span class="sd">        Returns:</span>
</span><span id="MultinomialCLM-155"><a href="#MultinomialCLM-155"><span class="linenos">155</span></a><span class="sd">            Sampled next tokens [Batch] {int32}.</span>
</span><span id="MultinomialCLM-156"><a href="#MultinomialCLM-156"><span class="linenos">156</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MultinomialCLM-157"><a href="#MultinomialCLM-157"><span class="linenos">157</span></a>        <span class="k">del</span> <span class="n">i</span>  <span class="c1"># Multinomial sampling does not depend on the current time step</span>
</span><span id="MultinomialCLM-158"><a href="#MultinomialCLM-158"><span class="linenos">158</span></a>        <span class="k">return</span> <span class="n">multinomial_sample</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">temp</span><span class="o">=</span><span class="n">temp</span><span class="p">)</span>
</span><span id="MultinomialCLM-159"><a href="#MultinomialCLM-159"><span class="linenos">159</span></a>
</span><span id="MultinomialCLM-160"><a href="#MultinomialCLM-160"><span class="linenos">160</span></a>    <span class="nd">@tf_func_wrapper</span>
</span><span id="MultinomialCLM-161"><a href="#MultinomialCLM-161"><span class="linenos">161</span></a>    <span class="k">def</span> <span class="nf">_generate_batch</span><span class="p">(</span>
</span><span id="MultinomialCLM-162"><a href="#MultinomialCLM-162"><span class="linenos">162</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">temp</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">call_func</span><span class="p">:</span> <span class="n">CallFunc</span><span class="p">,</span> <span class="n">sample_func</span><span class="p">:</span> <span class="n">SampleFunc</span>
</span><span id="MultinomialCLM-163"><a href="#MultinomialCLM-163"><span class="linenos">163</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
</span><span id="MultinomialCLM-164"><a href="#MultinomialCLM-164"><span class="linenos">164</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate one batch of samples (wrapped in a tf.function).</span>
</span><span id="MultinomialCLM-165"><a href="#MultinomialCLM-165"><span class="linenos">165</span></a>
</span><span id="MultinomialCLM-166"><a href="#MultinomialCLM-166"><span class="linenos">166</span></a><span class="sd">        Args:</span>
</span><span id="MultinomialCLM-167"><a href="#MultinomialCLM-167"><span class="linenos">167</span></a><span class="sd">            temp: Temperature factor</span>
</span><span id="MultinomialCLM-168"><a href="#MultinomialCLM-168"><span class="linenos">168</span></a><span class="sd">            batch_size: Batch size</span>
</span><span id="MultinomialCLM-169"><a href="#MultinomialCLM-169"><span class="linenos">169</span></a><span class="sd">            call_func: Function to call model for one time step.</span>
</span><span id="MultinomialCLM-170"><a href="#MultinomialCLM-170"><span class="linenos">170</span></a><span class="sd">            sample_func: Function to sample next tokens.</span>
</span><span id="MultinomialCLM-171"><a href="#MultinomialCLM-171"><span class="linenos">171</span></a>
</span><span id="MultinomialCLM-172"><a href="#MultinomialCLM-172"><span class="linenos">172</span></a><span class="sd">        Returns:</span>
</span><span id="MultinomialCLM-173"><a href="#MultinomialCLM-173"><span class="linenos">173</span></a><span class="sd">            Tuple with generated samples</span>
</span><span id="MultinomialCLM-174"><a href="#MultinomialCLM-174"><span class="linenos">174</span></a><span class="sd">            if embedding: [Batch, Length] {int32}</span>
</span><span id="MultinomialCLM-175"><a href="#MultinomialCLM-175"><span class="linenos">175</span></a><span class="sd">            else: [Batch, Length, Vocab] {float32}</span>
</span><span id="MultinomialCLM-176"><a href="#MultinomialCLM-176"><span class="linenos">176</span></a><span class="sd">            and predictions [Batch, Length, Vocab] {float32}</span>
</span><span id="MultinomialCLM-177"><a href="#MultinomialCLM-177"><span class="linenos">177</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MultinomialCLM-178"><a href="#MultinomialCLM-178"><span class="linenos">178</span></a>        <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</span><span id="MultinomialCLM-179"><a href="#MultinomialCLM-179"><span class="linenos">179</span></a>
</span><span id="MultinomialCLM-180"><a href="#MultinomialCLM-180"><span class="linenos">180</span></a>        <span class="c1"># Initialize start tokens for generation,</span>
</span><span id="MultinomialCLM-181"><a href="#MultinomialCLM-181"><span class="linenos">181</span></a>        <span class="c1"># if embedding: [Batch, 1] {int32}</span>
</span><span id="MultinomialCLM-182"><a href="#MultinomialCLM-182"><span class="linenos">182</span></a>        <span class="c1"># else: [Batch, 1, Vocab] {float32} # noqa: ERA001</span>
</span><span id="MultinomialCLM-183"><a href="#MultinomialCLM-183"><span class="linenos">183</span></a>        <span class="n">start_tokens</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">start_token</span><span class="p">,</span> <span class="n">repeats</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="MultinomialCLM-184"><a href="#MultinomialCLM-184"><span class="linenos">184</span></a>
</span><span id="MultinomialCLM-185"><a href="#MultinomialCLM-185"><span class="linenos">185</span></a>        <span class="c1"># Initialize hidden states for LSTM layers (GRU not supported)</span>
</span><span id="MultinomialCLM-186"><a href="#MultinomialCLM-186"><span class="linenos">186</span></a>        <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">init_hidden_states</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dims</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
</span><span id="MultinomialCLM-187"><a href="#MultinomialCLM-187"><span class="linenos">187</span></a>
</span><span id="MultinomialCLM-188"><a href="#MultinomialCLM-188"><span class="linenos">188</span></a>        <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_embedding</span> <span class="k">else</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span>
</span><span id="MultinomialCLM-189"><a href="#MultinomialCLM-189"><span class="linenos">189</span></a>        <span class="n">gen_x</span> <span class="o">=</span> <span class="n">init_tensor_array</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span><span class="p">)</span>
</span><span id="MultinomialCLM-190"><a href="#MultinomialCLM-190"><span class="linenos">190</span></a>        <span class="n">preds</span> <span class="o">=</span> <span class="n">init_tensor_array</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span><span class="p">)</span>
</span><span id="MultinomialCLM-191"><a href="#MultinomialCLM-191"><span class="linenos">191</span></a>
</span><span id="MultinomialCLM-192"><a href="#MultinomialCLM-192"><span class="linenos">192</span></a>        <span class="c1"># Define recurrence function to generate samples</span>
</span><span id="MultinomialCLM-193"><a href="#MultinomialCLM-193"><span class="linenos">193</span></a>        <span class="k">def</span> <span class="nf">_g_recurrence</span><span class="p">(</span>
</span><span id="MultinomialCLM-194"><a href="#MultinomialCLM-194"><span class="linenos">194</span></a>            <span class="n">i</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="MultinomialCLM-195"><a href="#MultinomialCLM-195"><span class="linenos">195</span></a>            <span class="n">gen_x</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorArray</span><span class="p">,</span>
</span><span id="MultinomialCLM-196"><a href="#MultinomialCLM-196"><span class="linenos">196</span></a>            <span class="n">next_tokens</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="MultinomialCLM-197"><a href="#MultinomialCLM-197"><span class="linenos">197</span></a>            <span class="n">hidden_states</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span>
</span><span id="MultinomialCLM-198"><a href="#MultinomialCLM-198"><span class="linenos">198</span></a>            <span class="n">preds</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorArray</span><span class="p">,</span>
</span><span id="MultinomialCLM-199"><a href="#MultinomialCLM-199"><span class="linenos">199</span></a>        <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span>
</span><span id="MultinomialCLM-200"><a href="#MultinomialCLM-200"><span class="linenos">200</span></a>            <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorArray</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorArray</span>
</span><span id="MultinomialCLM-201"><a href="#MultinomialCLM-201"><span class="linenos">201</span></a>        <span class="p">]:</span>
</span><span id="MultinomialCLM-202"><a href="#MultinomialCLM-202"><span class="linenos">202</span></a>            <span class="c1"># Call model for one time step</span>
</span><span id="MultinomialCLM-203"><a href="#MultinomialCLM-203"><span class="linenos">203</span></a>            <span class="n">x_t</span><span class="p">,</span> <span class="n">new_hidden_states</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">call_func</span><span class="p">(</span><span class="n">next_tokens</span><span class="p">,</span> <span class="n">hidden_states</span><span class="p">)</span>
</span><span id="MultinomialCLM-204"><a href="#MultinomialCLM-204"><span class="linenos">204</span></a>
</span><span id="MultinomialCLM-205"><a href="#MultinomialCLM-205"><span class="linenos">205</span></a>            <span class="c1"># Sample next token (from logits or softmax distribution)</span>
</span><span id="MultinomialCLM-206"><a href="#MultinomialCLM-206"><span class="linenos">206</span></a>
</span><span id="MultinomialCLM-207"><a href="#MultinomialCLM-207"><span class="linenos">207</span></a>            <span class="n">next_tokens</span> <span class="o">=</span> <span class="n">sample_func</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">x_t</span><span class="p">,</span> <span class="n">temp</span><span class="o">=</span><span class="n">temp</span><span class="p">)</span>
</span><span id="MultinomialCLM-208"><a href="#MultinomialCLM-208"><span class="linenos">208</span></a>
</span><span id="MultinomialCLM-209"><a href="#MultinomialCLM-209"><span class="linenos">209</span></a>            <span class="c1"># Cast selected token to float if using one-hot encoding</span>
</span><span id="MultinomialCLM-210"><a href="#MultinomialCLM-210"><span class="linenos">210</span></a>            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_embedding</span><span class="p">:</span>
</span><span id="MultinomialCLM-211"><a href="#MultinomialCLM-211"><span class="linenos">211</span></a>                <span class="n">next_tokens</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span>
</span><span id="MultinomialCLM-212"><a href="#MultinomialCLM-212"><span class="linenos">212</span></a>                    <span class="n">next_tokens</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">output_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span>
</span><span id="MultinomialCLM-213"><a href="#MultinomialCLM-213"><span class="linenos">213</span></a>                <span class="p">)</span>
</span><span id="MultinomialCLM-214"><a href="#MultinomialCLM-214"><span class="linenos">214</span></a>
</span><span id="MultinomialCLM-215"><a href="#MultinomialCLM-215"><span class="linenos">215</span></a>            <span class="c1"># Append next token to TensorArray</span>
</span><span id="MultinomialCLM-216"><a href="#MultinomialCLM-216"><span class="linenos">216</span></a>            <span class="c1"># Shape: [Length[:i], Batch] # noqa: ERA001</span>
</span><span id="MultinomialCLM-217"><a href="#MultinomialCLM-217"><span class="linenos">217</span></a>            <span class="n">gen_x</span> <span class="o">=</span> <span class="n">gen_x</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">next_tokens</span><span class="p">)</span>
</span><span id="MultinomialCLM-218"><a href="#MultinomialCLM-218"><span class="linenos">218</span></a>
</span><span id="MultinomialCLM-219"><a href="#MultinomialCLM-219"><span class="linenos">219</span></a>            <span class="c1"># Return updated variables</span>
</span><span id="MultinomialCLM-220"><a href="#MultinomialCLM-220"><span class="linenos">220</span></a>            <span class="k">return</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">gen_x</span><span class="p">,</span> <span class="n">next_tokens</span><span class="p">,</span> <span class="n">new_hidden_states</span><span class="p">,</span> <span class="n">preds</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">x_t</span><span class="p">))</span>
</span><span id="MultinomialCLM-221"><a href="#MultinomialCLM-221"><span class="linenos">221</span></a>
</span><span id="MultinomialCLM-222"><a href="#MultinomialCLM-222"><span class="linenos">222</span></a>        <span class="c1"># Generate samples using recurrence function</span>
</span><span id="MultinomialCLM-223"><a href="#MultinomialCLM-223"><span class="linenos">223</span></a>        <span class="n">zero</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
</span><span id="MultinomialCLM-224"><a href="#MultinomialCLM-224"><span class="linenos">224</span></a>
</span><span id="MultinomialCLM-225"><a href="#MultinomialCLM-225"><span class="linenos">225</span></a>        <span class="n">loop_output</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span>
</span><span id="MultinomialCLM-226"><a href="#MultinomialCLM-226"><span class="linenos">226</span></a>            <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorArray</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorArray</span>
</span><span id="MultinomialCLM-227"><a href="#MultinomialCLM-227"><span class="linenos">227</span></a>        <span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">while_loop</span><span class="p">(</span>
</span><span id="MultinomialCLM-228"><a href="#MultinomialCLM-228"><span class="linenos">228</span></a>            <span class="n">cond</span><span class="o">=</span><span class="k">lambda</span> <span class="n">i</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span><span class="p">:</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span><span class="p">,</span>
</span><span id="MultinomialCLM-229"><a href="#MultinomialCLM-229"><span class="linenos">229</span></a>            <span class="n">body</span><span class="o">=</span><span class="n">_g_recurrence</span><span class="p">,</span>
</span><span id="MultinomialCLM-230"><a href="#MultinomialCLM-230"><span class="linenos">230</span></a>            <span class="n">loop_vars</span><span class="o">=</span><span class="p">(</span>
</span><span id="MultinomialCLM-231"><a href="#MultinomialCLM-231"><span class="linenos">231</span></a>                <span class="n">zero</span><span class="p">,</span>  <span class="c1"># Shape: []</span>
</span><span id="MultinomialCLM-232"><a href="#MultinomialCLM-232"><span class="linenos">232</span></a>                <span class="n">gen_x</span><span class="p">,</span>  <span class="c1"># Shape: [Length[:0], Batch]</span>
</span><span id="MultinomialCLM-233"><a href="#MultinomialCLM-233"><span class="linenos">233</span></a>                <span class="n">start_tokens</span><span class="p">,</span>  <span class="c1"># Shape: [Batch]</span>
</span><span id="MultinomialCLM-234"><a href="#MultinomialCLM-234"><span class="linenos">234</span></a>                <span class="n">hidden_states</span><span class="p">,</span>  <span class="c1"># Shape: [[Batch, Neurons], ...]</span>
</span><span id="MultinomialCLM-235"><a href="#MultinomialCLM-235"><span class="linenos">235</span></a>                <span class="n">preds</span><span class="p">,</span>  <span class="c1"># Shape: [Length[:0], Batch, Vocab]</span>
</span><span id="MultinomialCLM-236"><a href="#MultinomialCLM-236"><span class="linenos">236</span></a>            <span class="p">),</span>
</span><span id="MultinomialCLM-237"><a href="#MultinomialCLM-237"><span class="linenos">237</span></a>        <span class="p">)</span>
</span><span id="MultinomialCLM-238"><a href="#MultinomialCLM-238"><span class="linenos">238</span></a>        <span class="n">_</span><span class="p">,</span> <span class="n">gen_x</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">loop_output</span>
</span><span id="MultinomialCLM-239"><a href="#MultinomialCLM-239"><span class="linenos">239</span></a>
</span><span id="MultinomialCLM-240"><a href="#MultinomialCLM-240"><span class="linenos">240</span></a>        <span class="c1"># Stack generated samples into final output</span>
</span><span id="MultinomialCLM-241"><a href="#MultinomialCLM-241"><span class="linenos">241</span></a>        <span class="c1"># Shape: [Length, Batch] # noqa: ERA001</span>
</span><span id="MultinomialCLM-242"><a href="#MultinomialCLM-242"><span class="linenos">242</span></a>        <span class="n">gen_x</span> <span class="o">=</span> <span class="n">gen_x</span><span class="o">.</span><span class="n">stack</span><span class="p">()</span>  <span class="c1"># TODO: Write an issue</span>
</span><span id="MultinomialCLM-243"><a href="#MultinomialCLM-243"><span class="linenos">243</span></a>        <span class="n">gen_x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>  <span class="c1"># pylint: disable=redefined-variable-type</span>
</span><span id="MultinomialCLM-244"><a href="#MultinomialCLM-244"><span class="linenos">244</span></a>            <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">start_tokens</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">gen_x</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span>
</span><span id="MultinomialCLM-245"><a href="#MultinomialCLM-245"><span class="linenos">245</span></a>        <span class="p">)</span>  <span class="c1"># Shape: [Length+1, Batch]</span>
</span><span id="MultinomialCLM-246"><a href="#MultinomialCLM-246"><span class="linenos">246</span></a>
</span><span id="MultinomialCLM-247"><a href="#MultinomialCLM-247"><span class="linenos">247</span></a>        <span class="n">permutation</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_embedding</span> <span class="k">else</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
</span><span id="MultinomialCLM-248"><a href="#MultinomialCLM-248"><span class="linenos">248</span></a>
</span><span id="MultinomialCLM-249"><a href="#MultinomialCLM-249"><span class="linenos">249</span></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">gen_x</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="n">permutation</span><span class="p">)</span>  <span class="c1"># Shape: [Batch, Length+1]</span>
</span><span id="MultinomialCLM-250"><a href="#MultinomialCLM-250"><span class="linenos">250</span></a>
</span><span id="MultinomialCLM-251"><a href="#MultinomialCLM-251"><span class="linenos">251</span></a>        <span class="n">preds</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="MultinomialCLM-252"><a href="#MultinomialCLM-252"><span class="linenos">252</span></a>            <span class="n">preds</span><span class="o">.</span><span class="n">stack</span><span class="p">()</span>  <span class="c1"># TODO: Write an issue</span>
</span><span id="MultinomialCLM-253"><a href="#MultinomialCLM-253"><span class="linenos">253</span></a>        <span class="p">)</span>  <span class="c1"># Shape: [Length, Batch, Vocab]</span>
</span><span id="MultinomialCLM-254"><a href="#MultinomialCLM-254"><span class="linenos">254</span></a>        <span class="n">preds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>  <span class="c1"># Shape: [Batch, Length, Vocab]</span>
</span><span id="MultinomialCLM-255"><a href="#MultinomialCLM-255"><span class="linenos">255</span></a>        <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">preds</span>
</span><span id="MultinomialCLM-256"><a href="#MultinomialCLM-256"><span class="linenos">256</span></a>
</span><span id="MultinomialCLM-257"><a href="#MultinomialCLM-257"><span class="linenos">257</span></a>    <span class="k">def</span> <span class="nf">generate_with_perplexity</span><span class="p">(</span>
</span><span id="MultinomialCLM-258"><a href="#MultinomialCLM-258"><span class="linenos">258</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="MultinomialCLM-259"><a href="#MultinomialCLM-259"><span class="linenos">259</span></a>        <span class="n">n_batches</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="MultinomialCLM-260"><a href="#MultinomialCLM-260"><span class="linenos">260</span></a>        <span class="n">temp</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
</span><span id="MultinomialCLM-261"><a href="#MultinomialCLM-261"><span class="linenos">261</span></a>        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span>
</span><span id="MultinomialCLM-262"><a href="#MultinomialCLM-262"><span class="linenos">262</span></a>        <span class="n">prior_probs</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">lookup</span><span class="o">.</span><span class="n">StaticHashTable</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="MultinomialCLM-263"><a href="#MultinomialCLM-263"><span class="linenos">263</span></a>        <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="MultinomialCLM-264"><a href="#MultinomialCLM-264"><span class="linenos">264</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
</span><span id="MultinomialCLM-265"><a href="#MultinomialCLM-265"><span class="linenos">265</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate samples with perplexity calculation from a model.</span>
</span><span id="MultinomialCLM-266"><a href="#MultinomialCLM-266"><span class="linenos">266</span></a>
</span><span id="MultinomialCLM-267"><a href="#MultinomialCLM-267"><span class="linenos">267</span></a><span class="sd">        Args:</span>
</span><span id="MultinomialCLM-268"><a href="#MultinomialCLM-268"><span class="linenos">268</span></a><span class="sd">            n_batches: Number of batches to generate. Defaults to 1.</span>
</span><span id="MultinomialCLM-269"><a href="#MultinomialCLM-269"><span class="linenos">269</span></a><span class="sd">            temp: Temperature factor. Defaults to 1.0.</span>
</span><span id="MultinomialCLM-270"><a href="#MultinomialCLM-270"><span class="linenos">270</span></a><span class="sd">            batch_size: Batch size for generation. Defaults to 1024.</span>
</span><span id="MultinomialCLM-271"><a href="#MultinomialCLM-271"><span class="linenos">271</span></a><span class="sd">            prior_probs: Prior probabilities for each token.</span>
</span><span id="MultinomialCLM-272"><a href="#MultinomialCLM-272"><span class="linenos">272</span></a><span class="sd">                Defaults to equal probabilities for each non-special token.</span>
</span><span id="MultinomialCLM-273"><a href="#MultinomialCLM-273"><span class="linenos">273</span></a><span class="sd">            verbose: Verbosity level. Defaults to 0.</span>
</span><span id="MultinomialCLM-274"><a href="#MultinomialCLM-274"><span class="linenos">274</span></a>
</span><span id="MultinomialCLM-275"><a href="#MultinomialCLM-275"><span class="linenos">275</span></a><span class="sd">        Returns:</span>
</span><span id="MultinomialCLM-276"><a href="#MultinomialCLM-276"><span class="linenos">276</span></a><span class="sd">            Tuple with generated samples [Batches*Batch, Length] {int32} and</span>
</span><span id="MultinomialCLM-277"><a href="#MultinomialCLM-277"><span class="linenos">277</span></a><span class="sd">            predictions [Batches*Batch, Length, Vocab] {float32} and</span>
</span><span id="MultinomialCLM-278"><a href="#MultinomialCLM-278"><span class="linenos">278</span></a><span class="sd">            perplexity scores [Batches*Batch] {float32}</span>
</span><span id="MultinomialCLM-279"><a href="#MultinomialCLM-279"><span class="linenos">279</span></a>
</span><span id="MultinomialCLM-280"><a href="#MultinomialCLM-280"><span class="linenos">280</span></a><span class="sd">        Raises:</span>
</span><span id="MultinomialCLM-281"><a href="#MultinomialCLM-281"><span class="linenos">281</span></a><span class="sd">            ValueError: If vocabulary is not provided.</span>
</span><span id="MultinomialCLM-282"><a href="#MultinomialCLM-282"><span class="linenos">282</span></a><span class="sd">                Set on instance creation or set `vocab` attribute.</span>
</span><span id="MultinomialCLM-283"><a href="#MultinomialCLM-283"><span class="linenos">283</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MultinomialCLM-284"><a href="#MultinomialCLM-284"><span class="linenos">284</span></a>        <span class="k">if</span> <span class="n">prior_probs</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="MultinomialCLM-285"><a href="#MultinomialCLM-285"><span class="linenos">285</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;prior_probs or vocab is required for this model&quot;</span><span class="p">)</span>
</span><span id="MultinomialCLM-286"><a href="#MultinomialCLM-286"><span class="linenos">286</span></a>
</span><span id="MultinomialCLM-287"><a href="#MultinomialCLM-287"><span class="linenos">287</span></a>        <span class="k">return</span> <span class="n">generate_with_perplexity</span><span class="p">(</span>
</span><span id="MultinomialCLM-288"><a href="#MultinomialCLM-288"><span class="linenos">288</span></a>            <span class="bp">self</span><span class="p">,</span> <span class="n">n_batches</span><span class="p">,</span> <span class="n">temp</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">prior_probs</span><span class="p">,</span> <span class="n">verbose</span>
</span><span id="MultinomialCLM-289"><a href="#MultinomialCLM-289"><span class="linenos">289</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Base class for models generating samples with multinomial sampling.</p>

<h6 id="attributes">Attributes:</h6>

<ul>
<li><strong>model (tf.keras.Model):</strong>  Model to wrap with LSTM layers.</li>
<li><strong>vocab (Vocabulary | None):</strong>  Vocabulary.</li>
<li><strong>seq_len (int):</strong>  Sequence length.</li>
<li><strong>dims (list[int]):</strong>  Number of neurons per LSTM layers.</li>
<li><strong>has_embedding (bool):</strong>  Whether the model has an Embedding layer.</li>
<li><strong>start_token (tf.Tensor):</strong>  Start token for generation.</li>
</ul>
</div>


                            <div id="MultinomialCLM.generate" class="classattr">
                                        <input id="MultinomialCLM.generate-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-tf_func_wrapper">@tf_func_wrapper</div>

        <span class="def">def</span>
        <span class="name">generate</span><span class="signature pdoc-code multiline">(<span class="param"> <span class="bp">self</span>,</span><span class="param">    <span class="n">n_batches</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>,</span><span class="param"> <span class="n">temp</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span>,</span><span class="param">  <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span>,</span><span class="param"> <span class="n">call_func</span><span class="p">:</span> <span class="n">lstm_clm</span><span class="o">.</span><span class="n">clm</span><span class="o">.</span><span class="n">proto</span><span class="o">.</span><span class="n">CallFunc</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">   <span class="n">sample_func</span><span class="p">:</span> <span class="n">lstm_clm</span><span class="o">.</span><span class="n">clm</span><span class="o">.</span><span class="n">proto</span><span class="o">.</span><span class="n">SampleFunc</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">   <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span></span><span class="return-annotation">) -> <span class="nb">tuple</span><span class="p">[</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span>:</span></span>

                <label class="view-source-button" for="MultinomialCLM.generate-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#MultinomialCLM.generate"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="MultinomialCLM.generate-40"><a href="#MultinomialCLM.generate-40"><span class="linenos"> 40</span></a>    <span class="nd">@tf_func_wrapper</span>
</span><span id="MultinomialCLM.generate-41"><a href="#MultinomialCLM.generate-41"><span class="linenos"> 41</span></a>    <span class="k">def</span> <span class="nf">generate</span><span class="p">(</span>
</span><span id="MultinomialCLM.generate-42"><a href="#MultinomialCLM.generate-42"><span class="linenos"> 42</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="MultinomialCLM.generate-43"><a href="#MultinomialCLM.generate-43"><span class="linenos"> 43</span></a>        <span class="n">n_batches</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="MultinomialCLM.generate-44"><a href="#MultinomialCLM.generate-44"><span class="linenos"> 44</span></a>        <span class="n">temp</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
</span><span id="MultinomialCLM.generate-45"><a href="#MultinomialCLM.generate-45"><span class="linenos"> 45</span></a>        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span>
</span><span id="MultinomialCLM.generate-46"><a href="#MultinomialCLM.generate-46"><span class="linenos"> 46</span></a>        <span class="n">call_func</span><span class="p">:</span> <span class="n">CallFunc</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="MultinomialCLM.generate-47"><a href="#MultinomialCLM.generate-47"><span class="linenos"> 47</span></a>        <span class="n">sample_func</span><span class="p">:</span> <span class="n">SampleFunc</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="MultinomialCLM.generate-48"><a href="#MultinomialCLM.generate-48"><span class="linenos"> 48</span></a>        <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="MultinomialCLM.generate-49"><a href="#MultinomialCLM.generate-49"><span class="linenos"> 49</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
</span><span id="MultinomialCLM.generate-50"><a href="#MultinomialCLM.generate-50"><span class="linenos"> 50</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate multiple batches of samples (wrapped in a tf.function).</span>
</span><span id="MultinomialCLM.generate-51"><a href="#MultinomialCLM.generate-51"><span class="linenos"> 51</span></a>
</span><span id="MultinomialCLM.generate-52"><a href="#MultinomialCLM.generate-52"><span class="linenos"> 52</span></a><span class="sd">        Args:</span>
</span><span id="MultinomialCLM.generate-53"><a href="#MultinomialCLM.generate-53"><span class="linenos"> 53</span></a><span class="sd">            n_batches: Number of batches to generate.</span>
</span><span id="MultinomialCLM.generate-54"><a href="#MultinomialCLM.generate-54"><span class="linenos"> 54</span></a><span class="sd">            temp: Temperature factor. Defaults to 1.0.</span>
</span><span id="MultinomialCLM.generate-55"><a href="#MultinomialCLM.generate-55"><span class="linenos"> 55</span></a><span class="sd">            batch_size: Batch size for generation. Defaults to 1024.</span>
</span><span id="MultinomialCLM.generate-56"><a href="#MultinomialCLM.generate-56"><span class="linenos"> 56</span></a><span class="sd">            call_func: Function to call model for one time step.</span>
</span><span id="MultinomialCLM.generate-57"><a href="#MultinomialCLM.generate-57"><span class="linenos"> 57</span></a><span class="sd">                Defaults to instance&#39;s `call_cell` method.</span>
</span><span id="MultinomialCLM.generate-58"><a href="#MultinomialCLM.generate-58"><span class="linenos"> 58</span></a><span class="sd">            sample_func: Function to sample next tokens.</span>
</span><span id="MultinomialCLM.generate-59"><a href="#MultinomialCLM.generate-59"><span class="linenos"> 59</span></a><span class="sd">                Defaults to instance&#39;s `sample_next_tokens` method.</span>
</span><span id="MultinomialCLM.generate-60"><a href="#MultinomialCLM.generate-60"><span class="linenos"> 60</span></a><span class="sd">            verbose: Verbosity level. Unused. Defaults to 0.</span>
</span><span id="MultinomialCLM.generate-61"><a href="#MultinomialCLM.generate-61"><span class="linenos"> 61</span></a>
</span><span id="MultinomialCLM.generate-62"><a href="#MultinomialCLM.generate-62"><span class="linenos"> 62</span></a><span class="sd">        Returns:</span>
</span><span id="MultinomialCLM.generate-63"><a href="#MultinomialCLM.generate-63"><span class="linenos"> 63</span></a><span class="sd">            Tuple with generated samples [Batches*Batch, Length] {int32}</span>
</span><span id="MultinomialCLM.generate-64"><a href="#MultinomialCLM.generate-64"><span class="linenos"> 64</span></a><span class="sd">            and predictions [Batches*Batch, Length, Vocab] {float32}</span>
</span><span id="MultinomialCLM.generate-65"><a href="#MultinomialCLM.generate-65"><span class="linenos"> 65</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MultinomialCLM.generate-66"><a href="#MultinomialCLM.generate-66"><span class="linenos"> 66</span></a>        <span class="k">del</span> <span class="n">verbose</span>  <span class="c1"># Unused because no progress bar</span>
</span><span id="MultinomialCLM.generate-67"><a href="#MultinomialCLM.generate-67"><span class="linenos"> 67</span></a>        <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</span><span id="MultinomialCLM.generate-68"><a href="#MultinomialCLM.generate-68"><span class="linenos"> 68</span></a>        <span class="c1"># from tfpb import tfpb # noqa: ERA001</span>
</span><span id="MultinomialCLM.generate-69"><a href="#MultinomialCLM.generate-69"><span class="linenos"> 69</span></a>
</span><span id="MultinomialCLM.generate-70"><a href="#MultinomialCLM.generate-70"><span class="linenos"> 70</span></a>        <span class="n">safe_call_func</span><span class="p">:</span> <span class="n">CallFunc</span> <span class="o">=</span> <span class="n">call_func</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">call_cell</span>
</span><span id="MultinomialCLM.generate-71"><a href="#MultinomialCLM.generate-71"><span class="linenos"> 71</span></a>        <span class="n">safe_sample_func</span><span class="p">:</span> <span class="n">SampleFunc</span> <span class="o">=</span> <span class="n">sample_func</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_next_tokens</span>
</span><span id="MultinomialCLM.generate-72"><a href="#MultinomialCLM.generate-72"><span class="linenos"> 72</span></a>
</span><span id="MultinomialCLM.generate-73"><a href="#MultinomialCLM.generate-73"><span class="linenos"> 73</span></a>        <span class="k">if</span> <span class="n">n_batches</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="MultinomialCLM.generate-74"><a href="#MultinomialCLM.generate-74"><span class="linenos"> 74</span></a>            <span class="n">samples</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_batch</span><span class="p">(</span>
</span><span id="MultinomialCLM.generate-75"><a href="#MultinomialCLM.generate-75"><span class="linenos"> 75</span></a>                <span class="n">temp</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">safe_call_func</span><span class="p">,</span> <span class="n">safe_sample_func</span>
</span><span id="MultinomialCLM.generate-76"><a href="#MultinomialCLM.generate-76"><span class="linenos"> 76</span></a>            <span class="p">)</span>
</span><span id="MultinomialCLM.generate-77"><a href="#MultinomialCLM.generate-77"><span class="linenos"> 77</span></a>
</span><span id="MultinomialCLM.generate-78"><a href="#MultinomialCLM.generate-78"><span class="linenos"> 78</span></a>        <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_embedding</span> <span class="k">else</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span>
</span><span id="MultinomialCLM.generate-79"><a href="#MultinomialCLM.generate-79"><span class="linenos"> 79</span></a>        <span class="n">samples</span> <span class="o">=</span> <span class="n">init_tensor_array</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">n_batches</span><span class="p">)</span>
</span><span id="MultinomialCLM.generate-80"><a href="#MultinomialCLM.generate-80"><span class="linenos"> 80</span></a>        <span class="n">preds</span> <span class="o">=</span> <span class="n">init_tensor_array</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">n_batches</span><span class="p">)</span>
</span><span id="MultinomialCLM.generate-81"><a href="#MultinomialCLM.generate-81"><span class="linenos"> 81</span></a>
</span><span id="MultinomialCLM.generate-82"><a href="#MultinomialCLM.generate-82"><span class="linenos"> 82</span></a>        <span class="c1"># Define recurrence function to generate batches</span>
</span><span id="MultinomialCLM.generate-83"><a href="#MultinomialCLM.generate-83"><span class="linenos"> 83</span></a>
</span><span id="MultinomialCLM.generate-84"><a href="#MultinomialCLM.generate-84"><span class="linenos"> 84</span></a>        <span class="c1"># pb = tfpb(desc=&quot;Generating samples&quot;, total=n_batches, disable=verbose &lt; 1) # noqa: ERA001,E501</span>
</span><span id="MultinomialCLM.generate-85"><a href="#MultinomialCLM.generate-85"><span class="linenos"> 85</span></a>        <span class="n">start</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">timestamp</span><span class="p">()</span>
</span><span id="MultinomialCLM.generate-86"><a href="#MultinomialCLM.generate-86"><span class="linenos"> 86</span></a>
</span><span id="MultinomialCLM.generate-87"><a href="#MultinomialCLM.generate-87"><span class="linenos"> 87</span></a>        <span class="k">def</span> <span class="nf">_g_recurrence</span><span class="p">(</span>
</span><span id="MultinomialCLM.generate-88"><a href="#MultinomialCLM.generate-88"><span class="linenos"> 88</span></a>            <span class="n">ix</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="MultinomialCLM.generate-89"><a href="#MultinomialCLM.generate-89"><span class="linenos"> 89</span></a>            <span class="n">last</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="MultinomialCLM.generate-90"><a href="#MultinomialCLM.generate-90"><span class="linenos"> 90</span></a>            <span class="n">samples</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorArray</span><span class="p">,</span>
</span><span id="MultinomialCLM.generate-91"><a href="#MultinomialCLM.generate-91"><span class="linenos"> 91</span></a>            <span class="n">preds</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorArray</span><span class="p">,</span>
</span><span id="MultinomialCLM.generate-92"><a href="#MultinomialCLM.generate-92"><span class="linenos"> 92</span></a>        <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorArray</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorArray</span><span class="p">]:</span>
</span><span id="MultinomialCLM.generate-93"><a href="#MultinomialCLM.generate-93"><span class="linenos"> 93</span></a>            <span class="c1"># Generate batch of samples</span>
</span><span id="MultinomialCLM.generate-94"><a href="#MultinomialCLM.generate-94"><span class="linenos"> 94</span></a>            <span class="c1"># if embedding: [Batch, Length] {int32}</span>
</span><span id="MultinomialCLM.generate-95"><a href="#MultinomialCLM.generate-95"><span class="linenos"> 95</span></a>            <span class="c1"># else: [Batch, Length, Vocab] {float32} # noqa: ERA001</span>
</span><span id="MultinomialCLM.generate-96"><a href="#MultinomialCLM.generate-96"><span class="linenos"> 96</span></a>
</span><span id="MultinomialCLM.generate-97"><a href="#MultinomialCLM.generate-97"><span class="linenos"> 97</span></a>            <span class="c1"># If return_preds is True, unpack samples and predictions and</span>
</span><span id="MultinomialCLM.generate-98"><a href="#MultinomialCLM.generate-98"><span class="linenos"> 98</span></a>            <span class="c1"># append predictions to TensorArray</span>
</span><span id="MultinomialCLM.generate-99"><a href="#MultinomialCLM.generate-99"><span class="linenos"> 99</span></a>            <span class="c1"># if return_preds: type of preds is tf.TensorArray and</span>
</span><span id="MultinomialCLM.generate-100"><a href="#MultinomialCLM.generate-100"><span class="linenos">100</span></a>            <span class="c1"># type _samples is tuple[tf.Tensor, tf.Tensor]</span>
</span><span id="MultinomialCLM.generate-101"><a href="#MultinomialCLM.generate-101"><span class="linenos">101</span></a>            <span class="n">samples_batch</span><span class="p">,</span> <span class="n">preds_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_batch</span><span class="p">(</span>
</span><span id="MultinomialCLM.generate-102"><a href="#MultinomialCLM.generate-102"><span class="linenos">102</span></a>                <span class="n">temp</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">safe_call_func</span><span class="p">,</span> <span class="n">safe_sample_func</span>
</span><span id="MultinomialCLM.generate-103"><a href="#MultinomialCLM.generate-103"><span class="linenos">103</span></a>            <span class="p">)</span>
</span><span id="MultinomialCLM.generate-104"><a href="#MultinomialCLM.generate-104"><span class="linenos">104</span></a>            <span class="n">preds</span> <span class="o">=</span> <span class="n">preds</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">ix</span><span class="p">,</span> <span class="n">preds_batch</span><span class="p">)</span>
</span><span id="MultinomialCLM.generate-105"><a href="#MultinomialCLM.generate-105"><span class="linenos">105</span></a>
</span><span id="MultinomialCLM.generate-106"><a href="#MultinomialCLM.generate-106"><span class="linenos">106</span></a>            <span class="c1"># Append samples to TensorArray</span>
</span><span id="MultinomialCLM.generate-107"><a href="#MultinomialCLM.generate-107"><span class="linenos">107</span></a>            <span class="n">samples</span> <span class="o">=</span> <span class="n">samples</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">ix</span><span class="p">,</span> <span class="n">samples_batch</span><span class="p">)</span>
</span><span id="MultinomialCLM.generate-108"><a href="#MultinomialCLM.generate-108"><span class="linenos">108</span></a>
</span><span id="MultinomialCLM.generate-109"><a href="#MultinomialCLM.generate-109"><span class="linenos">109</span></a>            <span class="n">new_ix</span> <span class="o">=</span> <span class="n">ix</span> <span class="o">+</span> <span class="mi">1</span>
</span><span id="MultinomialCLM.generate-110"><a href="#MultinomialCLM.generate-110"><span class="linenos">110</span></a>            <span class="c1"># new_ix, last = pb.update(ix, last, start) # noqa: ERA001</span>
</span><span id="MultinomialCLM.generate-111"><a href="#MultinomialCLM.generate-111"><span class="linenos">111</span></a>
</span><span id="MultinomialCLM.generate-112"><a href="#MultinomialCLM.generate-112"><span class="linenos">112</span></a>            <span class="k">return</span> <span class="n">new_ix</span><span class="p">,</span> <span class="n">last</span><span class="p">,</span> <span class="n">samples</span><span class="p">,</span> <span class="n">preds</span>
</span><span id="MultinomialCLM.generate-113"><a href="#MultinomialCLM.generate-113"><span class="linenos">113</span></a>
</span><span id="MultinomialCLM.generate-114"><a href="#MultinomialCLM.generate-114"><span class="linenos">114</span></a>        <span class="c1"># Generate batches using recurrence function</span>
</span><span id="MultinomialCLM.generate-115"><a href="#MultinomialCLM.generate-115"><span class="linenos">115</span></a>
</span><span id="MultinomialCLM.generate-116"><a href="#MultinomialCLM.generate-116"><span class="linenos">116</span></a>        <span class="n">loop_output</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorArray</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorArray</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="MultinomialCLM.generate-117"><a href="#MultinomialCLM.generate-117"><span class="linenos">117</span></a>            <span class="n">tf</span><span class="o">.</span><span class="n">while_loop</span><span class="p">(</span>
</span><span id="MultinomialCLM.generate-118"><a href="#MultinomialCLM.generate-118"><span class="linenos">118</span></a>                <span class="n">cond</span><span class="o">=</span><span class="k">lambda</span> <span class="n">i</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span><span class="p">:</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">n_batches</span><span class="p">,</span>
</span><span id="MultinomialCLM.generate-119"><a href="#MultinomialCLM.generate-119"><span class="linenos">119</span></a>                <span class="n">body</span><span class="o">=</span><span class="n">_g_recurrence</span><span class="p">,</span>
</span><span id="MultinomialCLM.generate-120"><a href="#MultinomialCLM.generate-120"><span class="linenos">120</span></a>                <span class="n">loop_vars</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">samples</span><span class="p">,</span> <span class="n">preds</span><span class="p">),</span>
</span><span id="MultinomialCLM.generate-121"><a href="#MultinomialCLM.generate-121"><span class="linenos">121</span></a>            <span class="p">)</span>
</span><span id="MultinomialCLM.generate-122"><a href="#MultinomialCLM.generate-122"><span class="linenos">122</span></a>        <span class="p">)</span>
</span><span id="MultinomialCLM.generate-123"><a href="#MultinomialCLM.generate-123"><span class="linenos">123</span></a>
</span><span id="MultinomialCLM.generate-124"><a href="#MultinomialCLM.generate-124"><span class="linenos">124</span></a>        <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">samples</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">loop_output</span>
</span><span id="MultinomialCLM.generate-125"><a href="#MultinomialCLM.generate-125"><span class="linenos">125</span></a>
</span><span id="MultinomialCLM.generate-126"><a href="#MultinomialCLM.generate-126"><span class="linenos">126</span></a>        <span class="c1"># Stack generated batches into final output</span>
</span><span id="MultinomialCLM.generate-127"><a href="#MultinomialCLM.generate-127"><span class="linenos">127</span></a>        <span class="c1"># [Batches*Batch, Length] {int32} if embedding else {float32}</span>
</span><span id="MultinomialCLM.generate-128"><a href="#MultinomialCLM.generate-128"><span class="linenos">128</span></a>        <span class="n">joined_samples</span> <span class="o">=</span> <span class="n">samples</span><span class="o">.</span><span class="n">concat</span><span class="p">()</span>
</span><span id="MultinomialCLM.generate-129"><a href="#MultinomialCLM.generate-129"><span class="linenos">129</span></a>
</span><span id="MultinomialCLM.generate-130"><a href="#MultinomialCLM.generate-130"><span class="linenos">130</span></a>        <span class="c1"># stack predictions into final output</span>
</span><span id="MultinomialCLM.generate-131"><a href="#MultinomialCLM.generate-131"><span class="linenos">131</span></a>        <span class="c1"># [Batches*Batch, Length, Vocab] {float32}</span>
</span><span id="MultinomialCLM.generate-132"><a href="#MultinomialCLM.generate-132"><span class="linenos">132</span></a>        <span class="c1"># and return samples and predictions</span>
</span><span id="MultinomialCLM.generate-133"><a href="#MultinomialCLM.generate-133"><span class="linenos">133</span></a>
</span><span id="MultinomialCLM.generate-134"><a href="#MultinomialCLM.generate-134"><span class="linenos">134</span></a>        <span class="n">joined_preds</span> <span class="o">=</span> <span class="n">preds</span><span class="o">.</span><span class="n">concat</span><span class="p">()</span>
</span><span id="MultinomialCLM.generate-135"><a href="#MultinomialCLM.generate-135"><span class="linenos">135</span></a>        <span class="k">return</span> <span class="n">joined_samples</span><span class="p">,</span> <span class="n">joined_preds</span>
</span></pre></div>


            <div class="docstring"><p>Generate multiple batches of samples (wrapped in a tf.function).</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>n_batches:</strong>  Number of batches to generate.</li>
<li><strong>temp:</strong>  Temperature factor. Defaults to 1.0.</li>
<li><strong>batch_size:</strong>  Batch size for generation. Defaults to 1024.</li>
<li><strong>call_func:</strong>  Function to call model for one time step.
Defaults to instance's <code><a href="#MultinomialCLM.call_cell">call_cell</a></code> method.</li>
<li><strong>sample_func:</strong>  Function to sample next tokens.
Defaults to instance's <code><a href="#MultinomialCLM.sample_next_tokens">sample_next_tokens</a></code> method.</li>
<li><strong>verbose:</strong>  Verbosity level. Unused. Defaults to 0.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>Tuple with generated samples [Batches<em>Batch, Length] {int32}
  and predictions [Batches</em>Batch, Length, Vocab] {float32}</p>
</blockquote>
</div>


                            </div>
                            <div id="MultinomialCLM.sample_next_tokens" class="classattr">
                                        <input id="MultinomialCLM.sample_next_tokens-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-tf_kw_func_wrapper">@tf_kw_func_wrapper(input_signature=[tf_tensor_spec(shape=(), dtype=tf_dtype.int32), tf_tensor_spec(shape=[None, None], dtype=tf_dtype.float32), tf_tensor_spec(shape=(), dtype=tf_dtype.float64)])</div>

        <span class="def">def</span>
        <span class="name">sample_next_tokens</span><span class="signature pdoc-code multiline">(<span class="param">   <span class="bp">self</span>,</span><span class="param">    <span class="n">i</span><span class="p">:</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span>,</span><span class="param">  <span class="n">x_t</span><span class="p">:</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span>,</span><span class="param">    <span class="o">/</span>,</span><span class="param">    <span class="n">temp</span><span class="p">:</span> <span class="nb">float</span></span><span class="return-annotation">) -> <span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span>:</span></span>

                <label class="view-source-button" for="MultinomialCLM.sample_next_tokens-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#MultinomialCLM.sample_next_tokens"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="MultinomialCLM.sample_next_tokens-137"><a href="#MultinomialCLM.sample_next_tokens-137"><span class="linenos">137</span></a>    <span class="nd">@tf_kw_func_wrapper</span><span class="p">(</span>
</span><span id="MultinomialCLM.sample_next_tokens-138"><a href="#MultinomialCLM.sample_next_tokens-138"><span class="linenos">138</span></a>        <span class="n">input_signature</span><span class="o">=</span><span class="p">[</span>
</span><span id="MultinomialCLM.sample_next_tokens-139"><a href="#MultinomialCLM.sample_next_tokens-139"><span class="linenos">139</span></a>            <span class="n">tf_tensor_spec</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf_dtype</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
</span><span id="MultinomialCLM.sample_next_tokens-140"><a href="#MultinomialCLM.sample_next_tokens-140"><span class="linenos">140</span></a>            <span class="n">tf_tensor_spec</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf_dtype</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
</span><span id="MultinomialCLM.sample_next_tokens-141"><a href="#MultinomialCLM.sample_next_tokens-141"><span class="linenos">141</span></a>            <span class="n">tf_tensor_spec</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf_dtype</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span>
</span><span id="MultinomialCLM.sample_next_tokens-142"><a href="#MultinomialCLM.sample_next_tokens-142"><span class="linenos">142</span></a>        <span class="p">]</span>
</span><span id="MultinomialCLM.sample_next_tokens-143"><a href="#MultinomialCLM.sample_next_tokens-143"><span class="linenos">143</span></a>    <span class="p">)</span>
</span><span id="MultinomialCLM.sample_next_tokens-144"><a href="#MultinomialCLM.sample_next_tokens-144"><span class="linenos">144</span></a>    <span class="k">def</span> <span class="nf">sample_next_tokens</span><span class="p">(</span>
</span><span id="MultinomialCLM.sample_next_tokens-145"><a href="#MultinomialCLM.sample_next_tokens-145"><span class="linenos">145</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">x_t</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">/</span><span class="p">,</span> <span class="n">temp</span><span class="p">:</span> <span class="nb">float</span>
</span><span id="MultinomialCLM.sample_next_tokens-146"><a href="#MultinomialCLM.sample_next_tokens-146"><span class="linenos">146</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="MultinomialCLM.sample_next_tokens-147"><a href="#MultinomialCLM.sample_next_tokens-147"><span class="linenos">147</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Multinomially sample next tokens from the output (wrapped in a tf.function).</span>
</span><span id="MultinomialCLM.sample_next_tokens-148"><a href="#MultinomialCLM.sample_next_tokens-148"><span class="linenos">148</span></a>
</span><span id="MultinomialCLM.sample_next_tokens-149"><a href="#MultinomialCLM.sample_next_tokens-149"><span class="linenos">149</span></a><span class="sd">        Args:</span>
</span><span id="MultinomialCLM.sample_next_tokens-150"><a href="#MultinomialCLM.sample_next_tokens-150"><span class="linenos">150</span></a><span class="sd">            i: Current time step. [1] {int32}.</span>
</span><span id="MultinomialCLM.sample_next_tokens-151"><a href="#MultinomialCLM.sample_next_tokens-151"><span class="linenos">151</span></a><span class="sd">            x_t: Model output [Batch, Vocab] {float32}.</span>
</span><span id="MultinomialCLM.sample_next_tokens-152"><a href="#MultinomialCLM.sample_next_tokens-152"><span class="linenos">152</span></a><span class="sd">            temp: Temperature factor. [1]</span>
</span><span id="MultinomialCLM.sample_next_tokens-153"><a href="#MultinomialCLM.sample_next_tokens-153"><span class="linenos">153</span></a>
</span><span id="MultinomialCLM.sample_next_tokens-154"><a href="#MultinomialCLM.sample_next_tokens-154"><span class="linenos">154</span></a><span class="sd">        Returns:</span>
</span><span id="MultinomialCLM.sample_next_tokens-155"><a href="#MultinomialCLM.sample_next_tokens-155"><span class="linenos">155</span></a><span class="sd">            Sampled next tokens [Batch] {int32}.</span>
</span><span id="MultinomialCLM.sample_next_tokens-156"><a href="#MultinomialCLM.sample_next_tokens-156"><span class="linenos">156</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MultinomialCLM.sample_next_tokens-157"><a href="#MultinomialCLM.sample_next_tokens-157"><span class="linenos">157</span></a>        <span class="k">del</span> <span class="n">i</span>  <span class="c1"># Multinomial sampling does not depend on the current time step</span>
</span><span id="MultinomialCLM.sample_next_tokens-158"><a href="#MultinomialCLM.sample_next_tokens-158"><span class="linenos">158</span></a>        <span class="k">return</span> <span class="n">multinomial_sample</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">temp</span><span class="o">=</span><span class="n">temp</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Multinomially sample next tokens from the output (wrapped in a tf.function).</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>i:</strong>  Current time step. [1] {int32}.</li>
<li><strong>x_t:</strong>  Model output [Batch, Vocab] {float32}.</li>
<li><strong>temp:</strong>  Temperature factor. [1]</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>Sampled next tokens [Batch] {int32}.</p>
</blockquote>
</div>


                            </div>
                            <div id="MultinomialCLM.generate_with_perplexity" class="classattr">
                                        <input id="MultinomialCLM.generate_with_perplexity-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">

        <span class="def">def</span>
        <span class="name">generate_with_perplexity</span><span class="signature pdoc-code multiline">(<span class="param"> <span class="bp">self</span>,</span><span class="param">    <span class="n">n_batches</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>,</span><span class="param"> <span class="n">temp</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span>,</span><span class="param">  <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span>,</span><span class="param"> <span class="n">prior_probs</span><span class="p">:</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">lookup_ops</span><span class="o">.</span><span class="n">StaticHashTable</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">  <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span></span><span class="return-annotation">) -> <span class="nb">tuple</span><span class="p">[</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span>:</span></span>

                <label class="view-source-button" for="MultinomialCLM.generate_with_perplexity-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#MultinomialCLM.generate_with_perplexity"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="MultinomialCLM.generate_with_perplexity-257"><a href="#MultinomialCLM.generate_with_perplexity-257"><span class="linenos">257</span></a>    <span class="k">def</span> <span class="nf">generate_with_perplexity</span><span class="p">(</span>
</span><span id="MultinomialCLM.generate_with_perplexity-258"><a href="#MultinomialCLM.generate_with_perplexity-258"><span class="linenos">258</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="MultinomialCLM.generate_with_perplexity-259"><a href="#MultinomialCLM.generate_with_perplexity-259"><span class="linenos">259</span></a>        <span class="n">n_batches</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="MultinomialCLM.generate_with_perplexity-260"><a href="#MultinomialCLM.generate_with_perplexity-260"><span class="linenos">260</span></a>        <span class="n">temp</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
</span><span id="MultinomialCLM.generate_with_perplexity-261"><a href="#MultinomialCLM.generate_with_perplexity-261"><span class="linenos">261</span></a>        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span>
</span><span id="MultinomialCLM.generate_with_perplexity-262"><a href="#MultinomialCLM.generate_with_perplexity-262"><span class="linenos">262</span></a>        <span class="n">prior_probs</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">lookup</span><span class="o">.</span><span class="n">StaticHashTable</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="MultinomialCLM.generate_with_perplexity-263"><a href="#MultinomialCLM.generate_with_perplexity-263"><span class="linenos">263</span></a>        <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="MultinomialCLM.generate_with_perplexity-264"><a href="#MultinomialCLM.generate_with_perplexity-264"><span class="linenos">264</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
</span><span id="MultinomialCLM.generate_with_perplexity-265"><a href="#MultinomialCLM.generate_with_perplexity-265"><span class="linenos">265</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate samples with perplexity calculation from a model.</span>
</span><span id="MultinomialCLM.generate_with_perplexity-266"><a href="#MultinomialCLM.generate_with_perplexity-266"><span class="linenos">266</span></a>
</span><span id="MultinomialCLM.generate_with_perplexity-267"><a href="#MultinomialCLM.generate_with_perplexity-267"><span class="linenos">267</span></a><span class="sd">        Args:</span>
</span><span id="MultinomialCLM.generate_with_perplexity-268"><a href="#MultinomialCLM.generate_with_perplexity-268"><span class="linenos">268</span></a><span class="sd">            n_batches: Number of batches to generate. Defaults to 1.</span>
</span><span id="MultinomialCLM.generate_with_perplexity-269"><a href="#MultinomialCLM.generate_with_perplexity-269"><span class="linenos">269</span></a><span class="sd">            temp: Temperature factor. Defaults to 1.0.</span>
</span><span id="MultinomialCLM.generate_with_perplexity-270"><a href="#MultinomialCLM.generate_with_perplexity-270"><span class="linenos">270</span></a><span class="sd">            batch_size: Batch size for generation. Defaults to 1024.</span>
</span><span id="MultinomialCLM.generate_with_perplexity-271"><a href="#MultinomialCLM.generate_with_perplexity-271"><span class="linenos">271</span></a><span class="sd">            prior_probs: Prior probabilities for each token.</span>
</span><span id="MultinomialCLM.generate_with_perplexity-272"><a href="#MultinomialCLM.generate_with_perplexity-272"><span class="linenos">272</span></a><span class="sd">                Defaults to equal probabilities for each non-special token.</span>
</span><span id="MultinomialCLM.generate_with_perplexity-273"><a href="#MultinomialCLM.generate_with_perplexity-273"><span class="linenos">273</span></a><span class="sd">            verbose: Verbosity level. Defaults to 0.</span>
</span><span id="MultinomialCLM.generate_with_perplexity-274"><a href="#MultinomialCLM.generate_with_perplexity-274"><span class="linenos">274</span></a>
</span><span id="MultinomialCLM.generate_with_perplexity-275"><a href="#MultinomialCLM.generate_with_perplexity-275"><span class="linenos">275</span></a><span class="sd">        Returns:</span>
</span><span id="MultinomialCLM.generate_with_perplexity-276"><a href="#MultinomialCLM.generate_with_perplexity-276"><span class="linenos">276</span></a><span class="sd">            Tuple with generated samples [Batches*Batch, Length] {int32} and</span>
</span><span id="MultinomialCLM.generate_with_perplexity-277"><a href="#MultinomialCLM.generate_with_perplexity-277"><span class="linenos">277</span></a><span class="sd">            predictions [Batches*Batch, Length, Vocab] {float32} and</span>
</span><span id="MultinomialCLM.generate_with_perplexity-278"><a href="#MultinomialCLM.generate_with_perplexity-278"><span class="linenos">278</span></a><span class="sd">            perplexity scores [Batches*Batch] {float32}</span>
</span><span id="MultinomialCLM.generate_with_perplexity-279"><a href="#MultinomialCLM.generate_with_perplexity-279"><span class="linenos">279</span></a>
</span><span id="MultinomialCLM.generate_with_perplexity-280"><a href="#MultinomialCLM.generate_with_perplexity-280"><span class="linenos">280</span></a><span class="sd">        Raises:</span>
</span><span id="MultinomialCLM.generate_with_perplexity-281"><a href="#MultinomialCLM.generate_with_perplexity-281"><span class="linenos">281</span></a><span class="sd">            ValueError: If vocabulary is not provided.</span>
</span><span id="MultinomialCLM.generate_with_perplexity-282"><a href="#MultinomialCLM.generate_with_perplexity-282"><span class="linenos">282</span></a><span class="sd">                Set on instance creation or set `vocab` attribute.</span>
</span><span id="MultinomialCLM.generate_with_perplexity-283"><a href="#MultinomialCLM.generate_with_perplexity-283"><span class="linenos">283</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="MultinomialCLM.generate_with_perplexity-284"><a href="#MultinomialCLM.generate_with_perplexity-284"><span class="linenos">284</span></a>        <span class="k">if</span> <span class="n">prior_probs</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="MultinomialCLM.generate_with_perplexity-285"><a href="#MultinomialCLM.generate_with_perplexity-285"><span class="linenos">285</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;prior_probs or vocab is required for this model&quot;</span><span class="p">)</span>
</span><span id="MultinomialCLM.generate_with_perplexity-286"><a href="#MultinomialCLM.generate_with_perplexity-286"><span class="linenos">286</span></a>
</span><span id="MultinomialCLM.generate_with_perplexity-287"><a href="#MultinomialCLM.generate_with_perplexity-287"><span class="linenos">287</span></a>        <span class="k">return</span> <span class="n">generate_with_perplexity</span><span class="p">(</span>
</span><span id="MultinomialCLM.generate_with_perplexity-288"><a href="#MultinomialCLM.generate_with_perplexity-288"><span class="linenos">288</span></a>            <span class="bp">self</span><span class="p">,</span> <span class="n">n_batches</span><span class="p">,</span> <span class="n">temp</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">prior_probs</span><span class="p">,</span> <span class="n">verbose</span>
</span><span id="MultinomialCLM.generate_with_perplexity-289"><a href="#MultinomialCLM.generate_with_perplexity-289"><span class="linenos">289</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Generate samples with perplexity calculation from a model.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>n_batches:</strong>  Number of batches to generate. Defaults to 1.</li>
<li><strong>temp:</strong>  Temperature factor. Defaults to 1.0.</li>
<li><strong>batch_size:</strong>  Batch size for generation. Defaults to 1024.</li>
<li><strong>prior_probs:</strong>  Prior probabilities for each token.
Defaults to equal probabilities for each non-special token.</li>
<li><strong>verbose:</strong>  Verbosity level. Defaults to 0.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>Tuple with generated samples [Batches<em>Batch, Length] {int32} and
  predictions [Batches</em>Batch, Length, Vocab] {float32} and
  perplexity scores [Batches*Batch] {float32}</p>
</blockquote>

<h6 id="raises">Raises:</h6>

<ul>
<li><strong>ValueError:</strong>  If vocabulary is not provided.
Set on instance creation or set <code>vocab</code> attribute.</li>
</ul>
</div>


                            </div>
                </section>
                <section id="Trainer">
                            <input id="Trainer-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">

    <span class="def">class</span>
    <span class="name">Trainer</span>:

                <label class="view-source-button" for="Trainer-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Trainer"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Trainer-39"><a href="#Trainer-39"><span class="linenos"> 39</span></a><span class="k">class</span> <span class="nc">Trainer</span><span class="p">:</span>
</span><span id="Trainer-40"><a href="#Trainer-40"><span class="linenos"> 40</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Convenience class to train a model with a :class:`RandomizedDataset`.&quot;&quot;&quot;</span>
</span><span id="Trainer-41"><a href="#Trainer-41"><span class="linenos"> 41</span></a>
</span><span id="Trainer-42"><a href="#Trainer-42"><span class="linenos"> 42</span></a>    <span class="nd">@staticmethod</span>
</span><span id="Trainer-43"><a href="#Trainer-43"><span class="linenos"> 43</span></a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
</span><span id="Trainer-44"><a href="#Trainer-44"><span class="linenos"> 44</span></a>        <span class="n">model</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">,</span>
</span><span id="Trainer-45"><a href="#Trainer-45"><span class="linenos"> 45</span></a>        <span class="n">train</span><span class="p">:</span> <span class="n">RandomizedDataset</span><span class="p">,</span>
</span><span id="Trainer-46"><a href="#Trainer-46"><span class="linenos"> 46</span></a>        <span class="n">val</span><span class="p">:</span> <span class="n">RandomizedDataset</span><span class="p">,</span>
</span><span id="Trainer-47"><a href="#Trainer-47"><span class="linenos"> 47</span></a>        <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="Trainer-48"><a href="#Trainer-48"><span class="linenos"> 48</span></a>        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="Trainer-49"><a href="#Trainer-49"><span class="linenos"> 49</span></a>        <span class="n">callbacks</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">Callback</span><span class="p">],</span>
</span><span id="Trainer-50"><a href="#Trainer-50"><span class="linenos"> 50</span></a>        <span class="n">strategy</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">Strategy</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="Trainer-51"><a href="#Trainer-51"><span class="linenos"> 51</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">History</span><span class="p">:</span>
</span><span id="Trainer-52"><a href="#Trainer-52"><span class="linenos"> 52</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Fit the model.</span>
</span><span id="Trainer-53"><a href="#Trainer-53"><span class="linenos"> 53</span></a>
</span><span id="Trainer-54"><a href="#Trainer-54"><span class="linenos"> 54</span></a><span class="sd">        Args:</span>
</span><span id="Trainer-55"><a href="#Trainer-55"><span class="linenos"> 55</span></a><span class="sd">            model: The model</span>
</span><span id="Trainer-56"><a href="#Trainer-56"><span class="linenos"> 56</span></a><span class="sd">            train: The training dataset</span>
</span><span id="Trainer-57"><a href="#Trainer-57"><span class="linenos"> 57</span></a><span class="sd">            val: The validation dataset</span>
</span><span id="Trainer-58"><a href="#Trainer-58"><span class="linenos"> 58</span></a><span class="sd">            epochs: The number of epochs</span>
</span><span id="Trainer-59"><a href="#Trainer-59"><span class="linenos"> 59</span></a><span class="sd">            batch_size: The batch size</span>
</span><span id="Trainer-60"><a href="#Trainer-60"><span class="linenos"> 60</span></a><span class="sd">            callbacks: The list of callbacks</span>
</span><span id="Trainer-61"><a href="#Trainer-61"><span class="linenos"> 61</span></a><span class="sd">            strategy: The strategy. Defaults to None.</span>
</span><span id="Trainer-62"><a href="#Trainer-62"><span class="linenos"> 62</span></a>
</span><span id="Trainer-63"><a href="#Trainer-63"><span class="linenos"> 63</span></a><span class="sd">        Returns:</span>
</span><span id="Trainer-64"><a href="#Trainer-64"><span class="linenos"> 64</span></a><span class="sd">            The history of the training</span>
</span><span id="Trainer-65"><a href="#Trainer-65"><span class="linenos"> 65</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Trainer-66"><a href="#Trainer-66"><span class="linenos"> 66</span></a>        <span class="n">built_train</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">build_dataset</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">strategy</span><span class="p">)</span>
</span><span id="Trainer-67"><a href="#Trainer-67"><span class="linenos"> 67</span></a>        <span class="n">built_val</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">build_dataset</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">strategy</span><span class="p">)</span>
</span><span id="Trainer-68"><a href="#Trainer-68"><span class="linenos"> 68</span></a>
</span><span id="Trainer-69"><a href="#Trainer-69"><span class="linenos"> 69</span></a>        <span class="k">return</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
</span><span id="Trainer-70"><a href="#Trainer-70"><span class="linenos"> 70</span></a>            <span class="n">built_train</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span>
</span><span id="Trainer-71"><a href="#Trainer-71"><span class="linenos"> 71</span></a>            <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
</span><span id="Trainer-72"><a href="#Trainer-72"><span class="linenos"> 72</span></a>            <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">built_train</span><span class="o">.</span><span class="n">steps</span><span class="p">,</span>
</span><span id="Trainer-73"><a href="#Trainer-73"><span class="linenos"> 73</span></a>            <span class="n">validation_data</span><span class="o">=</span><span class="n">built_val</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span>
</span><span id="Trainer-74"><a href="#Trainer-74"><span class="linenos"> 74</span></a>            <span class="n">validation_steps</span><span class="o">=</span><span class="n">built_val</span><span class="o">.</span><span class="n">steps</span><span class="p">,</span>
</span><span id="Trainer-75"><a href="#Trainer-75"><span class="linenos"> 75</span></a>            <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>
</span><span id="Trainer-76"><a href="#Trainer-76"><span class="linenos"> 76</span></a>            <span class="n">initial_epoch</span><span class="o">=</span><span class="n">built_train</span><span class="o">.</span><span class="n">init_epoch</span><span class="p">,</span>
</span><span id="Trainer-77"><a href="#Trainer-77"><span class="linenos"> 77</span></a>        <span class="p">)</span>
</span><span id="Trainer-78"><a href="#Trainer-78"><span class="linenos"> 78</span></a>
</span><span id="Trainer-79"><a href="#Trainer-79"><span class="linenos"> 79</span></a>    <span class="nd">@staticmethod</span>
</span><span id="Trainer-80"><a href="#Trainer-80"><span class="linenos"> 80</span></a>    <span class="k">def</span> <span class="nf">callbacks</span><span class="p">(</span>
</span><span id="Trainer-81"><a href="#Trainer-81"><span class="linenos"> 81</span></a>        <span class="n">clm</span><span class="p">:</span> <span class="n">MultinomialCLM</span><span class="p">,</span>
</span><span id="Trainer-82"><a href="#Trainer-82"><span class="linenos"> 82</span></a>        <span class="n">train</span><span class="p">:</span> <span class="n">RandomizedDataset</span><span class="p">,</span>
</span><span id="Trainer-83"><a href="#Trainer-83"><span class="linenos"> 83</span></a>        <span class="n">val</span><span class="p">:</span> <span class="n">RandomizedDataset</span><span class="p">,</span>
</span><span id="Trainer-84"><a href="#Trainer-84"><span class="linenos"> 84</span></a>        <span class="n">cp</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="Trainer-85"><a href="#Trainer-85"><span class="linenos"> 85</span></a>        <span class="n">calc_jsd</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="Trainer-86"><a href="#Trainer-86"><span class="linenos"> 86</span></a>        <span class="n">decay</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="Trainer-87"><a href="#Trainer-87"><span class="linenos"> 87</span></a>        <span class="n">models_path</span><span class="p">:</span> <span class="n">Path</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="Trainer-88"><a href="#Trainer-88"><span class="linenos"> 88</span></a>        <span class="n">early_stopping</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="Trainer-89"><a href="#Trainer-89"><span class="linenos"> 89</span></a>        <span class="n">additional_cbs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">Callback</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="Trainer-90"><a href="#Trainer-90"><span class="linenos"> 90</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">Callback</span><span class="p">]:</span>
</span><span id="Trainer-91"><a href="#Trainer-91"><span class="linenos"> 91</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the callbacks for training.</span>
</span><span id="Trainer-92"><a href="#Trainer-92"><span class="linenos"> 92</span></a>
</span><span id="Trainer-93"><a href="#Trainer-93"><span class="linenos"> 93</span></a><span class="sd">        - Additional positions:</span>
</span><span id="Trainer-94"><a href="#Trainer-94"><span class="linenos"> 94</span></a><span class="sd">            - 0 at beginning,</span>
</span><span id="Trainer-95"><a href="#Trainer-95"><span class="linenos"> 95</span></a><span class="sd">            - 1 after JSD,</span>
</span><span id="Trainer-96"><a href="#Trainer-96"><span class="linenos"> 96</span></a><span class="sd">            - 2 after decay,</span>
</span><span id="Trainer-97"><a href="#Trainer-97"><span class="linenos"> 97</span></a><span class="sd">            - 3 after checkpoint,</span>
</span><span id="Trainer-98"><a href="#Trainer-98"><span class="linenos"> 98</span></a><span class="sd">            - 4 after trainingCP,</span>
</span><span id="Trainer-99"><a href="#Trainer-99"><span class="linenos"> 99</span></a><span class="sd">            - 5 after early stopping</span>
</span><span id="Trainer-100"><a href="#Trainer-100"><span class="linenos">100</span></a><span class="sd">        - TODO: make the int as enum for add_cbs.</span>
</span><span id="Trainer-101"><a href="#Trainer-101"><span class="linenos">101</span></a>
</span><span id="Trainer-102"><a href="#Trainer-102"><span class="linenos">102</span></a><span class="sd">        Args:</span>
</span><span id="Trainer-103"><a href="#Trainer-103"><span class="linenos">103</span></a><span class="sd">            clm: The CLM</span>
</span><span id="Trainer-104"><a href="#Trainer-104"><span class="linenos">104</span></a><span class="sd">            train: The training dataset</span>
</span><span id="Trainer-105"><a href="#Trainer-105"><span class="linenos">105</span></a><span class="sd">            val: The validation dataset</span>
</span><span id="Trainer-106"><a href="#Trainer-106"><span class="linenos">106</span></a><span class="sd">            cp: The checkpoint to load. Defaults to None.</span>
</span><span id="Trainer-107"><a href="#Trainer-107"><span class="linenos">107</span></a><span class="sd">            calc_jsd: Whether to calc the JSD. Defaults to False.</span>
</span><span id="Trainer-108"><a href="#Trainer-108"><span class="linenos">108</span></a><span class="sd">            decay: The decay storer. Defaults to None.</span>
</span><span id="Trainer-109"><a href="#Trainer-109"><span class="linenos">109</span></a><span class="sd">            models_path: The _path to store the models. Defaults to None.</span>
</span><span id="Trainer-110"><a href="#Trainer-110"><span class="linenos">110</span></a><span class="sd">            early_stopping: The early stopping. Defaults to None.</span>
</span><span id="Trainer-111"><a href="#Trainer-111"><span class="linenos">111</span></a><span class="sd">            additional_cbs: Additional callbacks to add at specific positions.</span>
</span><span id="Trainer-112"><a href="#Trainer-112"><span class="linenos">112</span></a><span class="sd">                Defaults to empty dict.</span>
</span><span id="Trainer-113"><a href="#Trainer-113"><span class="linenos">113</span></a>
</span><span id="Trainer-114"><a href="#Trainer-114"><span class="linenos">114</span></a><span class="sd">        Returns:</span>
</span><span id="Trainer-115"><a href="#Trainer-115"><span class="linenos">115</span></a><span class="sd">            The list of callbacks</span>
</span><span id="Trainer-116"><a href="#Trainer-116"><span class="linenos">116</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Trainer-117"><a href="#Trainer-117"><span class="linenos">117</span></a>        <span class="n">add_cbs</span> <span class="o">=</span> <span class="n">additional_cbs</span> <span class="k">if</span> <span class="n">additional_cbs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
</span><span id="Trainer-118"><a href="#Trainer-118"><span class="linenos">118</span></a>
</span><span id="Trainer-119"><a href="#Trainer-119"><span class="linenos">119</span></a>        <span class="n">callbacks</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">Callback</span><span class="p">]</span> <span class="o">=</span> <span class="n">add_cbs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">[])</span>
</span><span id="Trainer-120"><a href="#Trainer-120"><span class="linenos">120</span></a>
</span><span id="Trainer-121"><a href="#Trainer-121"><span class="linenos">121</span></a>        <span class="k">if</span> <span class="n">calc_jsd</span><span class="p">:</span>
</span><span id="Trainer-122"><a href="#Trainer-122"><span class="linenos">122</span></a>            <span class="c1"># import here to don&#39;t import tensorflow on import</span>
</span><span id="Trainer-123"><a href="#Trainer-123"><span class="linenos">123</span></a>            <span class="kn">from</span> <span class="nn">lstm_clm.callbacks.jsd</span> <span class="kn">import</span> <span class="n">JSDCallback</span>
</span><span id="Trainer-124"><a href="#Trainer-124"><span class="linenos">124</span></a>
</span><span id="Trainer-125"><a href="#Trainer-125"><span class="linenos">125</span></a>            <span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">JSDCallback</span><span class="p">(</span><span class="n">clm</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">val</span><span class="p">))</span>
</span><span id="Trainer-126"><a href="#Trainer-126"><span class="linenos">126</span></a>
</span><span id="Trainer-127"><a href="#Trainer-127"><span class="linenos">127</span></a>        <span class="n">callbacks</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">add_cbs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">[]))</span>
</span><span id="Trainer-128"><a href="#Trainer-128"><span class="linenos">128</span></a>
</span><span id="Trainer-129"><a href="#Trainer-129"><span class="linenos">129</span></a>        <span class="k">if</span> <span class="n">decay</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="Trainer-130"><a href="#Trainer-130"><span class="linenos">130</span></a>            <span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">decay</span><span class="p">)</span>
</span><span id="Trainer-131"><a href="#Trainer-131"><span class="linenos">131</span></a>
</span><span id="Trainer-132"><a href="#Trainer-132"><span class="linenos">132</span></a>        <span class="n">callbacks</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">add_cbs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="p">[]))</span>
</span><span id="Trainer-133"><a href="#Trainer-133"><span class="linenos">133</span></a>
</span><span id="Trainer-134"><a href="#Trainer-134"><span class="linenos">134</span></a>        <span class="k">if</span> <span class="n">models_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="Trainer-135"><a href="#Trainer-135"><span class="linenos">135</span></a>            <span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">build_model_cp</span><span class="p">(</span><span class="n">models_path</span><span class="p">))</span>
</span><span id="Trainer-136"><a href="#Trainer-136"><span class="linenos">136</span></a>
</span><span id="Trainer-137"><a href="#Trainer-137"><span class="linenos">137</span></a>        <span class="n">callbacks</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">add_cbs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="p">[]))</span>
</span><span id="Trainer-138"><a href="#Trainer-138"><span class="linenos">138</span></a>
</span><span id="Trainer-139"><a href="#Trainer-139"><span class="linenos">139</span></a>        <span class="k">if</span> <span class="n">cp</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="Trainer-140"><a href="#Trainer-140"><span class="linenos">140</span></a>            <span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cp</span><span class="p">)</span>
</span><span id="Trainer-141"><a href="#Trainer-141"><span class="linenos">141</span></a>
</span><span id="Trainer-142"><a href="#Trainer-142"><span class="linenos">142</span></a>        <span class="n">callbacks</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">add_cbs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="p">[]))</span>
</span><span id="Trainer-143"><a href="#Trainer-143"><span class="linenos">143</span></a>
</span><span id="Trainer-144"><a href="#Trainer-144"><span class="linenos">144</span></a>        <span class="k">if</span> <span class="n">early_stopping</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="Trainer-145"><a href="#Trainer-145"><span class="linenos">145</span></a>            <span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">early_stopping</span><span class="p">)</span>
</span><span id="Trainer-146"><a href="#Trainer-146"><span class="linenos">146</span></a>
</span><span id="Trainer-147"><a href="#Trainer-147"><span class="linenos">147</span></a>        <span class="n">callbacks</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">add_cbs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="p">[]))</span>
</span><span id="Trainer-148"><a href="#Trainer-148"><span class="linenos">148</span></a>
</span><span id="Trainer-149"><a href="#Trainer-149"><span class="linenos">149</span></a>        <span class="k">return</span> <span class="n">callbacks</span>
</span><span id="Trainer-150"><a href="#Trainer-150"><span class="linenos">150</span></a>
</span><span id="Trainer-151"><a href="#Trainer-151"><span class="linenos">151</span></a>    <span class="nd">@staticmethod</span>
</span><span id="Trainer-152"><a href="#Trainer-152"><span class="linenos">152</span></a>    <span class="k">def</span> <span class="nf">init</span><span class="p">(</span>
</span><span id="Trainer-153"><a href="#Trainer-153"><span class="linenos">153</span></a>        <span class="n">build_model</span><span class="p">:</span> <span class="n">Factory</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">],</span>
</span><span id="Trainer-154"><a href="#Trainer-154"><span class="linenos">154</span></a>        <span class="n">build_opt</span><span class="p">:</span> <span class="n">Factory</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">],</span>
</span><span id="Trainer-155"><a href="#Trainer-155"><span class="linenos">155</span></a>        <span class="n">multi_gpu</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="Trainer-156"><a href="#Trainer-156"><span class="linenos">156</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">,</span> <span class="n">StrategyProto</span><span class="p">]:</span>
</span><span id="Trainer-157"><a href="#Trainer-157"><span class="linenos">157</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initializes the model and strategy.</span>
</span><span id="Trainer-158"><a href="#Trainer-158"><span class="linenos">158</span></a>
</span><span id="Trainer-159"><a href="#Trainer-159"><span class="linenos">159</span></a><span class="sd">        Args:</span>
</span><span id="Trainer-160"><a href="#Trainer-160"><span class="linenos">160</span></a><span class="sd">            build_model: Function to build the model</span>
</span><span id="Trainer-161"><a href="#Trainer-161"><span class="linenos">161</span></a><span class="sd">            build_opt: Function to build the optimizer</span>
</span><span id="Trainer-162"><a href="#Trainer-162"><span class="linenos">162</span></a><span class="sd">            multi_gpu: Whether to use multiple GPUs. Defaults to False.</span>
</span><span id="Trainer-163"><a href="#Trainer-163"><span class="linenos">163</span></a>
</span><span id="Trainer-164"><a href="#Trainer-164"><span class="linenos">164</span></a><span class="sd">        Returns:</span>
</span><span id="Trainer-165"><a href="#Trainer-165"><span class="linenos">165</span></a><span class="sd">            A tuple with the model, strategy, initial epoch, and decay storer/None</span>
</span><span id="Trainer-166"><a href="#Trainer-166"><span class="linenos">166</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Trainer-167"><a href="#Trainer-167"><span class="linenos">167</span></a>        <span class="n">strategy</span> <span class="o">=</span> <span class="n">get_strategy</span><span class="p">(</span><span class="n">multi_gpu</span><span class="p">)</span>
</span><span id="Trainer-168"><a href="#Trainer-168"><span class="linenos">168</span></a>
</span><span id="Trainer-169"><a href="#Trainer-169"><span class="linenos">169</span></a>        <span class="k">with</span> <span class="n">strategy</span><span class="o">.</span><span class="n">scope</span><span class="p">():</span>
</span><span id="Trainer-170"><a href="#Trainer-170"><span class="linenos">170</span></a>            <span class="c1"># need to build model and optimizer in scope (or load it in scope) IMPORTANT</span>
</span><span id="Trainer-171"><a href="#Trainer-171"><span class="linenos">171</span></a>            <span class="n">model</span> <span class="o">=</span> <span class="n">build_model</span><span class="p">()</span>
</span><span id="Trainer-172"><a href="#Trainer-172"><span class="linenos">172</span></a>            <span class="n">opt</span> <span class="o">=</span> <span class="n">build_opt</span><span class="p">()</span>
</span><span id="Trainer-173"><a href="#Trainer-173"><span class="linenos">173</span></a>            <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">)</span>
</span><span id="Trainer-174"><a href="#Trainer-174"><span class="linenos">174</span></a>
</span><span id="Trainer-175"><a href="#Trainer-175"><span class="linenos">175</span></a>        <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">strategy</span>
</span><span id="Trainer-176"><a href="#Trainer-176"><span class="linenos">176</span></a>
</span><span id="Trainer-177"><a href="#Trainer-177"><span class="linenos">177</span></a>    <span class="nd">@staticmethod</span>
</span><span id="Trainer-178"><a href="#Trainer-178"><span class="linenos">178</span></a>    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span>
</span><span id="Trainer-179"><a href="#Trainer-179"><span class="linenos">179</span></a>        <span class="n">train</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
</span><span id="Trainer-180"><a href="#Trainer-180"><span class="linenos">180</span></a>        <span class="n">val</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
</span><span id="Trainer-181"><a href="#Trainer-181"><span class="linenos">181</span></a>        <span class="n">vocab</span><span class="p">:</span> <span class="n">VocabProto</span><span class="p">,</span>
</span><span id="Trainer-182"><a href="#Trainer-182"><span class="linenos">182</span></a>        <span class="n">rnd_func</span><span class="p">:</span> <span class="n">RandomizeFunc</span><span class="p">,</span>
</span><span id="Trainer-183"><a href="#Trainer-183"><span class="linenos">183</span></a>        <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="Trainer-184"><a href="#Trainer-184"><span class="linenos">184</span></a>        <span class="n">n_jobs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="Trainer-185"><a href="#Trainer-185"><span class="linenos">185</span></a>        <span class="n">just_shuffle</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="Trainer-186"><a href="#Trainer-186"><span class="linenos">186</span></a>        <span class="n">init_epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="Trainer-187"><a href="#Trainer-187"><span class="linenos">187</span></a>        <span class="n">finetune</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="Trainer-188"><a href="#Trainer-188"><span class="linenos">188</span></a>        <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="Trainer-189"><a href="#Trainer-189"><span class="linenos">189</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">RandomizedDataset</span><span class="p">,</span> <span class="n">RandomizedDataset</span><span class="p">]:</span>
</span><span id="Trainer-190"><a href="#Trainer-190"><span class="linenos">190</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Builds the train and val _datasets for training.</span>
</span><span id="Trainer-191"><a href="#Trainer-191"><span class="linenos">191</span></a>
</span><span id="Trainer-192"><a href="#Trainer-192"><span class="linenos">192</span></a><span class="sd">        Args:</span>
</span><span id="Trainer-193"><a href="#Trainer-193"><span class="linenos">193</span></a><span class="sd">            train: The training data.</span>
</span><span id="Trainer-194"><a href="#Trainer-194"><span class="linenos">194</span></a><span class="sd">            val: The validation data.</span>
</span><span id="Trainer-195"><a href="#Trainer-195"><span class="linenos">195</span></a><span class="sd">            vocab: The vocabulary.</span>
</span><span id="Trainer-196"><a href="#Trainer-196"><span class="linenos">196</span></a><span class="sd">            rnd_func: Function to randomize the SMILES strings.</span>
</span><span id="Trainer-197"><a href="#Trainer-197"><span class="linenos">197</span></a><span class="sd">            epochs: The number of epochs.</span>
</span><span id="Trainer-198"><a href="#Trainer-198"><span class="linenos">198</span></a><span class="sd">            n_jobs: The number of jobs.</span>
</span><span id="Trainer-199"><a href="#Trainer-199"><span class="linenos">199</span></a><span class="sd">            just_shuffle: Whether to just shuffle the data. Defaults to False.</span>
</span><span id="Trainer-200"><a href="#Trainer-200"><span class="linenos">200</span></a><span class="sd">            init_epoch: The initial epoch. Defaults to 0.</span>
</span><span id="Trainer-201"><a href="#Trainer-201"><span class="linenos">201</span></a><span class="sd">            finetune: Whether its finetune data and thus</span>
</span><span id="Trainer-202"><a href="#Trainer-202"><span class="linenos">202</span></a><span class="sd">                data is precalc&#39;d. Defaults to False.</span>
</span><span id="Trainer-203"><a href="#Trainer-203"><span class="linenos">203</span></a><span class="sd">                Defaults to 4.</span>
</span><span id="Trainer-204"><a href="#Trainer-204"><span class="linenos">204</span></a><span class="sd">            verbose: Verbosity level. Defaults to 0.</span>
</span><span id="Trainer-205"><a href="#Trainer-205"><span class="linenos">205</span></a>
</span><span id="Trainer-206"><a href="#Trainer-206"><span class="linenos">206</span></a><span class="sd">        Returns:</span>
</span><span id="Trainer-207"><a href="#Trainer-207"><span class="linenos">207</span></a><span class="sd">            A tuple with train and val _datasets</span>
</span><span id="Trainer-208"><a href="#Trainer-208"><span class="linenos">208</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Trainer-209"><a href="#Trainer-209"><span class="linenos">209</span></a>        <span class="n">n_precalc</span> <span class="o">=</span> <span class="n">epochs</span> <span class="k">if</span> <span class="n">finetune</span> <span class="k">else</span> <span class="kc">None</span>
</span><span id="Trainer-210"><a href="#Trainer-210"><span class="linenos">210</span></a>
</span><span id="Trainer-211"><a href="#Trainer-211"><span class="linenos">211</span></a>        <span class="n">built_train</span><span class="p">,</span> <span class="n">built_val</span> <span class="o">=</span> <span class="n">RandomizedDataset</span><span class="o">.</span><span class="n">build</span><span class="p">(</span>
</span><span id="Trainer-212"><a href="#Trainer-212"><span class="linenos">212</span></a>            <span class="n">train</span><span class="p">,</span>
</span><span id="Trainer-213"><a href="#Trainer-213"><span class="linenos">213</span></a>            <span class="n">val</span><span class="p">,</span>
</span><span id="Trainer-214"><a href="#Trainer-214"><span class="linenos">214</span></a>            <span class="n">vocab</span><span class="p">,</span>
</span><span id="Trainer-215"><a href="#Trainer-215"><span class="linenos">215</span></a>            <span class="n">rnd_func</span><span class="p">,</span>
</span><span id="Trainer-216"><a href="#Trainer-216"><span class="linenos">216</span></a>            <span class="n">n_jobs</span><span class="p">,</span>
</span><span id="Trainer-217"><a href="#Trainer-217"><span class="linenos">217</span></a>            <span class="n">init_epoch</span><span class="p">,</span>
</span><span id="Trainer-218"><a href="#Trainer-218"><span class="linenos">218</span></a>            <span class="n">just_shuffle</span><span class="p">,</span>
</span><span id="Trainer-219"><a href="#Trainer-219"><span class="linenos">219</span></a>            <span class="n">n_precalc</span><span class="p">,</span>
</span><span id="Trainer-220"><a href="#Trainer-220"><span class="linenos">220</span></a>            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
</span><span id="Trainer-221"><a href="#Trainer-221"><span class="linenos">221</span></a>        <span class="p">)</span>
</span><span id="Trainer-222"><a href="#Trainer-222"><span class="linenos">222</span></a>
</span><span id="Trainer-223"><a href="#Trainer-223"><span class="linenos">223</span></a>        <span class="k">return</span> <span class="n">built_train</span><span class="p">,</span> <span class="n">built_val</span>
</span></pre></div>


            <div class="docstring"><p>Convenience class to train a model with a <code>RandomizedDataset</code>.</p>
</div>


                            <div id="Trainer.fit" class="classattr">
                                        <input id="Trainer.fit-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-staticmethod">@staticmethod</div>

        <span class="def">def</span>
        <span class="name">fit</span><span class="signature pdoc-code multiline">(<span class="param">  <span class="n">model</span><span class="p">:</span> <span class="n">keras</span><span class="o">.</span><span class="n">src</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">Model</span>,</span><span class="param"> <span class="n">train</span><span class="p">:</span> <span class="n"><a href="clm/randomized.html#RandomizedDataset">lstm_clm.clm.randomized.RandomizedDataset</a></span>,</span><span class="param">   <span class="n">val</span><span class="p">:</span> <span class="n"><a href="clm/randomized.html#RandomizedDataset">lstm_clm.clm.randomized.RandomizedDataset</a></span>,</span><span class="param"> <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span>,</span><span class="param">   <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span>,</span><span class="param">   <span class="n">callbacks</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">keras</span><span class="o">.</span><span class="n">src</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">Callback</span><span class="p">]</span>,</span><span class="param">  <span class="n">strategy</span><span class="p">:</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">distribute_lib</span><span class="o">.</span><span class="n">Strategy</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span></span><span class="return-annotation">) -> <span class="n">keras</span><span class="o">.</span><span class="n">src</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">History</span>:</span></span>

                <label class="view-source-button" for="Trainer.fit-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Trainer.fit"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Trainer.fit-42"><a href="#Trainer.fit-42"><span class="linenos">42</span></a>    <span class="nd">@staticmethod</span>
</span><span id="Trainer.fit-43"><a href="#Trainer.fit-43"><span class="linenos">43</span></a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
</span><span id="Trainer.fit-44"><a href="#Trainer.fit-44"><span class="linenos">44</span></a>        <span class="n">model</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">,</span>
</span><span id="Trainer.fit-45"><a href="#Trainer.fit-45"><span class="linenos">45</span></a>        <span class="n">train</span><span class="p">:</span> <span class="n">RandomizedDataset</span><span class="p">,</span>
</span><span id="Trainer.fit-46"><a href="#Trainer.fit-46"><span class="linenos">46</span></a>        <span class="n">val</span><span class="p">:</span> <span class="n">RandomizedDataset</span><span class="p">,</span>
</span><span id="Trainer.fit-47"><a href="#Trainer.fit-47"><span class="linenos">47</span></a>        <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="Trainer.fit-48"><a href="#Trainer.fit-48"><span class="linenos">48</span></a>        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="Trainer.fit-49"><a href="#Trainer.fit-49"><span class="linenos">49</span></a>        <span class="n">callbacks</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">Callback</span><span class="p">],</span>
</span><span id="Trainer.fit-50"><a href="#Trainer.fit-50"><span class="linenos">50</span></a>        <span class="n">strategy</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">Strategy</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="Trainer.fit-51"><a href="#Trainer.fit-51"><span class="linenos">51</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">History</span><span class="p">:</span>
</span><span id="Trainer.fit-52"><a href="#Trainer.fit-52"><span class="linenos">52</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Fit the model.</span>
</span><span id="Trainer.fit-53"><a href="#Trainer.fit-53"><span class="linenos">53</span></a>
</span><span id="Trainer.fit-54"><a href="#Trainer.fit-54"><span class="linenos">54</span></a><span class="sd">        Args:</span>
</span><span id="Trainer.fit-55"><a href="#Trainer.fit-55"><span class="linenos">55</span></a><span class="sd">            model: The model</span>
</span><span id="Trainer.fit-56"><a href="#Trainer.fit-56"><span class="linenos">56</span></a><span class="sd">            train: The training dataset</span>
</span><span id="Trainer.fit-57"><a href="#Trainer.fit-57"><span class="linenos">57</span></a><span class="sd">            val: The validation dataset</span>
</span><span id="Trainer.fit-58"><a href="#Trainer.fit-58"><span class="linenos">58</span></a><span class="sd">            epochs: The number of epochs</span>
</span><span id="Trainer.fit-59"><a href="#Trainer.fit-59"><span class="linenos">59</span></a><span class="sd">            batch_size: The batch size</span>
</span><span id="Trainer.fit-60"><a href="#Trainer.fit-60"><span class="linenos">60</span></a><span class="sd">            callbacks: The list of callbacks</span>
</span><span id="Trainer.fit-61"><a href="#Trainer.fit-61"><span class="linenos">61</span></a><span class="sd">            strategy: The strategy. Defaults to None.</span>
</span><span id="Trainer.fit-62"><a href="#Trainer.fit-62"><span class="linenos">62</span></a>
</span><span id="Trainer.fit-63"><a href="#Trainer.fit-63"><span class="linenos">63</span></a><span class="sd">        Returns:</span>
</span><span id="Trainer.fit-64"><a href="#Trainer.fit-64"><span class="linenos">64</span></a><span class="sd">            The history of the training</span>
</span><span id="Trainer.fit-65"><a href="#Trainer.fit-65"><span class="linenos">65</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Trainer.fit-66"><a href="#Trainer.fit-66"><span class="linenos">66</span></a>        <span class="n">built_train</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">build_dataset</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">strategy</span><span class="p">)</span>
</span><span id="Trainer.fit-67"><a href="#Trainer.fit-67"><span class="linenos">67</span></a>        <span class="n">built_val</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">build_dataset</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">strategy</span><span class="p">)</span>
</span><span id="Trainer.fit-68"><a href="#Trainer.fit-68"><span class="linenos">68</span></a>
</span><span id="Trainer.fit-69"><a href="#Trainer.fit-69"><span class="linenos">69</span></a>        <span class="k">return</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
</span><span id="Trainer.fit-70"><a href="#Trainer.fit-70"><span class="linenos">70</span></a>            <span class="n">built_train</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span>
</span><span id="Trainer.fit-71"><a href="#Trainer.fit-71"><span class="linenos">71</span></a>            <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
</span><span id="Trainer.fit-72"><a href="#Trainer.fit-72"><span class="linenos">72</span></a>            <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">built_train</span><span class="o">.</span><span class="n">steps</span><span class="p">,</span>
</span><span id="Trainer.fit-73"><a href="#Trainer.fit-73"><span class="linenos">73</span></a>            <span class="n">validation_data</span><span class="o">=</span><span class="n">built_val</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span>
</span><span id="Trainer.fit-74"><a href="#Trainer.fit-74"><span class="linenos">74</span></a>            <span class="n">validation_steps</span><span class="o">=</span><span class="n">built_val</span><span class="o">.</span><span class="n">steps</span><span class="p">,</span>
</span><span id="Trainer.fit-75"><a href="#Trainer.fit-75"><span class="linenos">75</span></a>            <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>
</span><span id="Trainer.fit-76"><a href="#Trainer.fit-76"><span class="linenos">76</span></a>            <span class="n">initial_epoch</span><span class="o">=</span><span class="n">built_train</span><span class="o">.</span><span class="n">init_epoch</span><span class="p">,</span>
</span><span id="Trainer.fit-77"><a href="#Trainer.fit-77"><span class="linenos">77</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Fit the model.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>model:</strong>  The model</li>
<li><strong>train:</strong>  The training dataset</li>
<li><strong>val:</strong>  The validation dataset</li>
<li><strong>epochs:</strong>  The number of epochs</li>
<li><strong>batch_size:</strong>  The batch size</li>
<li><strong>callbacks:</strong>  The list of callbacks</li>
<li><strong>strategy:</strong>  The strategy. Defaults to None.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>The history of the training</p>
</blockquote>
</div>


                            </div>
                            <div id="Trainer.callbacks" class="classattr">
                                        <input id="Trainer.callbacks-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-staticmethod">@staticmethod</div>

        <span class="def">def</span>
        <span class="name">callbacks</span><span class="signature pdoc-code multiline">(<span class="param">    <span class="n">clm</span><span class="p">:</span> <span class="n"><a href="#MultinomialCLM">MultinomialCLM</a></span>,</span><span class="param">  <span class="n">train</span><span class="p">:</span> <span class="n"><a href="clm/randomized.html#RandomizedDataset">lstm_clm.clm.randomized.RandomizedDataset</a></span>,</span><span class="param">   <span class="n">val</span><span class="p">:</span> <span class="n"><a href="clm/randomized.html#RandomizedDataset">lstm_clm.clm.randomized.RandomizedDataset</a></span>,</span><span class="param"> <span class="n">cp</span><span class="p">:</span> <span class="n">keras</span><span class="o">.</span><span class="n">src</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">  <span class="n">calc_jsd</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>,</span><span class="param"> <span class="n">decay</span><span class="p">:</span> <span class="n">keras</span><span class="o">.</span><span class="n">src</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param"> <span class="n">models_path</span><span class="p">:</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">   <span class="n">early_stopping</span><span class="p">:</span> <span class="n">keras</span><span class="o">.</span><span class="n">src</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">    <span class="n">additional_cbs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">keras</span><span class="o">.</span><span class="n">src</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">Callback</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span></span><span class="return-annotation">) -> <span class="nb">list</span><span class="p">[</span><span class="n">keras</span><span class="o">.</span><span class="n">src</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">Callback</span><span class="p">]</span>:</span></span>

                <label class="view-source-button" for="Trainer.callbacks-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Trainer.callbacks"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Trainer.callbacks-79"><a href="#Trainer.callbacks-79"><span class="linenos"> 79</span></a>    <span class="nd">@staticmethod</span>
</span><span id="Trainer.callbacks-80"><a href="#Trainer.callbacks-80"><span class="linenos"> 80</span></a>    <span class="k">def</span> <span class="nf">callbacks</span><span class="p">(</span>
</span><span id="Trainer.callbacks-81"><a href="#Trainer.callbacks-81"><span class="linenos"> 81</span></a>        <span class="n">clm</span><span class="p">:</span> <span class="n">MultinomialCLM</span><span class="p">,</span>
</span><span id="Trainer.callbacks-82"><a href="#Trainer.callbacks-82"><span class="linenos"> 82</span></a>        <span class="n">train</span><span class="p">:</span> <span class="n">RandomizedDataset</span><span class="p">,</span>
</span><span id="Trainer.callbacks-83"><a href="#Trainer.callbacks-83"><span class="linenos"> 83</span></a>        <span class="n">val</span><span class="p">:</span> <span class="n">RandomizedDataset</span><span class="p">,</span>
</span><span id="Trainer.callbacks-84"><a href="#Trainer.callbacks-84"><span class="linenos"> 84</span></a>        <span class="n">cp</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="Trainer.callbacks-85"><a href="#Trainer.callbacks-85"><span class="linenos"> 85</span></a>        <span class="n">calc_jsd</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="Trainer.callbacks-86"><a href="#Trainer.callbacks-86"><span class="linenos"> 86</span></a>        <span class="n">decay</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="Trainer.callbacks-87"><a href="#Trainer.callbacks-87"><span class="linenos"> 87</span></a>        <span class="n">models_path</span><span class="p">:</span> <span class="n">Path</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="Trainer.callbacks-88"><a href="#Trainer.callbacks-88"><span class="linenos"> 88</span></a>        <span class="n">early_stopping</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="Trainer.callbacks-89"><a href="#Trainer.callbacks-89"><span class="linenos"> 89</span></a>        <span class="n">additional_cbs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">Callback</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="Trainer.callbacks-90"><a href="#Trainer.callbacks-90"><span class="linenos"> 90</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">Callback</span><span class="p">]:</span>
</span><span id="Trainer.callbacks-91"><a href="#Trainer.callbacks-91"><span class="linenos"> 91</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the callbacks for training.</span>
</span><span id="Trainer.callbacks-92"><a href="#Trainer.callbacks-92"><span class="linenos"> 92</span></a>
</span><span id="Trainer.callbacks-93"><a href="#Trainer.callbacks-93"><span class="linenos"> 93</span></a><span class="sd">        - Additional positions:</span>
</span><span id="Trainer.callbacks-94"><a href="#Trainer.callbacks-94"><span class="linenos"> 94</span></a><span class="sd">            - 0 at beginning,</span>
</span><span id="Trainer.callbacks-95"><a href="#Trainer.callbacks-95"><span class="linenos"> 95</span></a><span class="sd">            - 1 after JSD,</span>
</span><span id="Trainer.callbacks-96"><a href="#Trainer.callbacks-96"><span class="linenos"> 96</span></a><span class="sd">            - 2 after decay,</span>
</span><span id="Trainer.callbacks-97"><a href="#Trainer.callbacks-97"><span class="linenos"> 97</span></a><span class="sd">            - 3 after checkpoint,</span>
</span><span id="Trainer.callbacks-98"><a href="#Trainer.callbacks-98"><span class="linenos"> 98</span></a><span class="sd">            - 4 after trainingCP,</span>
</span><span id="Trainer.callbacks-99"><a href="#Trainer.callbacks-99"><span class="linenos"> 99</span></a><span class="sd">            - 5 after early stopping</span>
</span><span id="Trainer.callbacks-100"><a href="#Trainer.callbacks-100"><span class="linenos">100</span></a><span class="sd">        - TODO: make the int as enum for add_cbs.</span>
</span><span id="Trainer.callbacks-101"><a href="#Trainer.callbacks-101"><span class="linenos">101</span></a>
</span><span id="Trainer.callbacks-102"><a href="#Trainer.callbacks-102"><span class="linenos">102</span></a><span class="sd">        Args:</span>
</span><span id="Trainer.callbacks-103"><a href="#Trainer.callbacks-103"><span class="linenos">103</span></a><span class="sd">            clm: The CLM</span>
</span><span id="Trainer.callbacks-104"><a href="#Trainer.callbacks-104"><span class="linenos">104</span></a><span class="sd">            train: The training dataset</span>
</span><span id="Trainer.callbacks-105"><a href="#Trainer.callbacks-105"><span class="linenos">105</span></a><span class="sd">            val: The validation dataset</span>
</span><span id="Trainer.callbacks-106"><a href="#Trainer.callbacks-106"><span class="linenos">106</span></a><span class="sd">            cp: The checkpoint to load. Defaults to None.</span>
</span><span id="Trainer.callbacks-107"><a href="#Trainer.callbacks-107"><span class="linenos">107</span></a><span class="sd">            calc_jsd: Whether to calc the JSD. Defaults to False.</span>
</span><span id="Trainer.callbacks-108"><a href="#Trainer.callbacks-108"><span class="linenos">108</span></a><span class="sd">            decay: The decay storer. Defaults to None.</span>
</span><span id="Trainer.callbacks-109"><a href="#Trainer.callbacks-109"><span class="linenos">109</span></a><span class="sd">            models_path: The _path to store the models. Defaults to None.</span>
</span><span id="Trainer.callbacks-110"><a href="#Trainer.callbacks-110"><span class="linenos">110</span></a><span class="sd">            early_stopping: The early stopping. Defaults to None.</span>
</span><span id="Trainer.callbacks-111"><a href="#Trainer.callbacks-111"><span class="linenos">111</span></a><span class="sd">            additional_cbs: Additional callbacks to add at specific positions.</span>
</span><span id="Trainer.callbacks-112"><a href="#Trainer.callbacks-112"><span class="linenos">112</span></a><span class="sd">                Defaults to empty dict.</span>
</span><span id="Trainer.callbacks-113"><a href="#Trainer.callbacks-113"><span class="linenos">113</span></a>
</span><span id="Trainer.callbacks-114"><a href="#Trainer.callbacks-114"><span class="linenos">114</span></a><span class="sd">        Returns:</span>
</span><span id="Trainer.callbacks-115"><a href="#Trainer.callbacks-115"><span class="linenos">115</span></a><span class="sd">            The list of callbacks</span>
</span><span id="Trainer.callbacks-116"><a href="#Trainer.callbacks-116"><span class="linenos">116</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Trainer.callbacks-117"><a href="#Trainer.callbacks-117"><span class="linenos">117</span></a>        <span class="n">add_cbs</span> <span class="o">=</span> <span class="n">additional_cbs</span> <span class="k">if</span> <span class="n">additional_cbs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
</span><span id="Trainer.callbacks-118"><a href="#Trainer.callbacks-118"><span class="linenos">118</span></a>
</span><span id="Trainer.callbacks-119"><a href="#Trainer.callbacks-119"><span class="linenos">119</span></a>        <span class="n">callbacks</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">Callback</span><span class="p">]</span> <span class="o">=</span> <span class="n">add_cbs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">[])</span>
</span><span id="Trainer.callbacks-120"><a href="#Trainer.callbacks-120"><span class="linenos">120</span></a>
</span><span id="Trainer.callbacks-121"><a href="#Trainer.callbacks-121"><span class="linenos">121</span></a>        <span class="k">if</span> <span class="n">calc_jsd</span><span class="p">:</span>
</span><span id="Trainer.callbacks-122"><a href="#Trainer.callbacks-122"><span class="linenos">122</span></a>            <span class="c1"># import here to don&#39;t import tensorflow on import</span>
</span><span id="Trainer.callbacks-123"><a href="#Trainer.callbacks-123"><span class="linenos">123</span></a>            <span class="kn">from</span> <span class="nn">lstm_clm.callbacks.jsd</span> <span class="kn">import</span> <span class="n">JSDCallback</span>
</span><span id="Trainer.callbacks-124"><a href="#Trainer.callbacks-124"><span class="linenos">124</span></a>
</span><span id="Trainer.callbacks-125"><a href="#Trainer.callbacks-125"><span class="linenos">125</span></a>            <span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">JSDCallback</span><span class="p">(</span><span class="n">clm</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">val</span><span class="p">))</span>
</span><span id="Trainer.callbacks-126"><a href="#Trainer.callbacks-126"><span class="linenos">126</span></a>
</span><span id="Trainer.callbacks-127"><a href="#Trainer.callbacks-127"><span class="linenos">127</span></a>        <span class="n">callbacks</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">add_cbs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">[]))</span>
</span><span id="Trainer.callbacks-128"><a href="#Trainer.callbacks-128"><span class="linenos">128</span></a>
</span><span id="Trainer.callbacks-129"><a href="#Trainer.callbacks-129"><span class="linenos">129</span></a>        <span class="k">if</span> <span class="n">decay</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="Trainer.callbacks-130"><a href="#Trainer.callbacks-130"><span class="linenos">130</span></a>            <span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">decay</span><span class="p">)</span>
</span><span id="Trainer.callbacks-131"><a href="#Trainer.callbacks-131"><span class="linenos">131</span></a>
</span><span id="Trainer.callbacks-132"><a href="#Trainer.callbacks-132"><span class="linenos">132</span></a>        <span class="n">callbacks</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">add_cbs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="p">[]))</span>
</span><span id="Trainer.callbacks-133"><a href="#Trainer.callbacks-133"><span class="linenos">133</span></a>
</span><span id="Trainer.callbacks-134"><a href="#Trainer.callbacks-134"><span class="linenos">134</span></a>        <span class="k">if</span> <span class="n">models_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="Trainer.callbacks-135"><a href="#Trainer.callbacks-135"><span class="linenos">135</span></a>            <span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">build_model_cp</span><span class="p">(</span><span class="n">models_path</span><span class="p">))</span>
</span><span id="Trainer.callbacks-136"><a href="#Trainer.callbacks-136"><span class="linenos">136</span></a>
</span><span id="Trainer.callbacks-137"><a href="#Trainer.callbacks-137"><span class="linenos">137</span></a>        <span class="n">callbacks</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">add_cbs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="p">[]))</span>
</span><span id="Trainer.callbacks-138"><a href="#Trainer.callbacks-138"><span class="linenos">138</span></a>
</span><span id="Trainer.callbacks-139"><a href="#Trainer.callbacks-139"><span class="linenos">139</span></a>        <span class="k">if</span> <span class="n">cp</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="Trainer.callbacks-140"><a href="#Trainer.callbacks-140"><span class="linenos">140</span></a>            <span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cp</span><span class="p">)</span>
</span><span id="Trainer.callbacks-141"><a href="#Trainer.callbacks-141"><span class="linenos">141</span></a>
</span><span id="Trainer.callbacks-142"><a href="#Trainer.callbacks-142"><span class="linenos">142</span></a>        <span class="n">callbacks</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">add_cbs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="p">[]))</span>
</span><span id="Trainer.callbacks-143"><a href="#Trainer.callbacks-143"><span class="linenos">143</span></a>
</span><span id="Trainer.callbacks-144"><a href="#Trainer.callbacks-144"><span class="linenos">144</span></a>        <span class="k">if</span> <span class="n">early_stopping</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="Trainer.callbacks-145"><a href="#Trainer.callbacks-145"><span class="linenos">145</span></a>            <span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">early_stopping</span><span class="p">)</span>
</span><span id="Trainer.callbacks-146"><a href="#Trainer.callbacks-146"><span class="linenos">146</span></a>
</span><span id="Trainer.callbacks-147"><a href="#Trainer.callbacks-147"><span class="linenos">147</span></a>        <span class="n">callbacks</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">add_cbs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="p">[]))</span>
</span><span id="Trainer.callbacks-148"><a href="#Trainer.callbacks-148"><span class="linenos">148</span></a>
</span><span id="Trainer.callbacks-149"><a href="#Trainer.callbacks-149"><span class="linenos">149</span></a>        <span class="k">return</span> <span class="n">callbacks</span>
</span></pre></div>


            <div class="docstring"><p>Get the callbacks for training.</p>

<ul>
<li>Additional positions:
<ul>
<li>0 at beginning,</li>
<li>1 after JSD,</li>
<li>2 after decay,</li>
<li>3 after checkpoint,</li>
<li>4 after trainingCP,</li>
<li>5 after early stopping</li>
</ul></li>
<li>TODO: make the int as enum for add_cbs.</li>
</ul>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>clm:</strong>  The CLM</li>
<li><strong>train:</strong>  The training dataset</li>
<li><strong>val:</strong>  The validation dataset</li>
<li><strong>cp:</strong>  The checkpoint to load. Defaults to None.</li>
<li><strong>calc_jsd:</strong>  Whether to calc the JSD. Defaults to False.</li>
<li><strong>decay:</strong>  The decay storer. Defaults to None.</li>
<li><strong>models_path:</strong>  The _path to store the models. Defaults to None.</li>
<li><strong>early_stopping:</strong>  The early stopping. Defaults to None.</li>
<li><strong>additional_cbs:</strong>  Additional callbacks to add at specific positions.
Defaults to empty dict.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>The list of callbacks</p>
</blockquote>
</div>


                            </div>
                            <div id="Trainer.init" class="classattr">
                                        <input id="Trainer.init-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-staticmethod">@staticmethod</div>

        <span class="def">def</span>
        <span class="name">init</span><span class="signature pdoc-code multiline">(<span class="param"> <span class="n">build_model</span><span class="p">:</span> <span class="n">lstm_clm</span><span class="o">.</span><span class="n">clm</span><span class="o">.</span><span class="n">proto</span><span class="o">.</span><span class="n">Factory</span><span class="p">[</span><span class="n">keras</span><span class="o">.</span><span class="n">src</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">Model</span><span class="p">]</span>,</span><span class="param">    <span class="n">build_opt</span><span class="p">:</span> <span class="n">lstm_clm</span><span class="o">.</span><span class="n">clm</span><span class="o">.</span><span class="n">proto</span><span class="o">.</span><span class="n">Factory</span><span class="p">[</span><span class="n">keras</span><span class="o">.</span><span class="n">src</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">Model</span><span class="p">]</span>,</span><span class="param">  <span class="n">multi_gpu</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span></span><span class="return-annotation">) -> <span class="nb">tuple</span><span class="p">[</span><span class="n">keras</span><span class="o">.</span><span class="n">src</span><span class="o">.</span><span class="n">engine</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">Model</span><span class="p">,</span> <span class="n">lstm_clm</span><span class="o">.</span><span class="n">clm</span><span class="o">.</span><span class="n">proto</span><span class="o">.</span><span class="n">StrategyProto</span><span class="p">]</span>:</span></span>

                <label class="view-source-button" for="Trainer.init-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Trainer.init"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Trainer.init-151"><a href="#Trainer.init-151"><span class="linenos">151</span></a>    <span class="nd">@staticmethod</span>
</span><span id="Trainer.init-152"><a href="#Trainer.init-152"><span class="linenos">152</span></a>    <span class="k">def</span> <span class="nf">init</span><span class="p">(</span>
</span><span id="Trainer.init-153"><a href="#Trainer.init-153"><span class="linenos">153</span></a>        <span class="n">build_model</span><span class="p">:</span> <span class="n">Factory</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">],</span>
</span><span id="Trainer.init-154"><a href="#Trainer.init-154"><span class="linenos">154</span></a>        <span class="n">build_opt</span><span class="p">:</span> <span class="n">Factory</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">],</span>
</span><span id="Trainer.init-155"><a href="#Trainer.init-155"><span class="linenos">155</span></a>        <span class="n">multi_gpu</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="Trainer.init-156"><a href="#Trainer.init-156"><span class="linenos">156</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">,</span> <span class="n">StrategyProto</span><span class="p">]:</span>
</span><span id="Trainer.init-157"><a href="#Trainer.init-157"><span class="linenos">157</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initializes the model and strategy.</span>
</span><span id="Trainer.init-158"><a href="#Trainer.init-158"><span class="linenos">158</span></a>
</span><span id="Trainer.init-159"><a href="#Trainer.init-159"><span class="linenos">159</span></a><span class="sd">        Args:</span>
</span><span id="Trainer.init-160"><a href="#Trainer.init-160"><span class="linenos">160</span></a><span class="sd">            build_model: Function to build the model</span>
</span><span id="Trainer.init-161"><a href="#Trainer.init-161"><span class="linenos">161</span></a><span class="sd">            build_opt: Function to build the optimizer</span>
</span><span id="Trainer.init-162"><a href="#Trainer.init-162"><span class="linenos">162</span></a><span class="sd">            multi_gpu: Whether to use multiple GPUs. Defaults to False.</span>
</span><span id="Trainer.init-163"><a href="#Trainer.init-163"><span class="linenos">163</span></a>
</span><span id="Trainer.init-164"><a href="#Trainer.init-164"><span class="linenos">164</span></a><span class="sd">        Returns:</span>
</span><span id="Trainer.init-165"><a href="#Trainer.init-165"><span class="linenos">165</span></a><span class="sd">            A tuple with the model, strategy, initial epoch, and decay storer/None</span>
</span><span id="Trainer.init-166"><a href="#Trainer.init-166"><span class="linenos">166</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Trainer.init-167"><a href="#Trainer.init-167"><span class="linenos">167</span></a>        <span class="n">strategy</span> <span class="o">=</span> <span class="n">get_strategy</span><span class="p">(</span><span class="n">multi_gpu</span><span class="p">)</span>
</span><span id="Trainer.init-168"><a href="#Trainer.init-168"><span class="linenos">168</span></a>
</span><span id="Trainer.init-169"><a href="#Trainer.init-169"><span class="linenos">169</span></a>        <span class="k">with</span> <span class="n">strategy</span><span class="o">.</span><span class="n">scope</span><span class="p">():</span>
</span><span id="Trainer.init-170"><a href="#Trainer.init-170"><span class="linenos">170</span></a>            <span class="c1"># need to build model and optimizer in scope (or load it in scope) IMPORTANT</span>
</span><span id="Trainer.init-171"><a href="#Trainer.init-171"><span class="linenos">171</span></a>            <span class="n">model</span> <span class="o">=</span> <span class="n">build_model</span><span class="p">()</span>
</span><span id="Trainer.init-172"><a href="#Trainer.init-172"><span class="linenos">172</span></a>            <span class="n">opt</span> <span class="o">=</span> <span class="n">build_opt</span><span class="p">()</span>
</span><span id="Trainer.init-173"><a href="#Trainer.init-173"><span class="linenos">173</span></a>            <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">)</span>
</span><span id="Trainer.init-174"><a href="#Trainer.init-174"><span class="linenos">174</span></a>
</span><span id="Trainer.init-175"><a href="#Trainer.init-175"><span class="linenos">175</span></a>        <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">strategy</span>
</span></pre></div>


            <div class="docstring"><p>Initializes the model and strategy.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>build_model:</strong>  Function to build the model</li>
<li><strong>build_opt:</strong>  Function to build the optimizer</li>
<li><strong>multi_gpu:</strong>  Whether to use multiple GPUs. Defaults to False.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>A tuple with the model, strategy, initial epoch, and decay storer/None</p>
</blockquote>
</div>


                            </div>
                            <div id="Trainer.build" class="classattr">
                                        <input id="Trainer.build-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator decorator-staticmethod">@staticmethod</div>

        <span class="def">def</span>
        <span class="name">build</span><span class="signature pdoc-code multiline">(<span class="param">    <span class="n">train</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>,</span><span class="param"> <span class="n">val</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>,</span><span class="param">   <span class="n">vocab</span><span class="p">:</span> <span class="n"><a href="vocab.html#VocabProto">lstm_clm.vocab.VocabProto</a></span>,</span><span class="param">   <span class="n">rnd_func</span><span class="p">:</span> <span class="n">lstm_clm</span><span class="o">.</span><span class="n">clm</span><span class="o">.</span><span class="n">proto</span><span class="o">.</span><span class="n">RandomizeFunc</span>,</span><span class="param">   <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span>,</span><span class="param">   <span class="n">n_jobs</span><span class="p">:</span> <span class="nb">int</span>,</span><span class="param">   <span class="n">just_shuffle</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>,</span><span class="param"> <span class="n">init_epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>,</span><span class="param">    <span class="n">finetune</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>,</span><span class="param"> <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span></span><span class="return-annotation">) -> <span class="nb">tuple</span><span class="p">[</span><span class="n"><a href="clm/randomized.html#RandomizedDataset">lstm_clm.clm.randomized.RandomizedDataset</a></span><span class="p">,</span> <span class="n"><a href="clm/randomized.html#RandomizedDataset">lstm_clm.clm.randomized.RandomizedDataset</a></span><span class="p">]</span>:</span></span>

                <label class="view-source-button" for="Trainer.build-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#Trainer.build"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="Trainer.build-177"><a href="#Trainer.build-177"><span class="linenos">177</span></a>    <span class="nd">@staticmethod</span>
</span><span id="Trainer.build-178"><a href="#Trainer.build-178"><span class="linenos">178</span></a>    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span>
</span><span id="Trainer.build-179"><a href="#Trainer.build-179"><span class="linenos">179</span></a>        <span class="n">train</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
</span><span id="Trainer.build-180"><a href="#Trainer.build-180"><span class="linenos">180</span></a>        <span class="n">val</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
</span><span id="Trainer.build-181"><a href="#Trainer.build-181"><span class="linenos">181</span></a>        <span class="n">vocab</span><span class="p">:</span> <span class="n">VocabProto</span><span class="p">,</span>
</span><span id="Trainer.build-182"><a href="#Trainer.build-182"><span class="linenos">182</span></a>        <span class="n">rnd_func</span><span class="p">:</span> <span class="n">RandomizeFunc</span><span class="p">,</span>
</span><span id="Trainer.build-183"><a href="#Trainer.build-183"><span class="linenos">183</span></a>        <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="Trainer.build-184"><a href="#Trainer.build-184"><span class="linenos">184</span></a>        <span class="n">n_jobs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="Trainer.build-185"><a href="#Trainer.build-185"><span class="linenos">185</span></a>        <span class="n">just_shuffle</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="Trainer.build-186"><a href="#Trainer.build-186"><span class="linenos">186</span></a>        <span class="n">init_epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="Trainer.build-187"><a href="#Trainer.build-187"><span class="linenos">187</span></a>        <span class="n">finetune</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="Trainer.build-188"><a href="#Trainer.build-188"><span class="linenos">188</span></a>        <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="Trainer.build-189"><a href="#Trainer.build-189"><span class="linenos">189</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">RandomizedDataset</span><span class="p">,</span> <span class="n">RandomizedDataset</span><span class="p">]:</span>
</span><span id="Trainer.build-190"><a href="#Trainer.build-190"><span class="linenos">190</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Builds the train and val _datasets for training.</span>
</span><span id="Trainer.build-191"><a href="#Trainer.build-191"><span class="linenos">191</span></a>
</span><span id="Trainer.build-192"><a href="#Trainer.build-192"><span class="linenos">192</span></a><span class="sd">        Args:</span>
</span><span id="Trainer.build-193"><a href="#Trainer.build-193"><span class="linenos">193</span></a><span class="sd">            train: The training data.</span>
</span><span id="Trainer.build-194"><a href="#Trainer.build-194"><span class="linenos">194</span></a><span class="sd">            val: The validation data.</span>
</span><span id="Trainer.build-195"><a href="#Trainer.build-195"><span class="linenos">195</span></a><span class="sd">            vocab: The vocabulary.</span>
</span><span id="Trainer.build-196"><a href="#Trainer.build-196"><span class="linenos">196</span></a><span class="sd">            rnd_func: Function to randomize the SMILES strings.</span>
</span><span id="Trainer.build-197"><a href="#Trainer.build-197"><span class="linenos">197</span></a><span class="sd">            epochs: The number of epochs.</span>
</span><span id="Trainer.build-198"><a href="#Trainer.build-198"><span class="linenos">198</span></a><span class="sd">            n_jobs: The number of jobs.</span>
</span><span id="Trainer.build-199"><a href="#Trainer.build-199"><span class="linenos">199</span></a><span class="sd">            just_shuffle: Whether to just shuffle the data. Defaults to False.</span>
</span><span id="Trainer.build-200"><a href="#Trainer.build-200"><span class="linenos">200</span></a><span class="sd">            init_epoch: The initial epoch. Defaults to 0.</span>
</span><span id="Trainer.build-201"><a href="#Trainer.build-201"><span class="linenos">201</span></a><span class="sd">            finetune: Whether its finetune data and thus</span>
</span><span id="Trainer.build-202"><a href="#Trainer.build-202"><span class="linenos">202</span></a><span class="sd">                data is precalc&#39;d. Defaults to False.</span>
</span><span id="Trainer.build-203"><a href="#Trainer.build-203"><span class="linenos">203</span></a><span class="sd">                Defaults to 4.</span>
</span><span id="Trainer.build-204"><a href="#Trainer.build-204"><span class="linenos">204</span></a><span class="sd">            verbose: Verbosity level. Defaults to 0.</span>
</span><span id="Trainer.build-205"><a href="#Trainer.build-205"><span class="linenos">205</span></a>
</span><span id="Trainer.build-206"><a href="#Trainer.build-206"><span class="linenos">206</span></a><span class="sd">        Returns:</span>
</span><span id="Trainer.build-207"><a href="#Trainer.build-207"><span class="linenos">207</span></a><span class="sd">            A tuple with train and val _datasets</span>
</span><span id="Trainer.build-208"><a href="#Trainer.build-208"><span class="linenos">208</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="Trainer.build-209"><a href="#Trainer.build-209"><span class="linenos">209</span></a>        <span class="n">n_precalc</span> <span class="o">=</span> <span class="n">epochs</span> <span class="k">if</span> <span class="n">finetune</span> <span class="k">else</span> <span class="kc">None</span>
</span><span id="Trainer.build-210"><a href="#Trainer.build-210"><span class="linenos">210</span></a>
</span><span id="Trainer.build-211"><a href="#Trainer.build-211"><span class="linenos">211</span></a>        <span class="n">built_train</span><span class="p">,</span> <span class="n">built_val</span> <span class="o">=</span> <span class="n">RandomizedDataset</span><span class="o">.</span><span class="n">build</span><span class="p">(</span>
</span><span id="Trainer.build-212"><a href="#Trainer.build-212"><span class="linenos">212</span></a>            <span class="n">train</span><span class="p">,</span>
</span><span id="Trainer.build-213"><a href="#Trainer.build-213"><span class="linenos">213</span></a>            <span class="n">val</span><span class="p">,</span>
</span><span id="Trainer.build-214"><a href="#Trainer.build-214"><span class="linenos">214</span></a>            <span class="n">vocab</span><span class="p">,</span>
</span><span id="Trainer.build-215"><a href="#Trainer.build-215"><span class="linenos">215</span></a>            <span class="n">rnd_func</span><span class="p">,</span>
</span><span id="Trainer.build-216"><a href="#Trainer.build-216"><span class="linenos">216</span></a>            <span class="n">n_jobs</span><span class="p">,</span>
</span><span id="Trainer.build-217"><a href="#Trainer.build-217"><span class="linenos">217</span></a>            <span class="n">init_epoch</span><span class="p">,</span>
</span><span id="Trainer.build-218"><a href="#Trainer.build-218"><span class="linenos">218</span></a>            <span class="n">just_shuffle</span><span class="p">,</span>
</span><span id="Trainer.build-219"><a href="#Trainer.build-219"><span class="linenos">219</span></a>            <span class="n">n_precalc</span><span class="p">,</span>
</span><span id="Trainer.build-220"><a href="#Trainer.build-220"><span class="linenos">220</span></a>            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
</span><span id="Trainer.build-221"><a href="#Trainer.build-221"><span class="linenos">221</span></a>        <span class="p">)</span>
</span><span id="Trainer.build-222"><a href="#Trainer.build-222"><span class="linenos">222</span></a>
</span><span id="Trainer.build-223"><a href="#Trainer.build-223"><span class="linenos">223</span></a>        <span class="k">return</span> <span class="n">built_train</span><span class="p">,</span> <span class="n">built_val</span>
</span></pre></div>


            <div class="docstring"><p>Builds the train and val _datasets for training.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>train:</strong>  The training data.</li>
<li><strong>val:</strong>  The validation data.</li>
<li><strong>vocab:</strong>  The vocabulary.</li>
<li><strong>rnd_func:</strong>  Function to randomize the SMILES strings.</li>
<li><strong>epochs:</strong>  The number of epochs.</li>
<li><strong>n_jobs:</strong>  The number of jobs.</li>
<li><strong>just_shuffle:</strong>  Whether to just shuffle the data. Defaults to False.</li>
<li><strong>init_epoch:</strong>  The initial epoch. Defaults to 0.</li>
<li><strong>finetune:</strong>  Whether its finetune data and thus
data is precalc'd. Defaults to False.
Defaults to 4.</li>
<li><strong>verbose:</strong>  Verbosity level. Defaults to 0.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>A tuple with train and val _datasets</p>
</blockquote>
</div>


                            </div>
                </section>
                <section id="VocabMultinomialCLM">
                            <input id="VocabMultinomialCLM-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">

    <span class="def">class</span>
    <span class="name">VocabMultinomialCLM</span><wbr>(<span class="base"><a href="#MultinomialCLM">lstm_clm.clm.MultinomialCLM</a></span>):

                <label class="view-source-button" for="VocabMultinomialCLM-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#VocabMultinomialCLM"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="VocabMultinomialCLM-292"><a href="#VocabMultinomialCLM-292"><span class="linenos">292</span></a><span class="k">class</span> <span class="nc">VocabMultinomialCLM</span><span class="p">(</span><span class="n">MultinomialCLM</span><span class="p">):</span>
</span><span id="VocabMultinomialCLM-293"><a href="#VocabMultinomialCLM-293"><span class="linenos">293</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Generating samples with multinomial sampling with vocabulary.</span>
</span><span id="VocabMultinomialCLM-294"><a href="#VocabMultinomialCLM-294"><span class="linenos">294</span></a>
</span><span id="VocabMultinomialCLM-295"><a href="#VocabMultinomialCLM-295"><span class="linenos">295</span></a><span class="sd">    Attributes:</span>
</span><span id="VocabMultinomialCLM-296"><a href="#VocabMultinomialCLM-296"><span class="linenos">296</span></a><span class="sd">        model (tf.keras.Model): Model to wrap with LSTM layers.</span>
</span><span id="VocabMultinomialCLM-297"><a href="#VocabMultinomialCLM-297"><span class="linenos">297</span></a><span class="sd">        vocab (Vocabulary): Vocabulary.</span>
</span><span id="VocabMultinomialCLM-298"><a href="#VocabMultinomialCLM-298"><span class="linenos">298</span></a><span class="sd">        seq_len (int): Sequence length.</span>
</span><span id="VocabMultinomialCLM-299"><a href="#VocabMultinomialCLM-299"><span class="linenos">299</span></a><span class="sd">        dims (list[int]): Number of neurons per LSTM layers.</span>
</span><span id="VocabMultinomialCLM-300"><a href="#VocabMultinomialCLM-300"><span class="linenos">300</span></a><span class="sd">        has_embedding (bool): Whether the model has an Embedding layer.</span>
</span><span id="VocabMultinomialCLM-301"><a href="#VocabMultinomialCLM-301"><span class="linenos">301</span></a><span class="sd">        start_token (tf.Tensor): Start token for generation.</span>
</span><span id="VocabMultinomialCLM-302"><a href="#VocabMultinomialCLM-302"><span class="linenos">302</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="VocabMultinomialCLM-303"><a href="#VocabMultinomialCLM-303"><span class="linenos">303</span></a>
</span><span id="VocabMultinomialCLM-304"><a href="#VocabMultinomialCLM-304"><span class="linenos">304</span></a>    <span class="n">ASSERT_VOCAB</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="VocabMultinomialCLM-305"><a href="#VocabMultinomialCLM-305"><span class="linenos">305</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Needs to be initialized with a vocabulary.&quot;&quot;&quot;</span>
</span><span id="VocabMultinomialCLM-306"><a href="#VocabMultinomialCLM-306"><span class="linenos">306</span></a>    <span class="n">vocab</span><span class="p">:</span> <span class="n">VocabProto</span>
</span><span id="VocabMultinomialCLM-307"><a href="#VocabMultinomialCLM-307"><span class="linenos">307</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;@private Vocabulary&quot;&quot;&quot;</span>
</span></pre></div>


            <div class="docstring"><p>Generating samples with multinomial sampling with vocabulary.</p>

<h6 id="attributes">Attributes:</h6>

<ul>
<li><strong>model (tf.keras.Model):</strong>  Model to wrap with LSTM layers.</li>
<li><strong>vocab (Vocabulary):</strong>  Vocabulary.</li>
<li><strong>seq_len (int):</strong>  Sequence length.</li>
<li><strong>dims (list[int]):</strong>  Number of neurons per LSTM layers.</li>
<li><strong>has_embedding (bool):</strong>  Whether the model has an Embedding layer.</li>
<li><strong>start_token (tf.Tensor):</strong>  Start token for generation.</li>
</ul>
</div>


                            <div id="VocabMultinomialCLM.ASSERT_VOCAB" class="classattr">
                                <div class="attr variable">
            <span class="name">ASSERT_VOCAB</span>        =
<span class="default_value">True</span>


    </div>
    <a class="headerlink" href="#VocabMultinomialCLM.ASSERT_VOCAB"></a>

            <div class="docstring"><p>Needs to be initialized with a vocabulary.</p>
</div>


                            </div>
                </section>
                <section id="allow_memory_growth">
                            <input id="allow_memory_growth-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">

        <span class="def">def</span>
        <span class="name">allow_memory_growth</span><span class="signature pdoc-code condensed">(<span class="return-annotation">) -> <span class="kc">None</span>:</span></span>

                <label class="view-source-button" for="allow_memory_growth-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#allow_memory_growth"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="allow_memory_growth-38"><a href="#allow_memory_growth-38"><span class="linenos">38</span></a><span class="k">def</span> <span class="nf">allow_memory_growth</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="allow_memory_growth-39"><a href="#allow_memory_growth-39"><span class="linenos">39</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Allow memory growth for TensorFlow GPU devices.&quot;&quot;&quot;</span>
</span><span id="allow_memory_growth-40"><a href="#allow_memory_growth-40"><span class="linenos">40</span></a>    <span class="c1"># Allow memory growth</span>
</span><span id="allow_memory_growth-41"><a href="#allow_memory_growth-41"><span class="linenos">41</span></a>    <span class="c1"># Only in main process</span>
</span><span id="allow_memory_growth-42"><a href="#allow_memory_growth-42"><span class="linenos">42</span></a>    <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</span><span id="allow_memory_growth-43"><a href="#allow_memory_growth-43"><span class="linenos">43</span></a>
</span><span id="allow_memory_growth-44"><a href="#allow_memory_growth-44"><span class="linenos">44</span></a>    <span class="k">if</span> <span class="n">gpus</span> <span class="o">:=</span> <span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="s2">&quot;GPU&quot;</span><span class="p">):</span>
</span><span id="allow_memory_growth-45"><a href="#allow_memory_growth-45"><span class="linenos">45</span></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="allow_memory_growth-46"><a href="#allow_memory_growth-46"><span class="linenos">46</span></a>            <span class="k">for</span> <span class="n">gpu</span> <span class="ow">in</span> <span class="n">gpus</span><span class="p">:</span>
</span><span id="allow_memory_growth-47"><a href="#allow_memory_growth-47"><span class="linenos">47</span></a>                <span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">set_memory_growth</span><span class="p">(</span><span class="n">gpu</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
</span><span id="allow_memory_growth-48"><a href="#allow_memory_growth-48"><span class="linenos">48</span></a>        <span class="k">except</span> <span class="ne">RuntimeError</span><span class="p">:</span>
</span><span id="allow_memory_growth-49"><a href="#allow_memory_growth-49"><span class="linenos">49</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">exception</span><span class="p">(</span><span class="s2">&quot;Failed to set memory growth&quot;</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Allow memory growth for TensorFlow GPU devices.</p>
</div>


                </section>
                <section id="batch_tensor_slices">
                            <input id="batch_tensor_slices-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">

        <span class="def">def</span>
        <span class="name">batch_tensor_slices</span><span class="signature pdoc-code multiline">(<span class="param">  <span class="n">data</span><span class="p">:</span> <span class="o">~</span><span class="n">BatchableT</span>,</span><span class="param">   <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span>,</span><span class="param">   <span class="n">desc</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param"> <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span></span><span class="return-annotation">) -> <span class="n">Iterable</span><span class="p">[</span><span class="o">~</span><span class="n">BatchableT</span><span class="p">]</span>:</span></span>

                <label class="view-source-button" for="batch_tensor_slices-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#batch_tensor_slices"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="batch_tensor_slices-98"><a href="#batch_tensor_slices-98"><span class="linenos"> 98</span></a><span class="k">def</span> <span class="nf">batch_tensor_slices</span><span class="p">(</span>
</span><span id="batch_tensor_slices-99"><a href="#batch_tensor_slices-99"><span class="linenos"> 99</span></a>    <span class="n">data</span><span class="p">:</span> <span class="n">BatchableT</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">desc</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="batch_tensor_slices-100"><a href="#batch_tensor_slices-100"><span class="linenos">100</span></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterable</span><span class="p">[</span><span class="n">BatchableT</span><span class="p">]:</span>
</span><span id="batch_tensor_slices-101"><a href="#batch_tensor_slices-101"><span class="linenos">101</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Batch tensor slices to :class:`tf.data.Dataset`.</span>
</span><span id="batch_tensor_slices-102"><a href="#batch_tensor_slices-102"><span class="linenos">102</span></a>
</span><span id="batch_tensor_slices-103"><a href="#batch_tensor_slices-103"><span class="linenos">103</span></a><span class="sd">    Args:</span>
</span><span id="batch_tensor_slices-104"><a href="#batch_tensor_slices-104"><span class="linenos">104</span></a><span class="sd">        data: Data to batch. Either a single tensor or a tuple! of tensors.</span>
</span><span id="batch_tensor_slices-105"><a href="#batch_tensor_slices-105"><span class="linenos">105</span></a><span class="sd">        batch_size: Batch size.</span>
</span><span id="batch_tensor_slices-106"><a href="#batch_tensor_slices-106"><span class="linenos">106</span></a><span class="sd">        desc: Description for tqdm. Defaults to None.</span>
</span><span id="batch_tensor_slices-107"><a href="#batch_tensor_slices-107"><span class="linenos">107</span></a><span class="sd">        verbose: Verbosity level. Defaults to 0.</span>
</span><span id="batch_tensor_slices-108"><a href="#batch_tensor_slices-108"><span class="linenos">108</span></a>
</span><span id="batch_tensor_slices-109"><a href="#batch_tensor_slices-109"><span class="linenos">109</span></a><span class="sd">    Returns:</span>
</span><span id="batch_tensor_slices-110"><a href="#batch_tensor_slices-110"><span class="linenos">110</span></a><span class="sd">        A iterable over a :class:`tf.data.Dataset` of batched data.</span>
</span><span id="batch_tensor_slices-111"><a href="#batch_tensor_slices-111"><span class="linenos">111</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="batch_tensor_slices-112"><a href="#batch_tensor_slices-112"><span class="linenos">112</span></a>    <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</span><span id="batch_tensor_slices-113"><a href="#batch_tensor_slices-113"><span class="linenos">113</span></a>
</span><span id="batch_tensor_slices-114"><a href="#batch_tensor_slices-114"><span class="linenos">114</span></a>    <span class="n">dataset</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="batch_tensor_slices-115"><a href="#batch_tensor_slices-115"><span class="linenos">115</span></a>        <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</span><span id="batch_tensor_slices-116"><a href="#batch_tensor_slices-116"><span class="linenos">116</span></a>        <span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
</span><span id="batch_tensor_slices-117"><a href="#batch_tensor_slices-117"><span class="linenos">117</span></a>        <span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>
</span><span id="batch_tensor_slices-118"><a href="#batch_tensor_slices-118"><span class="linenos">118</span></a>    <span class="p">)</span>
</span><span id="batch_tensor_slices-119"><a href="#batch_tensor_slices-119"><span class="linenos">119</span></a>    <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="batch_tensor_slices-120"><a href="#batch_tensor_slices-120"><span class="linenos">120</span></a>        <span class="n">batches</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">)</span>
</span><span id="batch_tensor_slices-121"><a href="#batch_tensor_slices-121"><span class="linenos">121</span></a>        <span class="k">return</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="n">desc</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="n">batches</span><span class="p">)</span>  <span class="c1"># type: ignore[no-any-return]</span>
</span><span id="batch_tensor_slices-122"><a href="#batch_tensor_slices-122"><span class="linenos">122</span></a>
</span><span id="batch_tensor_slices-123"><a href="#batch_tensor_slices-123"><span class="linenos">123</span></a>    <span class="k">return</span> <span class="n">dataset</span>  <span class="c1"># type: ignore[no-any-return]</span>
</span></pre></div>


            <div class="docstring"><p>Batch tensor slices to <code>tf.data.Dataset</code>.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>data:</strong>  Data to batch. Either a single tensor or a tuple! of tensors.</li>
<li><strong>batch_size:</strong>  Batch size.</li>
<li><strong>desc:</strong>  Description for tqdm. Defaults to None.</li>
<li><strong>verbose:</strong>  Verbosity level. Defaults to 0.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>A iterable over a <code>tf.data.Dataset</code> of batched data.</p>
</blockquote>
</div>


                </section>
                <section id="build_adam_optimizer">
                            <input id="build_adam_optimizer-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">

        <span class="def">def</span>
        <span class="name">build_adam_optimizer</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span></span><span class="return-annotation">) -> <span class="n">keras</span><span class="o">.</span><span class="n">src</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">Optimizer</span>:</span></span>

                <label class="view-source-button" for="build_adam_optimizer-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#build_adam_optimizer"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="build_adam_optimizer-78"><a href="#build_adam_optimizer-78"><span class="linenos">78</span></a><span class="k">def</span> <span class="nf">build_adam_optimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">:</span>
</span><span id="build_adam_optimizer-79"><a href="#build_adam_optimizer-79"><span class="linenos">79</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Return an Adam optimizer with the given learning rate.</span>
</span><span id="build_adam_optimizer-80"><a href="#build_adam_optimizer-80"><span class="linenos">80</span></a>
</span><span id="build_adam_optimizer-81"><a href="#build_adam_optimizer-81"><span class="linenos">81</span></a><span class="sd">    As there are some issues with the Adam optimizer on Apple M1,</span>
</span><span id="build_adam_optimizer-82"><a href="#build_adam_optimizer-82"><span class="linenos">82</span></a><span class="sd">    we use the legacy version in this case.</span>
</span><span id="build_adam_optimizer-83"><a href="#build_adam_optimizer-83"><span class="linenos">83</span></a>
</span><span id="build_adam_optimizer-84"><a href="#build_adam_optimizer-84"><span class="linenos">84</span></a><span class="sd">    Args:</span>
</span><span id="build_adam_optimizer-85"><a href="#build_adam_optimizer-85"><span class="linenos">85</span></a><span class="sd">        learning_rate: Initial learning rate.</span>
</span><span id="build_adam_optimizer-86"><a href="#build_adam_optimizer-86"><span class="linenos">86</span></a>
</span><span id="build_adam_optimizer-87"><a href="#build_adam_optimizer-87"><span class="linenos">87</span></a><span class="sd">    Returns:</span>
</span><span id="build_adam_optimizer-88"><a href="#build_adam_optimizer-88"><span class="linenos">88</span></a><span class="sd">        Adam optimizer.</span>
</span><span id="build_adam_optimizer-89"><a href="#build_adam_optimizer-89"><span class="linenos">89</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="build_adam_optimizer-90"><a href="#build_adam_optimizer-90"><span class="linenos">90</span></a>    <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</span><span id="build_adam_optimizer-91"><a href="#build_adam_optimizer-91"><span class="linenos">91</span></a>
</span><span id="build_adam_optimizer-92"><a href="#build_adam_optimizer-92"><span class="linenos">92</span></a>    <span class="k">if</span> <span class="n">platform</span><span class="o">.</span><span class="n">system</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;Darwin&quot;</span> <span class="ow">and</span> <span class="n">platform</span><span class="o">.</span><span class="n">processor</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;arm&quot;</span><span class="p">:</span>
</span><span id="build_adam_optimizer-93"><a href="#build_adam_optimizer-93"><span class="linenos">93</span></a>        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">legacy</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
</span><span id="build_adam_optimizer-94"><a href="#build_adam_optimizer-94"><span class="linenos">94</span></a>
</span><span id="build_adam_optimizer-95"><a href="#build_adam_optimizer-95"><span class="linenos">95</span></a>    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Return an Adam optimizer with the given learning rate.</p>

<p>As there are some issues with the Adam optimizer on Apple M1,
we use the legacy version in this case.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>learning_rate:</strong>  Initial learning rate.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>Adam optimizer.</p>
</blockquote>
</div>


                </section>
                <section id="build_model_cp">
                            <input id="build_model_cp-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">

        <span class="def">def</span>
        <span class="name">build_model_cp</span><span class="signature pdoc-code multiline">(<span class="param">   <span class="n">models_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>,</span><span class="param"> <span class="n">scheme</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="si">{epoch}</span><span class="s1">.h5&#39;</span>,</span><span class="param"> <span class="n">best_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>,</span><span class="param">    <span class="n">weights_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span></span><span class="return-annotation">) -> <span class="n">keras</span><span class="o">.</span><span class="n">src</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span>:</span></span>

                <label class="view-source-button" for="build_model_cp-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#build_model_cp"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="build_model_cp-52"><a href="#build_model_cp-52"><span class="linenos">52</span></a><span class="k">def</span> <span class="nf">build_model_cp</span><span class="p">(</span>
</span><span id="build_model_cp-53"><a href="#build_model_cp-53"><span class="linenos">53</span></a>    <span class="n">models_path</span><span class="p">:</span> <span class="n">StrPath</span><span class="p">,</span>
</span><span id="build_model_cp-54"><a href="#build_model_cp-54"><span class="linenos">54</span></a>    <span class="n">scheme</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">{epoch}</span><span class="s2">.h5&quot;</span><span class="p">,</span>
</span><span id="build_model_cp-55"><a href="#build_model_cp-55"><span class="linenos">55</span></a>    <span class="n">best_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="build_model_cp-56"><a href="#build_model_cp-56"><span class="linenos">56</span></a>    <span class="n">weights_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="build_model_cp-57"><a href="#build_model_cp-57"><span class="linenos">57</span></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">:</span>
</span><span id="build_model_cp-58"><a href="#build_model_cp-58"><span class="linenos">58</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the model checkpoint callback.</span>
</span><span id="build_model_cp-59"><a href="#build_model_cp-59"><span class="linenos">59</span></a>
</span><span id="build_model_cp-60"><a href="#build_model_cp-60"><span class="linenos">60</span></a><span class="sd">    Args:</span>
</span><span id="build_model_cp-61"><a href="#build_model_cp-61"><span class="linenos">61</span></a><span class="sd">        models_path: Path to save the models</span>
</span><span id="build_model_cp-62"><a href="#build_model_cp-62"><span class="linenos">62</span></a><span class="sd">        scheme: Scheme to save the models. Defaults to &quot;{epoch}.h5&quot;.</span>
</span><span id="build_model_cp-63"><a href="#build_model_cp-63"><span class="linenos">63</span></a><span class="sd">        best_only: Save only the best model. Defaults to False.</span>
</span><span id="build_model_cp-64"><a href="#build_model_cp-64"><span class="linenos">64</span></a><span class="sd">        weights_only: Save only the weights. Defaults to True.</span>
</span><span id="build_model_cp-65"><a href="#build_model_cp-65"><span class="linenos">65</span></a>
</span><span id="build_model_cp-66"><a href="#build_model_cp-66"><span class="linenos">66</span></a><span class="sd">    Returns:</span>
</span><span id="build_model_cp-67"><a href="#build_model_cp-67"><span class="linenos">67</span></a><span class="sd">        The model checkpoint callback</span>
</span><span id="build_model_cp-68"><a href="#build_model_cp-68"><span class="linenos">68</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="build_model_cp-69"><a href="#build_model_cp-69"><span class="linenos">69</span></a>    <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</span><span id="build_model_cp-70"><a href="#build_model_cp-70"><span class="linenos">70</span></a>
</span><span id="build_model_cp-71"><a href="#build_model_cp-71"><span class="linenos">71</span></a>    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span>
</span><span id="build_model_cp-72"><a href="#build_model_cp-72"><span class="linenos">72</span></a>        <span class="nb">str</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">models_path</span><span class="p">)</span> <span class="o">/</span> <span class="n">scheme</span><span class="p">),</span>
</span><span id="build_model_cp-73"><a href="#build_model_cp-73"><span class="linenos">73</span></a>        <span class="n">save_best_only</span><span class="o">=</span><span class="n">best_only</span><span class="p">,</span>
</span><span id="build_model_cp-74"><a href="#build_model_cp-74"><span class="linenos">74</span></a>        <span class="n">save_weights_only</span><span class="o">=</span><span class="n">weights_only</span><span class="p">,</span>
</span><span id="build_model_cp-75"><a href="#build_model_cp-75"><span class="linenos">75</span></a>    <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Get the model checkpoint callback.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>models_path:</strong>  Path to save the models</li>
<li><strong>scheme:</strong>  Scheme to save the models. Defaults to "{epoch}.h5".</li>
<li><strong>best_only:</strong>  Save only the best model. Defaults to False.</li>
<li><strong>weights_only:</strong>  Save only the weights. Defaults to True.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>The model checkpoint callback</p>
</blockquote>
</div>


                </section>
                <section id="get_data_from_vocab">
                            <input id="get_data_from_vocab-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">

        <span class="def">def</span>
        <span class="name">get_data_from_vocab</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">vocab</span><span class="p">:</span> <span class="n"><a href="vocab.html#VocabProto">lstm_clm.vocab.VocabProto</a></span></span><span class="return-annotation">) -> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span>:</span></span>

                <label class="view-source-button" for="get_data_from_vocab-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#get_data_from_vocab"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="get_data_from_vocab-317"><a href="#get_data_from_vocab-317"><span class="linenos">317</span></a><span class="k">def</span> <span class="nf">get_data_from_vocab</span><span class="p">(</span><span class="n">vocab</span><span class="p">:</span> <span class="n">VocabProto</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
</span><span id="get_data_from_vocab-318"><a href="#get_data_from_vocab-318"><span class="linenos">318</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the settings stored in a vocabulary.</span>
</span><span id="get_data_from_vocab-319"><a href="#get_data_from_vocab-319"><span class="linenos">319</span></a>
</span><span id="get_data_from_vocab-320"><a href="#get_data_from_vocab-320"><span class="linenos">320</span></a><span class="sd">    Args:</span>
</span><span id="get_data_from_vocab-321"><a href="#get_data_from_vocab-321"><span class="linenos">321</span></a><span class="sd">        vocab: Vocabulary.</span>
</span><span id="get_data_from_vocab-322"><a href="#get_data_from_vocab-322"><span class="linenos">322</span></a>
</span><span id="get_data_from_vocab-323"><a href="#get_data_from_vocab-323"><span class="linenos">323</span></a><span class="sd">    Returns:</span>
</span><span id="get_data_from_vocab-324"><a href="#get_data_from_vocab-324"><span class="linenos">324</span></a><span class="sd">        A tuple with the vocabulary size (length of the tokens),</span>
</span><span id="get_data_from_vocab-325"><a href="#get_data_from_vocab-325"><span class="linenos">325</span></a><span class="sd">        defined maximum length,</span>
</span><span id="get_data_from_vocab-326"><a href="#get_data_from_vocab-326"><span class="linenos">326</span></a><span class="sd">        start index (index of the BOS token),</span>
</span><span id="get_data_from_vocab-327"><a href="#get_data_from_vocab-327"><span class="linenos">327</span></a><span class="sd">        and sequence length append (1 if EOS token is present, else 0).</span>
</span><span id="get_data_from_vocab-328"><a href="#get_data_from_vocab-328"><span class="linenos">328</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="get_data_from_vocab-329"><a href="#get_data_from_vocab-329"><span class="linenos">329</span></a>    <span class="n">start_index</span> <span class="o">=</span> <span class="n">vocab</span><span class="o">.</span><span class="n">encode_map</span><span class="p">[</span><span class="n">vocab</span><span class="o">.</span><span class="n">bos</span><span class="p">]</span>
</span><span id="get_data_from_vocab-330"><a href="#get_data_from_vocab-330"><span class="linenos">330</span></a>    <span class="n">seq_len_append</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">vocab</span><span class="o">.</span><span class="n">eos</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">0</span>
</span><span id="get_data_from_vocab-331"><a href="#get_data_from_vocab-331"><span class="linenos">331</span></a>    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">vocab</span><span class="o">.</span><span class="n">max_len</span><span class="p">,</span> <span class="n">start_index</span><span class="p">,</span> <span class="n">seq_len_append</span>
</span></pre></div>


            <div class="docstring"><p>Get the settings stored in a vocabulary.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>vocab:</strong>  Vocabulary.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>A tuple with the vocabulary size (length of the tokens),
  defined maximum length,
  start index (index of the BOS token),
  and sequence length append (1 if EOS token is present, else 0).</p>
</blockquote>
</div>


                </section>
    </main>
<script>
    function escapeHTML(html) {
        return document.createElement('div').appendChild(document.createTextNode(html)).parentNode.innerHTML;
    }

    const originalContent = document.querySelector("main.pdoc");
    let currentContent = originalContent;

    function setContent(innerHTML) {
        let elem;
        if (innerHTML) {
            elem = document.createElement("main");
            elem.classList.add("pdoc");
            elem.innerHTML = innerHTML;
        } else {
            elem = originalContent;
        }
        if (currentContent !== elem) {
            currentContent.replaceWith(elem);
            currentContent = elem;
        }
    }

    function getSearchTerm() {
        return (new URL(window.location)).searchParams.get("search");
    }

    const searchBox = document.querySelector(".pdoc input[type=search]");
    searchBox.addEventListener("input", function () {
        let url = new URL(window.location);
        if (searchBox.value.trim()) {
            url.hash = "";
            url.searchParams.set("search", searchBox.value);
        } else {
            url.searchParams.delete("search");
        }
        history.replaceState("", "", url.toString());
        onInput();
    });
    window.addEventListener("popstate", onInput);


    let search, searchErr;

    async function initialize() {
        try {
            search = await new Promise((resolve, reject) => {
                const script = document.createElement("script");
                script.type = "text/javascript";
                script.async = true;
                script.onload = () => resolve(window.pdocSearch);
                script.onerror = (e) => reject(e);
                script.src = "../search.js";
                document.getElementsByTagName("head")[0].appendChild(script);
            });
        } catch (e) {
            console.error("Cannot fetch pdoc search index");
            searchErr = "Cannot fetch search index.";
        }
        onInput();

        document.querySelector("nav.pdoc").addEventListener("click", e => {
            if (e.target.hash) {
                searchBox.value = "";
                searchBox.dispatchEvent(new Event("input"));
            }
        });
    }

    function onInput() {
        setContent((() => {
            const term = getSearchTerm();
            if (!term) {
                return null
            }
            if (searchErr) {
                return `<h3>Error: ${searchErr}</h3>`
            }
            if (!search) {
                return "<h3>Searching...</h3>"
            }

            window.scrollTo({top: 0, left: 0, behavior: 'auto'});

            const results = search(term);

            let html;
            if (results.length === 0) {
                html = `No search results for '${escapeHTML(term)}'.`
            } else {
                html = `<h4>${results.length} search result${results.length > 1 ? "s" : ""} for '${escapeHTML(term)}'.</h4>`;
            }
            for (let result of results.slice(0, 10)) {
                let doc = result.doc;
                let url = `../${doc.modulename.replaceAll(".", "/")}.html`;
                if (doc.qualname) {
                    url += `#${doc.qualname}`;
                }

                let heading;
                switch (result.doc.kind) {
                    case "function":
                        if (doc.fullname.endsWith(".__init__")) {
                            heading = `<span class="name">${doc.fullname.replace(/\.__init__$/, "")}</span>${doc.signature}`;
                        } else {
                            heading = `<span class="def">${doc.funcdef}</span> <span class="name">${doc.fullname}</span>${doc.signature}`;
                        }
                        break;
                    case "class":
                        heading = `<span class="def">class</span> <span class="name">${doc.fullname}</span>`;
                        if (doc.bases)
                            heading += `<wbr>(<span class="base">${doc.bases}</span>)`;
                        heading += `:`;
                        break;
                    case "variable":
                        heading = `<span class="name">${doc.fullname}</span>`;
                        if (doc.annotation)
                            heading += `<span class="annotation">${doc.annotation}</span>`;
                        if (doc.default_value)
                            heading += `<span class="default_value"> = ${doc.default_value}</span>`;
                        break;
                    default:
                        heading = `<span class="name">${doc.fullname}</span>`;
                        break;
                }
                html += `
                        <section class="search-result">
                        <a href="${url}" class="attr ${doc.kind}">${heading}</a>
                        <div class="docstring">${doc.doc}</div>
                        </section>
                    `;

            }
            return html;
        })());
    }

    if (getSearchTerm()) {
        initialize();
        searchBox.value = getSearchTerm();
        onInput();
    } else {
        searchBox.addEventListener("focus", initialize, {once: true});
    }

    searchBox.addEventListener("keydown", e => {
        if (["ArrowDown", "ArrowUp", "Enter"].includes(e.key)) {
            let focused = currentContent.querySelector(".search-result.focused");
            if (!focused) {
                currentContent.querySelector(".search-result").classList.add("focused");
            } else if (
                e.key === "ArrowDown"
                && focused.nextElementSibling
                && focused.nextElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.nextElementSibling.classList.add("focused");
                focused.nextElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "ArrowUp"
                && focused.previousElementSibling
                && focused.previousElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.previousElementSibling.classList.add("focused");
                focused.previousElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "Enter"
            ) {
                focused.querySelector("a").click();
            }
        }
    });
</script></body>
</html>
